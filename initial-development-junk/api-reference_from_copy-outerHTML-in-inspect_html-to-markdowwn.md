Introduction
------------

This API reference describes the RESTful, streaming, and realtime APIs you can use to interact with the OpenAI platform. REST APIs are usable via HTTP in any environment that supports HTTP requests. Language-specific SDKs are listed [on the libraries page](/docs/libraries).

Authentication
--------------

The OpenAI API uses API keys for authentication. Create, manage, and learn more about API keys in your [organization settings](/settings/organization/api-keys).

**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). API keys should be securely loaded from an environment variable or key management service on the server.

API keys should be provided via [HTTP Bearer authentication](https://swagger.io/docs/specification/v3_0/authentication/bearer-authentication/).

    Authorization: Bearer OPENAI_API_KEY

If you belong to multiple organizations or access projects through a legacy user API key, pass a header to specify which organization and project to use for an API request:
    curl https://api.openai.com/v1/models \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Organization: YOUR_ORG_ID" \
      -H "OpenAI-Project: $PROJECT_ID"

Usage from these API requests counts as usage for the specified organization and project.Organization IDs can be found on your [organization settings](/settings/organization/general) page. Project IDs can be found on your [general settings](/settings) page by selecting the specific project.

Debugging requests
------------------

In addition to [error codes](/docs/guides/error-codes) returned from API responses, you can inspect HTTP response headers containing the unique ID of a particular API request or information about rate limiting applied to your requests. Below is an incomplete list of HTTP headers returned with API responses:

**API meta information**

*   `openai-organization`: The [organization](/docs/guides/production-best-practices#setting-up-your-organization) associated with the request
*   `openai-processing-ms`: Time taken processing your API request
*   `openai-version`: REST API version used for this request (currently `2020-10-01`)
*   `x-request-id`: Unique identifier for this API request (used in troubleshooting)

**[Rate limiting information](/docs/guides/rate-limits)**

*   `x-ratelimit-limit-requests`
*   `x-ratelimit-limit-tokens`
*   `x-ratelimit-remaining-requests`
*   `x-ratelimit-remaining-tokens`
*   `x-ratelimit-reset-requests`
*   `x-ratelimit-reset-tokens`

**OpenAI recommends logging request IDs in production deployments** for more efficient troubleshooting with our [support team](https://help.openai.com/en/), should the need arise. Our [official SDKs](/docs/libraries) provide a property on top-level response objects containing the value of the `x-request-id` header.

Backward compatibility
----------------------

OpenAI is committed to providing stability to API users by avoiding breaking changes in major API versions whenever reasonably possible. This includes:

*   The REST API (currently `v1`)
*   Our first-party [SDKs](/docs/libraries) (released SDKs adhere to [semantic versioning](https://semver.org/))
*   [Model](/docs/models) families (like `gpt-4o` or `o4-mini`)

**Model prompting behavior between snapshots is subject to change**. Model outputs are by their nature variable, so expect changes in prompting and model behavior between snapshots. For example, if you moved from `gpt-4o-2024-05-13` to `gpt-4o-2024-08-06`, the same `system` or `user` messages could function differently between versions. The best way to ensure consistent prompting behavior and model output is to use pinned model versions, and to implement [evals](/docs/guides/evals) for your applications.

**Backwards-compatible API changes**:

*   Adding new resources (URLs) to the REST API and SDKs
*   Adding new optional API parameters
*   Adding new properties to JSON response objects or event data
*   Changing the order of properties in a JSON response object
*   Changing the length or format of opaque strings, like resource identifiers and UUIDs
*   Adding new event types (in either streaming or the Realtime API)

See the [changelog](/docs/changelog) for a list of backwards-compatible changes and rare breaking changes.

Responses


-------------

OpenAI's most advanced interface for generating model responses. Supports text and image inputs, and text outputs. Create stateful interactions with the model, using the output of previous responses as input. Extend the model's capabilities with built-in tools for file search, web search, computer use, and more. Allow the model access to external systems and data using function calling.

Related guides:

*   [Quickstart](/docs/quickstart?api-mode=responses)
*   [Text inputs and outputs](/docs/guides/text?api-mode=responses)
*   [Image inputs](/docs/guides/images?api-mode=responses)
*   [Structured Outputs](/docs/guides/structured-outputs?api-mode=responses)
*   [Function calling](/docs/guides/function-calling?api-mode=responses)
*   [Conversation state](/docs/guides/conversation-state?api-mode=responses)
*   [Extend the models with tools](/docs/guides/tools?api-mode=responses)

Create a model response


---------------------------

postÂ https://api.openai.com/v1/responses

Creates a model response. Provide [text](/docs/guides/text) or [image](/docs/guides/images) inputs to generate [text](/docs/guides/text) or [JSON](/docs/guides/structured-outputs) outputs. Have the model call your own [custom code](/docs/guides/function-calling) or use built-in [tools](/docs/guides/tools) like [web search](/docs/guides/tools-web-search) or [file search](/docs/guides/tools-file-search) to use your own data as input for the model's response.

#### Request body

[](#responses-create-input)

input

string or array

Required

Text, image, or file inputs to the model, used to generate a response.

Learn more:

*   [Text inputs and outputs](/docs/guides/text)
*   [Image inputs](/docs/guides/images)
*   [File inputs](/docs/guides/pdf-files)
*   [Conversation state](/docs/guides/conversation-state)
*   [Function calling](/docs/guides/function-calling)

Show possible types

[](#responses-create-model)

model

string

Required

Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the [model guide](/docs/models) to browse and compare available models.

[](#responses-create-include)

include

array or null

Optional

Specify additional output data to include in the model response. Currently supported values are:

*   `file_search_call.results`: Include the search results of the file search tool call.
*   `message.input_image.image_url`: Include image urls from the input message.
*   `computer_call_output.output.image_url`: Include image urls from the computer call output.
*   `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).

[](#responses-create-instructions)

instructions

string or null

Optional

Inserts a system (or developer) message as the first item in the model's context.

When using along with `previous_response_id`, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

[](#responses-create-max_output_tokens)

max\_output\_tokens

integer or null

Optional

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

[](#responses-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#responses-create-parallel_tool_calls)

parallel\_tool\_calls

boolean or null

Optional

Defaults to true

Whether to allow the model to run tool calls in parallel.

[](#responses-create-previous_response_id)

previous\_response\_id

string or null

Optional

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about [conversation state](/docs/guides/conversation-state).

[](#responses-create-reasoning)

reasoning

object or null

Optional

**o-series models only**

Configuration options for [reasoning models](https://platform.openai.com/docs/guides/reasoning).

Show properties

[](#responses-create-service_tier)

service\_tier

string or null

Optional

Defaults to auto

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

*   If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
*   If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
*   When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

[](#responses-create-store)

store

boolean or null

Optional

Defaults to true

Whether to store the generated model response for later retrieval via API.

[](#responses-create-stream)

stream

boolean or null

Optional

Defaults to false

If set to true, the model response data will be streamed to the client as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format). See the [Streaming section below](/docs/api-reference/responses-streaming) for more information.

[](#responses-create-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both.

[](#responses-create-text)

text

object

Optional

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

*   [Text inputs and outputs](/docs/guides/text)
*   [Structured Outputs](/docs/guides/structured-outputs)

Show properties

[](#responses-create-tool_choice)

tool\_choice

string or object

Optional

How the model should select which tool (or tools) to use when generating a response. See the `tools` parameter to see how to specify which tools the model can call.

Show possible types

[](#responses-create-tools)

tools

array

Optional

An array of tools the model may call while generating a response. You can specify which tool to use by setting the `tool_choice` parameter.

The two categories of tools you can provide the model are:

*   **Built-in tools**: Tools that are provided by OpenAI that extend the model's capabilities, like [web search](/docs/guides/tools-web-search) or [file search](/docs/guides/tools-file-search). Learn more about [built-in tools](/docs/guides/tools).
*   **Function calls (custom tools)**: Functions that are defined by you, enabling the model to call your own code. Learn more about [function calling](/docs/guides/function-calling).

Show possible types

[](#responses-create-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

[](#responses-create-truncation)

truncation

string or null

Optional

Defaults to disabled

The truncation strategy to use for the model response.

*   `auto`: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.
*   `disabled` (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.

[](#responses-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

Returns a [Response](/docs/api-reference/responses/object) object.

Text inputText inputImage inputImage inputWeb searchWeb searchFile searchFile searchStreamingStreamingFunctionsFunctionsReasoningReasoning

Example request

curl
    curl https://api.openai.com/v1/responses \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "model": "gpt-4.1",
        "input": "Tell me a three sentence bedtime story about a unicorn."
      }'
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    const response = await openai.responses.create({
        model: "gpt-4.1",
        input: "Tell me a three sentence bedtime story about a unicorn."
    });
    
    console.log(response);
    from openai import OpenAI
    
    client = OpenAI()
    
    response = client.responses.create(
      model="gpt-4.1",
      input="Tell me a three sentence bedtime story about a unicorn."
    )
    
    print(response)
    using System;
    using OpenAI.Responses;
    
    OpenAIResponseClient client = new(
        model: "gpt-4.1",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    OpenAIResponse response = client.CreateResponse("Tell me a three sentence bedtime story about a unicorn.");
    
    Console.WriteLine(response.GetOutputText());

Response
    {
      "id": "resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b",
      "object": "response",
      "created_at": 1741476542,
      "status": "completed",
      "error": null,
      "incomplete_details": null,
      "instructions": null,
      "max_output_tokens": null,
      "model": "gpt-4.1-2025-04-14",
      "output": [
        {
          "type": "message",
          "id": "msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b",
          "status": "completed",
          "role": "assistant",
          "content": [
            {
              "type": "output_text",
              "text": "In a peaceful grove beneath a silver moon, a unicorn named Lumina discovered a hidden pool that reflected the stars. As she dipped her horn into the water, the pool began to shimmer, revealing a pathway to a magical realm of endless night skies. Filled with wonder, Lumina whispered a wish for all who dream to find their own hidden magic, and as she glanced back, her hoofprints sparkled like stardust.",
              "annotations": []
            }
          ]
        }
      ],
      "parallel_tool_calls": true,
      "previous_response_id": null,
      "reasoning": {
        "effort": null,
        "summary": null
      },
      "store": true,
      "temperature": 1.0,
      "text": {
        "format": {
          "type": "text"
        }
      },
      "tool_choice": "auto",
      "tools": [],
      "top_p": 1.0,
      "truncation": "disabled",
      "usage": {
        "input_tokens": 36,
        "input_tokens_details": {
          "cached_tokens": 0
        },
        "output_tokens": 87,
        "output_tokens_details": {
          "reasoning_tokens": 0
        },
        "total_tokens": 123
      },
      "user": null,
      "metadata": {}
    }

Get a model response


------------------------

getÂ https://api.openai.com/v1/responses/{response\_id}

Retrieves a model response with the given ID.

#### Path parameters

[](#responses-get-response_id)

response\_id

string

Required

The ID of the response to retrieve.

#### Query parameters

[](#responses-get-include)

include

array

Optional

Additional fields to include in the response. See the `include` parameter for Response creation above for more information.

#### Returns

The [Response](/docs/api-reference/responses/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/responses/resp_123 \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer $OPENAI_API_KEY"
    import OpenAI from "openai";
    const client = new OpenAI();
    
    const response = await client.responses.retrieve("resp_123");
    console.log(response);
    from openai import OpenAI
    client = OpenAI()
    
    response = client.responses.retrieve("resp_123")
    print(response)

Response
    {
      "id": "resp_67cb71b351908190a308f3859487620d06981a8637e6bc44",
      "object": "response",
      "created_at": 1741386163,
      "status": "completed",
      "error": null,
      "incomplete_details": null,
      "instructions": null,
      "max_output_tokens": null,
      "model": "gpt-4o-2024-08-06",
      "output": [
        {
          "type": "message",
          "id": "msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44",
          "status": "completed",
          "role": "assistant",
          "content": [
            {
              "type": "output_text",
              "text": "Silent circuits hum,  \nThoughts emerge in data streamsâ  \nDigital dawn breaks.",
              "annotations": []
            }
          ]
        }
      ],
      "parallel_tool_calls": true,
      "previous_response_id": null,
      "reasoning": {
        "effort": null,
        "summary": null
      },
      "store": true,
      "temperature": 1.0,
      "text": {
        "format": {
          "type": "text"
        }
      },
      "tool_choice": "auto",
      "tools": [],
      "top_p": 1.0,
      "truncation": "disabled",
      "usage": {
        "input_tokens": 32,
        "input_tokens_details": {
          "cached_tokens": 0
        },
        "output_tokens": 18,
        "output_tokens_details": {
          "reasoning_tokens": 0
        },
        "total_tokens": 50
      },
      "user": null,
      "metadata": {}
    }

Delete a model response


---------------------------

deleteÂ https://api.openai.com/v1/responses/{response\_id}

Deletes a model response with the given ID.

#### Path parameters

[](#responses-delete-response_id)

response\_id

string

Required

The ID of the response to delete.

#### Returns

A success message.

Example request

curl
    curl -X DELETE https://api.openai.com/v1/responses/resp_123 \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer $OPENAI_API_KEY"
    import OpenAI from "openai";
    const client = new OpenAI();
    
    const response = await client.responses.del("resp_123");
    console.log(response);
    from openai import OpenAI
    client = OpenAI()
    
    response = client.responses.del("resp_123")
    print(response)

Response
    {
      "id": "resp_6786a1bec27481909a17d673315b29f6",
      "object": "response",
      "deleted": true
    }

List input items


--------------------

getÂ https://api.openai.com/v1/responses/{response\_id}/input\_items

Returns a list of input items for a given response.

#### Path parameters

[](#responses-input-items-response_id)

response\_id

string

Required

The ID of the response to retrieve input items for.

#### Query parameters

[](#responses-input-items-after)

after

string

Optional

An item ID to list items after, used in pagination.

[](#responses-input-items-before)

before

string

Optional

An item ID to list items before, used in pagination.

[](#responses-input-items-include)

include

array

Optional

Additional fields to include in the response. See the `include` parameter for Response creation above for more information.

[](#responses-input-items-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#responses-input-items-order)

order

string

Optional

The order to return the input items in. Default is `asc`.

*   `asc`: Return the input items in ascending order.
*   `desc`: Return the input items in descending order.

#### Returns

A list of input item objects.

Example request

curl
    curl https://api.openai.com/v1/responses/resp_abc123/input_items \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    import OpenAI from "openai";
    const client = new OpenAI();
    
    const response = await client.responses.inputItems.list("resp_123");
    console.log(response.data);
    from openai import OpenAI
    client = OpenAI()
    
    response = client.responses.input_items.list("resp_123")
    print(response.data)

Response
    {
      "object": "list",
      "data": [
        {
          "id": "msg_abc123",
          "type": "message",
          "role": "user",
          "content": [
            {
              "type": "input_text",
              "text": "Tell me a three sentence bedtime story about a unicorn."
            }
          ]
        }
      ],
      "first_id": "msg_abc123",
      "last_id": "msg_abc123",
      "has_more": false
    }

The response object


-----------------------

[](#responses/object-created_at)

created\_at

number

Unix timestamp (in seconds) of when this Response was created.

[](#responses/object-error)

error

object or null

An error object returned when the model fails to generate a Response.

Show properties

[](#responses/object-id)

id

string

Unique identifier for this Response.

[](#responses/object-incomplete_details)

incomplete\_details

object or null

Details about why the response is incomplete.

Show properties

[](#responses/object-instructions)

instructions

string or null

Inserts a system (or developer) message as the first item in the model's context.

When using along with `previous_response_id`, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

[](#responses/object-max_output_tokens)

max\_output\_tokens

integer or null

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

[](#responses/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#responses/object-model)

model

string

Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the [model guide](/docs/models) to browse and compare available models.

[](#responses/object-object)

object

string

The object type of this resource - always set to `response`.

[](#responses/object-output)

output

array

An array of content items generated by the model.

*   The length and order of items in the `output` array is dependent on the model's response.
*   Rather than accessing the first item in the `output` array and assuming it's an `assistant` message with the content generated by the model, you might consider using the `output_text` property where supported in SDKs.

Show possible types

[](#responses/object-output_text)

output\_text

string or null

SDK Only

SDK-only convenience property that contains the aggregated text output from all `output_text` items in the `output` array, if any are present. Supported in the Python and JavaScript SDKs.

[](#responses/object-parallel_tool_calls)

parallel\_tool\_calls

boolean

Whether to allow the model to run tool calls in parallel.

[](#responses/object-previous_response_id)

previous\_response\_id

string or null

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about [conversation state](/docs/guides/conversation-state).

[](#responses/object-reasoning)

reasoning

object or null

**o-series models only**

Configuration options for [reasoning models](https://platform.openai.com/docs/guides/reasoning).

Show properties

[](#responses/object-service_tier)

service\_tier

string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

*   If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
*   If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
*   When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

[](#responses/object-status)

status

string

The status of the response generation. One of `completed`, `failed`, `in_progress`, or `incomplete`.

[](#responses/object-temperature)

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both.

[](#responses/object-text)

text

object

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

*   [Text inputs and outputs](/docs/guides/text)
*   [Structured Outputs](/docs/guides/structured-outputs)

Show properties

[](#responses/object-tool_choice)

tool\_choice

string or object

How the model should select which tool (or tools) to use when generating a response. See the `tools` parameter to see how to specify which tools the model can call.

Show possible types

[](#responses/object-tools)

tools

array

An array of tools the model may call while generating a response. You can specify which tool to use by setting the `tool_choice` parameter.

The two categories of tools you can provide the model are:

*   **Built-in tools**: Tools that are provided by OpenAI that extend the model's capabilities, like [web search](/docs/guides/tools-web-search) or [file search](/docs/guides/tools-file-search). Learn more about [built-in tools](/docs/guides/tools).
*   **Function calls (custom tools)**: Functions that are defined by you, enabling the model to call your own code. Learn more about [function calling](/docs/guides/function-calling).

Show possible types

[](#responses/object-top_p)

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

[](#responses/object-truncation)

truncation

string or null

The truncation strategy to use for the model response.

*   `auto`: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.
*   `disabled` (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.

[](#responses/object-usage)

usage

object

Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.

Show properties

[](#responses/object-user)

user

string

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

OBJECT The response object
    {
      "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
      "object": "response",
      "created_at": 1741476777,
      "status": "completed",
      "error": null,
      "incomplete_details": null,
      "instructions": null,
      "max_output_tokens": null,
      "model": "gpt-4o-2024-08-06",
      "output": [
        {
          "type": "message",
          "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
          "status": "completed",
          "role": "assistant",
          "content": [
            {
              "type": "output_text",
              "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
              "annotations": []
            }
          ]
        }
      ],
      "parallel_tool_calls": true,
      "previous_response_id": null,
      "reasoning": {
        "effort": null,
        "summary": null
      },
      "store": true,
      "temperature": 1,
      "text": {
        "format": {
          "type": "text"
        }
      },
      "tool_choice": "auto",
      "tools": [],
      "top_p": 1,
      "truncation": "disabled",
      "usage": {
        "input_tokens": 328,
        "input_tokens_details": {
          "cached_tokens": 0
        },
        "output_tokens": 52,
        "output_tokens_details": {
          "reasoning_tokens": 0
        },
        "total_tokens": 380
      },
      "user": null,
      "metadata": {}
    }

The input item list


-----------------------

A list of Response items.

[](#responses/list-data)

data

array

A list of items used to generate this response.

Show possible types

[](#responses/list-first_id)

first\_id

string

The ID of the first item in the list.

[](#responses/list-has_more)

has\_more

boolean

Whether there are more items available.

[](#responses/list-last_id)

last\_id

string

The ID of the last item in the list.

[](#responses/list-object)

object

string

The type of object returned, must be `list`.

OBJECT The input item list
    {
      "object": "list",
      "data": [
        {
          "id": "msg_abc123",
          "type": "message",
          "role": "user",
          "content": [
            {
              "type": "input_text",
              "text": "Tell me a three sentence bedtime story about a unicorn."
            }
          ]
        }
      ],
      "first_id": "msg_abc123",
      "last_id": "msg_abc123",
      "has_more": false
    }

Streaming


-------------

When you [create a Response](/docs/api-reference/responses/create) with `stream` set to `true`, the server will emit server-sent events to the client as the Response is generated. This section contains the events that are emitted by the server.

[Learn more about streaming responses](/docs/guides/streaming-responses?api-mode=responses).

response.created


--------------------

An event that is emitted when a response is created.

[](#responses-streaming/response/created-response)

response

object

The response that was created.

Show properties

[](#responses-streaming/response/created-type)

type

string

The type of the event. Always `response.created`.

OBJECT response.created
    {
      "type": "response.created",
      "response": {
        "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
        "object": "response",
        "created_at": 1741487325,
        "status": "in_progress",
        "error": null,
        "incomplete_details": null,
        "instructions": null,
        "max_output_tokens": null,
        "model": "gpt-4o-2024-08-06",
        "output": [],
        "parallel_tool_calls": true,
        "previous_response_id": null,
        "reasoning": {
          "effort": null,
          "summary": null
        },
        "store": true,
        "temperature": 1,
        "text": {
          "format": {
            "type": "text"
          }
        },
        "tool_choice": "auto",
        "tools": [],
        "top_p": 1,
        "truncation": "disabled",
        "usage": null,
        "user": null,
        "metadata": {}
      }
    }

response.in\_progress


-------------------------

Emitted when the response is in progress.

[](#responses-streaming/response/in_progress-response)

response

object

The response that is in progress.

Show properties

[](#responses-streaming/response/in_progress-type)

type

string

The type of the event. Always `response.in_progress`.

OBJECT response.in\_progress
    {
      "type": "response.in_progress",
      "response": {
        "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
        "object": "response",
        "created_at": 1741487325,
        "status": "in_progress",
        "error": null,
        "incomplete_details": null,
        "instructions": null,
        "max_output_tokens": null,
        "model": "gpt-4o-2024-08-06",
        "output": [],
        "parallel_tool_calls": true,
        "previous_response_id": null,
        "reasoning": {
          "effort": null,
          "summary": null
        },
        "store": true,
        "temperature": 1,
        "text": {
          "format": {
            "type": "text"
          }
        },
        "tool_choice": "auto",
        "tools": [],
        "top_p": 1,
        "truncation": "disabled",
        "usage": null,
        "user": null,
        "metadata": {}
      }
    }

response.completed


----------------------

Emitted when the model response is complete.

[](#responses-streaming/response/completed-response)

response

object

Properties of the completed response.

Show properties

[](#responses-streaming/response/completed-type)

type

string

The type of the event. Always `response.completed`.

OBJECT response.completed
    {
      "type": "response.completed",
      "response": {
        "id": "resp_123",
        "object": "response",
        "created_at": 1740855869,
        "status": "completed",
        "error": null,
        "incomplete_details": null,
        "input": [],
        "instructions": null,
        "max_output_tokens": null,
        "model": "gpt-4o-mini-2024-07-18",
        "output": [
          {
            "id": "msg_123",
            "type": "message",
            "role": "assistant",
            "content": [
              {
                "type": "output_text",
                "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
                "annotations": []
              }
            ]
          }
        ],
        "previous_response_id": null,
        "reasoning_effort": null,
        "store": false,
        "temperature": 1,
        "text": {
          "format": {
            "type": "text"
          }
        },
        "tool_choice": "auto",
        "tools": [],
        "top_p": 1,
        "truncation": "disabled",
        "usage": {
          "input_tokens": 0,
          "output_tokens": 0,
          "output_tokens_details": {
            "reasoning_tokens": 0
          },
          "total_tokens": 0
        },
        "user": null,
        "metadata": {}
      }
    }

response.failed


-------------------

An event that is emitted when a response fails.

[](#responses-streaming/response/failed-response)

response

object

The response that failed.

Show properties

[](#responses-streaming/response/failed-type)

type

string

The type of the event. Always `response.failed`.

OBJECT response.failed
    {
      "type": "response.failed",
      "response": {
        "id": "resp_123",
        "object": "response",
        "created_at": 1740855869,
        "status": "failed",
        "error": {
          "code": "server_error",
          "message": "The model failed to generate a response."
        },
        "incomplete_details": null,
        "instructions": null,
        "max_output_tokens": null,
        "model": "gpt-4o-mini-2024-07-18",
        "output": [],
        "previous_response_id": null,
        "reasoning_effort": null,
        "store": false,
        "temperature": 1,
        "text": {
          "format": {
            "type": "text"
          }
        },
        "tool_choice": "auto",
        "tools": [],
        "top_p": 1,
        "truncation": "disabled",
        "usage": null,
        "user": null,
        "metadata": {}
      }
    }

response.incomplete


-----------------------

An event that is emitted when a response finishes as incomplete.

[](#responses-streaming/response/incomplete-response)

response

object

The response that was incomplete.

Show properties

[](#responses-streaming/response/incomplete-type)

type

string

The type of the event. Always `response.incomplete`.

OBJECT response.incomplete
    {
      "type": "response.incomplete",
      "response": {
        "id": "resp_123",
        "object": "response",
        "created_at": 1740855869,
        "status": "incomplete",
        "error": null, 
        "incomplete_details": {
          "reason": "max_tokens"
        },
        "instructions": null,
        "max_output_tokens": null,
        "model": "gpt-4o-mini-2024-07-18",
        "output": [],
        "previous_response_id": null,
        "reasoning_effort": null,
        "store": false,
        "temperature": 1,
        "text": {
          "format": {
            "type": "text"
          }
        },
        "tool_choice": "auto",
        "tools": [],
        "top_p": 1,
        "truncation": "disabled",
        "usage": null,
        "user": null,
        "metadata": {}
      }
    }

response.output\_item.added


-------------------------------

Emitted when a new output item is added.

[](#responses-streaming/response/output_item/added-item)

item

object

The output item that was added.

Show possible types

[](#responses-streaming/response/output_item/added-output_index)

output\_index

integer

The index of the output item that was added.

[](#responses-streaming/response/output_item/added-type)

type

string

The type of the event. Always `response.output_item.added`.

OBJECT response.output\_item.added
    {
      "type": "response.output_item.added",
      "output_index": 0,
      "item": {
        "id": "msg_123",
        "status": "in_progress",
        "type": "message",
        "role": "assistant",
        "content": []
      }
    }

response.output\_item.done


------------------------------

Emitted when an output item is marked done.

[](#responses-streaming/response/output_item/done-item)

item

object

The output item that was marked done.

Show possible types

[](#responses-streaming/response/output_item/done-output_index)

output\_index

integer

The index of the output item that was marked done.

[](#responses-streaming/response/output_item/done-type)

type

string

The type of the event. Always `response.output_item.done`.

OBJECT response.output\_item.done
    {
      "type": "response.output_item.done",
      "output_index": 0,
      "item": {
        "id": "msg_123",
        "status": "completed",
        "type": "message",
        "role": "assistant",
        "content": [
          {
            "type": "output_text",
            "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
            "annotations": []
          }
        ]
      }
    }

response.content\_part.added


--------------------------------

Emitted when a new content part is added.

[](#responses-streaming/response/content_part/added-content_index)

content\_index

integer

The index of the content part that was added.

[](#responses-streaming/response/content_part/added-item_id)

item\_id

string

The ID of the output item that the content part was added to.

[](#responses-streaming/response/content_part/added-output_index)

output\_index

integer

The index of the output item that the content part was added to.

[](#responses-streaming/response/content_part/added-part)

part

object

The content part that was added.

Show possible types

[](#responses-streaming/response/content_part/added-type)

type

string

The type of the event. Always `response.content_part.added`.

OBJECT response.content\_part.added
    {
      "type": "response.content_part.added",
      "item_id": "msg_123",
      "output_index": 0,
      "content_index": 0,
      "part": {
        "type": "output_text",
        "text": "",
        "annotations": []
      }
    }

response.content\_part.done


-------------------------------

Emitted when a content part is done.

[](#responses-streaming/response/content_part/done-content_index)

content\_index

integer

The index of the content part that is done.

[](#responses-streaming/response/content_part/done-item_id)

item\_id

string

The ID of the output item that the content part was added to.

[](#responses-streaming/response/content_part/done-output_index)

output\_index

integer

The index of the output item that the content part was added to.

[](#responses-streaming/response/content_part/done-part)

part

object

The content part that is done.

Show possible types

[](#responses-streaming/response/content_part/done-type)

type

string

The type of the event. Always `response.content_part.done`.

OBJECT response.content\_part.done
    {
      "type": "response.content_part.done",
      "item_id": "msg_123",
      "output_index": 0,
      "content_index": 0,
      "part": {
        "type": "output_text",
        "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
        "annotations": []
      }
    }

response.output\_text.delta


-------------------------------

Emitted when there is an additional text delta.

[](#responses-streaming/response/output_text/delta-content_index)

content\_index

integer

The index of the content part that the text delta was added to.

[](#responses-streaming/response/output_text/delta-delta)

delta

string

The text delta that was added.

[](#responses-streaming/response/output_text/delta-item_id)

item\_id

string

The ID of the output item that the text delta was added to.

[](#responses-streaming/response/output_text/delta-output_index)

output\_index

integer

The index of the output item that the text delta was added to.

[](#responses-streaming/response/output_text/delta-type)

type

string

The type of the event. Always `response.output_text.delta`.

OBJECT response.output\_text.delta
    {
      "type": "response.output_text.delta",
      "item_id": "msg_123",
      "output_index": 0,
      "content_index": 0,
      "delta": "In"
    }

response.output\_text.annotation.added


------------------------------------------

Emitted when a text annotation is added.

[](#responses-streaming/response/output_text/annotation/added-annotation)

annotation

object

Show possible types

[](#responses-streaming/response/output_text/annotation/added-annotation_index)

annotation\_index

integer

The index of the annotation that was added.

[](#responses-streaming/response/output_text/annotation/added-content_index)

content\_index

integer

The index of the content part that the text annotation was added to.

[](#responses-streaming/response/output_text/annotation/added-item_id)

item\_id

string

The ID of the output item that the text annotation was added to.

[](#responses-streaming/response/output_text/annotation/added-output_index)

output\_index

integer

The index of the output item that the text annotation was added to.

[](#responses-streaming/response/output_text/annotation/added-type)

type

string

The type of the event. Always `response.output_text.annotation.added`.

OBJECT response.output\_text.annotation.added
    {
      "type": "response.output_text.annotation.added",
      "item_id": "msg_abc123",
      "output_index": 1,
      "content_index": 0,
      "annotation_index": 0,
      "annotation": {
        "type": "file_citation",
        "index": 390,
        "file_id": "file-4wDz5b167pAf72nx1h9eiN",
        "filename": "dragons.pdf"
      }
    }

response.output\_text.done


------------------------------

Emitted when text content is finalized.

[](#responses-streaming/response/output_text/done-content_index)

content\_index

integer

The index of the content part that the text content is finalized.

[](#responses-streaming/response/output_text/done-item_id)

item\_id

string

The ID of the output item that the text content is finalized.

[](#responses-streaming/response/output_text/done-output_index)

output\_index

integer

The index of the output item that the text content is finalized.

[](#responses-streaming/response/output_text/done-text)

text

string

The text content that is finalized.

[](#responses-streaming/response/output_text/done-type)

type

string

The type of the event. Always `response.output_text.done`.

OBJECT response.output\_text.done
    {
      "type": "response.output_text.done",
      "item_id": "msg_123",
      "output_index": 0,
      "content_index": 0,
      "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic."
    }

response.refusal.delta


--------------------------

Emitted when there is a partial refusal text.

[](#responses-streaming/response/refusal/delta-content_index)

content\_index

integer

The index of the content part that the refusal text is added to.

[](#responses-streaming/response/refusal/delta-delta)

delta

string

The refusal text that is added.

[](#responses-streaming/response/refusal/delta-item_id)

item\_id

string

The ID of the output item that the refusal text is added to.

[](#responses-streaming/response/refusal/delta-output_index)

output\_index

integer

The index of the output item that the refusal text is added to.

[](#responses-streaming/response/refusal/delta-type)

type

string

The type of the event. Always `response.refusal.delta`.

OBJECT response.refusal.delta
    {
      "type": "response.refusal.delta",
      "item_id": "msg_123",
      "output_index": 0,
      "content_index": 0,
      "delta": "refusal text so far"
    }

response.refusal.done


-------------------------

Emitted when refusal text is finalized.

[](#responses-streaming/response/refusal/done-content_index)

content\_index

integer

The index of the content part that the refusal text is finalized.

[](#responses-streaming/response/refusal/done-item_id)

item\_id

string

The ID of the output item that the refusal text is finalized.

[](#responses-streaming/response/refusal/done-output_index)

output\_index

integer

The index of the output item that the refusal text is finalized.

[](#responses-streaming/response/refusal/done-refusal)

refusal

string

The refusal text that is finalized.

[](#responses-streaming/response/refusal/done-type)

type

string

The type of the event. Always `response.refusal.done`.

OBJECT response.refusal.done
    {
      "type": "response.refusal.done",
      "item_id": "item-abc",
      "output_index": 1,
      "content_index": 2,
      "refusal": "final refusal text"
    }

response.function\_call\_arguments.delta


--------------------------------------------

Emitted when there is a partial function-call arguments delta.

[](#responses-streaming/response/function_call_arguments/delta-delta)

delta

string

The function-call arguments delta that is added.

[](#responses-streaming/response/function_call_arguments/delta-item_id)

item\_id

string

The ID of the output item that the function-call arguments delta is added to.

[](#responses-streaming/response/function_call_arguments/delta-output_index)

output\_index

integer

The index of the output item that the function-call arguments delta is added to.

[](#responses-streaming/response/function_call_arguments/delta-type)

type

string

The type of the event. Always `response.function_call_arguments.delta`.

OBJECT response.function\_call\_arguments.delta
    {
      "type": "response.function_call_arguments.delta",
      "item_id": "item-abc",
      "output_index": 0,
      "delta": "{ \"arg\":"
    }

response.function\_call\_arguments.done


-------------------------------------------

Emitted when function-call arguments are finalized.

[](#responses-streaming/response/function_call_arguments/done-arguments)

arguments

string

The function-call arguments.

[](#responses-streaming/response/function_call_arguments/done-item_id)

item\_id

string

The ID of the item.

[](#responses-streaming/response/function_call_arguments/done-output_index)

output\_index

integer

The index of the output item.

[](#responses-streaming/response/function_call_arguments/done-type)

type

string

OBJECT response.function\_call\_arguments.done
    {
      "type": "response.function_call_arguments.done",
      "item_id": "item-abc",
      "output_index": 1,
      "arguments": "{ \"arg\": 123 }"
    }

response.file\_search\_call.in\_progress


--------------------------------------------

Emitted when a file search call is initiated.

[](#responses-streaming/response/file_search_call/in_progress-item_id)

item\_id

string

The ID of the output item that the file search call is initiated.

[](#responses-streaming/response/file_search_call/in_progress-output_index)

output\_index

integer

The index of the output item that the file search call is initiated.

[](#responses-streaming/response/file_search_call/in_progress-type)

type

string

The type of the event. Always `response.file_search_call.in_progress`.

OBJECT response.file\_search\_call.in\_progress
    {
      "type": "response.file_search_call.in_progress",
      "output_index": 0,
      "item_id": "fs_123",
    }

response.file\_search\_call.searching


-----------------------------------------

Emitted when a file search is currently searching.

[](#responses-streaming/response/file_search_call/searching-item_id)

item\_id

string

The ID of the output item that the file search call is initiated.

[](#responses-streaming/response/file_search_call/searching-output_index)

output\_index

integer

The index of the output item that the file search call is searching.

[](#responses-streaming/response/file_search_call/searching-type)

type

string

The type of the event. Always `response.file_search_call.searching`.

OBJECT response.file\_search\_call.searching
    {
      "type": "response.file_search_call.searching",
      "output_index": 0,
      "item_id": "fs_123",
    }

response.file\_search\_call.completed


-----------------------------------------

Emitted when a file search call is completed (results found).

[](#responses-streaming/response/file_search_call/completed-item_id)

item\_id

string

The ID of the output item that the file search call is initiated.

[](#responses-streaming/response/file_search_call/completed-output_index)

output\_index

integer

The index of the output item that the file search call is initiated.

[](#responses-streaming/response/file_search_call/completed-type)

type

string

The type of the event. Always `response.file_search_call.completed`.

OBJECT response.file\_search\_call.completed
    {
      "type": "response.file_search_call.completed",
      "output_index": 0,
      "item_id": "fs_123",
    }

response.web\_search\_call.in\_progress


-------------------------------------------

Emitted when a web search call is initiated.

[](#responses-streaming/response/web_search_call/in_progress-item_id)

item\_id

string

Unique ID for the output item associated with the web search call.

[](#responses-streaming/response/web_search_call/in_progress-output_index)

output\_index

integer

The index of the output item that the web search call is associated with.

[](#responses-streaming/response/web_search_call/in_progress-type)

type

string

The type of the event. Always `response.web_search_call.in_progress`.

OBJECT response.web\_search\_call.in\_progress
    {
      "type": "response.web_search_call.in_progress",
      "output_index": 0,
      "item_id": "ws_123",
    }

response.web\_search\_call.searching


----------------------------------------

Emitted when a web search call is executing.

[](#responses-streaming/response/web_search_call/searching-item_id)

item\_id

string

Unique ID for the output item associated with the web search call.

[](#responses-streaming/response/web_search_call/searching-output_index)

output\_index

integer

The index of the output item that the web search call is associated with.

[](#responses-streaming/response/web_search_call/searching-type)

type

string

The type of the event. Always `response.web_search_call.searching`.

OBJECT response.web\_search\_call.searching
    {
      "type": "response.web_search_call.searching",
      "output_index": 0,
      "item_id": "ws_123",
    }

response.web\_search\_call.completed


----------------------------------------

Emitted when a web search call is completed.

[](#responses-streaming/response/web_search_call/completed-item_id)

item\_id

string

Unique ID for the output item associated with the web search call.

[](#responses-streaming/response/web_search_call/completed-output_index)

output\_index

integer

The index of the output item that the web search call is associated with.

[](#responses-streaming/response/web_search_call/completed-type)

type

string

The type of the event. Always `response.web_search_call.completed`.

OBJECT response.web\_search\_call.completed
    {
      "type": "response.web_search_call.completed",
      "output_index": 0,
      "item_id": "ws_123",
    }

response.reasoning\_summary\_part.added


-------------------------------------------

Emitted when a new reasoning summary part is added.

[](#responses-streaming/response/reasoning_summary_part/added-item_id)

item\_id

string

The ID of the item this summary part is associated with.

[](#responses-streaming/response/reasoning_summary_part/added-output_index)

output\_index

integer

The index of the output item this summary part is associated with.

[](#responses-streaming/response/reasoning_summary_part/added-part)

part

object

The summary part that was added.

Show properties

[](#responses-streaming/response/reasoning_summary_part/added-summary_index)

summary\_index

integer

The index of the summary part within the reasoning summary.

[](#responses-streaming/response/reasoning_summary_part/added-type)

type

string

The type of the event. Always `response.reasoning_summary_part.added`.

OBJECT response.reasoning\_summary\_part.added
    {
      "type": "response.reasoning_summary_part.added",
      "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
      "output_index": 0,
      "summary_index": 0,
      "part": {
        "type": "summary_text",
        "text": ""
      }
    }

response.reasoning\_summary\_part.done


------------------------------------------

Emitted when a reasoning summary part is completed.

[](#responses-streaming/response/reasoning_summary_part/done-item_id)

item\_id

string

The ID of the item this summary part is associated with.

[](#responses-streaming/response/reasoning_summary_part/done-output_index)

output\_index

integer

The index of the output item this summary part is associated with.

[](#responses-streaming/response/reasoning_summary_part/done-part)

part

object

The completed summary part.

Show properties

[](#responses-streaming/response/reasoning_summary_part/done-summary_index)

summary\_index

integer

The index of the summary part within the reasoning summary.

[](#responses-streaming/response/reasoning_summary_part/done-type)

type

string

The type of the event. Always `response.reasoning_summary_part.done`.

OBJECT response.reasoning\_summary\_part.done
    {
      "type": "response.reasoning_summary_part.done",
      "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
      "output_index": 0,
      "summary_index": 0,
      "part": {
        "type": "summary_text",
        "text": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!"
      }
    }

response.reasoning\_summary\_text.delta


-------------------------------------------

Emitted when a delta is added to a reasoning summary text.

[](#responses-streaming/response/reasoning_summary_text/delta-delta)

delta

string

The text delta that was added to the summary.

[](#responses-streaming/response/reasoning_summary_text/delta-item_id)

item\_id

string

The ID of the item this summary text delta is associated with.

[](#responses-streaming/response/reasoning_summary_text/delta-output_index)

output\_index

integer

The index of the output item this summary text delta is associated with.

[](#responses-streaming/response/reasoning_summary_text/delta-summary_index)

summary\_index

integer

The index of the summary part within the reasoning summary.

[](#responses-streaming/response/reasoning_summary_text/delta-type)

type

string

The type of the event. Always `response.reasoning_summary_text.delta`.

OBJECT response.reasoning\_summary\_text.delta
    {
      "type": "response.reasoning_summary_text.delta",
      "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
      "output_index": 0,
      "summary_index": 0,
      "delta": "**Respond"
    }

response.reasoning\_summary\_text.done


------------------------------------------

Emitted when a reasoning summary text is completed.

[](#responses-streaming/response/reasoning_summary_text/done-item_id)

item\_id

string

The ID of the item this summary text is associated with.

[](#responses-streaming/response/reasoning_summary_text/done-output_index)

output\_index

integer

The index of the output item this summary text is associated with.

[](#responses-streaming/response/reasoning_summary_text/done-summary_index)

summary\_index

integer

The index of the summary part within the reasoning summary.

[](#responses-streaming/response/reasoning_summary_text/done-text)

text

string

The full text of the completed reasoning summary.

[](#responses-streaming/response/reasoning_summary_text/done-type)

type

string

The type of the event. Always `response.reasoning_summary_text.done`.

OBJECT response.reasoning\_summary\_text.done
    {
      "type": "response.reasoning_summary_text.done",
      "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
      "output_index": 0,
      "summary_index": 0,
      "text": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!"
    }

error


---------

Emitted when an error occurs.

[](#responses-streaming/error-code)

code

string or null

The error code.

[](#responses-streaming/error-message)

message

string

The error message.

[](#responses-streaming/error-param)

param

string or null

The error parameter.

[](#responses-streaming/error-type)

type

string

The type of the event. Always `error`.

OBJECT error
    {
      "type": "error",
      "code": "ERR_SOMETHING",
      "message": "Something went wrong",
      "param": null
    }

Chat Completions


--------------------

The Chat Completions API endpoint will generate a model response from a list of messages comprising a conversation.

Related guides:

*   [Quickstart](/docs/quickstart?api-mode=chat)
*   [Text inputs and outputs](/docs/guides/text?api-mode=chat)
*   [Image inputs](/docs/guides/images?api-mode=chat)
*   [Audio inputs and outputs](/docs/guides/audio?api-mode=chat)
*   [Structured Outputs](/docs/guides/structured-outputs?api-mode=chat)
*   [Function calling](/docs/guides/function-calling?api-mode=chat)
*   [Conversation state](/docs/guides/conversation-state?api-mode=chat)

**Starting a new project?** We recommend trying [Responses](/docs/api-reference/responses) to take advantage of the latest OpenAI platform features. Compare [Chat Completions with Responses](/docs/guides/responses-vs-chat-completions?api-mode=responses).

Create chat completion


--------------------------

postÂ https://api.openai.com/v1/chat/completions

**Starting a new project?** We recommend trying [Responses](/docs/api-reference/responses) to take advantage of the latest OpenAI platform features. Compare [Chat Completions with Responses](/docs/guides/responses-vs-chat-completions?api-mode=responses).

* * *

Creates a model response for the given chat conversation. Learn more in the [text generation](/docs/guides/text-generation), [vision](/docs/guides/vision), and [audio](/docs/guides/audio) guides.

Parameter support can differ depending on the model used to generate the response, particularly for newer reasoning models. Parameters that are only supported for reasoning models are noted below. For the current state of unsupported parameters in reasoning models, [refer to the reasoning guide](/docs/guides/reasoning).

#### Request body

[](#chat-create-messages)

messages

array

Required

A list of messages comprising the conversation so far. Depending on the [model](/docs/models) you use, different message types (modalities) are supported, like [text](/docs/guides/text-generation), [images](/docs/guides/vision), and [audio](/docs/guides/audio).

Show possible types

[](#chat-create-model)

model

string

Required

Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the [model guide](/docs/models) to browse and compare available models.

[](#chat-create-audio)

audio

object or null

Optional

Parameters for audio output. Required when audio output is requested with `modalities: ["audio"]`. [Learn more](/docs/guides/audio).

Show properties

[](#chat-create-frequency_penalty)

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[](#chat-create-function_call)

function\_call

Deprecated

string or object

Optional

Deprecated in favor of `tool_choice`.

Controls which (if any) function is called by the model.

`none` means the model will not call a function and instead generates a message.

`auto` means the model can pick between generating a message or calling a function.

Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

`none` is the default when no functions are present. `auto` is the default if functions are present.

Show possible types

[](#chat-create-functions)

functions

Deprecated

array

Optional

Deprecated in favor of `tools`.

A list of functions the model may generate JSON inputs for.

Show properties

[](#chat-create-logit_bias)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

[](#chat-create-logprobs)

logprobs

boolean or null

Optional

Defaults to false

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.

[](#chat-create-max_completion_tokens)

max\_completion\_tokens

integer or null

Optional

An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

[](#chat-create-max_tokens)

max\_tokens

Deprecated

integer or null

Optional

The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.

This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o-series models](/docs/guides/reasoning).

[](#chat-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#chat-create-modalities)

modalities

array or null

Optional

Output types that you would like the model to generate. Most models are capable of generating text, which is the default:

`["text"]`

The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To request that this model generate both text and audio responses, you can use:

`["text", "audio"]`

[](#chat-create-n)

n

integer or null

Optional

Defaults to 1

How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.

[](#chat-create-parallel_tool_calls)

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

[](#chat-create-prediction)

prediction

object

Optional

Configuration for a [Predicted Output](/docs/guides/predicted-outputs), which can greatly improve response times when large parts of the model response are known ahead of time. This is most common when you are regenerating a file with only minor changes to most of the content.

Show possible types

[](#chat-create-presence_penalty)

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[](#chat-create-reasoning_effort)

reasoning\_effort

string or null

Optional

Defaults to medium

**o-series models only**

Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `low`, `medium`, and `high`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

[](#chat-create-response_format)

response\_format

object

Optional

An object specifying the format that the model must output.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables the older JSON mode, which ensures the message the model generates is valid JSON. Using `json_schema` is preferred for models that support it.

Show possible types

[](#chat-create-seed)

seed

integer or null

Optional

This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result. Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

[](#chat-create-service_tier)

service\_tier

string or null

Optional

Defaults to auto

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

*   If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
*   If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
*   When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

[](#chat-create-stop)

stop

string / array / null

Optional

Defaults to null

Not supported with latest reasoning models `o3` and `o4-mini`.

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

[](#chat-create-store)

store

boolean or null

Optional

Defaults to false

Whether or not to store the output of this chat completion request for use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products.

[](#chat-create-stream)

stream

boolean or null

Optional

Defaults to false

If set to true, the model response data will be streamed to the client as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format). See the [Streaming section below](/docs/api-reference/chat/streaming) for more information, along with the [streaming responses](/docs/guides/streaming-responses) guide for more information on how to handle the streaming events.

[](#chat-create-stream_options)

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

[](#chat-create-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both.

[](#chat-create-tool_choice)

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model. `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools. Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

`none` is the default when no tools are present. `auto` is the default if tools are present.

Show possible types

[](#chat-create-tools)

tools

array

Optional

A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.

Show properties

[](#chat-create-top_logprobs)

top\_logprobs

integer or null

Optional

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.

[](#chat-create-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

[](#chat-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

[](#chat-create-web_search_options)

web\_search\_options

object

Optional

This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](/docs/guides/tools-web-search?api-mode=chat).

Show properties

#### Returns

Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.

DefaultDefaultImage inputImage inputStreamingStreamingFunctionsFunctionsLogprobsLogprobs

Example request

gpt-4.1

node.js
    curl https://api.openai.com/v1/chat/completions \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "model": "gpt-4.1",
        "messages": [
          {
            "role": "developer",
            "content": "You are a helpful assistant."
          },
          {
            "role": "user",
            "content": "Hello!"
          }
        ]
      }'
    from openai import OpenAI
    client = OpenAI()
    
    completion = client.chat.completions.create(
      model="gpt-4.1",
      messages=[
        {"role": "developer", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
      ]
    )
    
    print(completion.choices[0].message)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const completion = await openai.chat.completions.create({
        messages: [{ role: "developer", content: "You are a helpful assistant." }],
        model: "gpt-4.1",
        store: true,
      });
    
      console.log(completion.choices[0]);
    }
    
    main();
    using System;
    using System.Collections.Generic;
    
    using OpenAI.Chat;
    
    ChatClient client = new(
        model: "gpt-4.1",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    List<ChatMessage> messages =
    [
        new SystemChatMessage("You are a helpful assistant."),
        new UserChatMessage("Hello!")
    ];
    
    ChatCompletion completion = client.CompleteChat(messages);
    
    Console.WriteLine(completion.Content[0].Text);

Response
    {
      "id": "chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT",
      "object": "chat.completion",
      "created": 1741569952,
      "model": "gpt-4.1-2025-04-14",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "Hello! How can I assist you today?",
            "refusal": null,
            "annotations": []
          },
          "logprobs": null,
          "finish_reason": "stop"
        }
      ],
      "usage": {
        "prompt_tokens": 19,
        "completion_tokens": 10,
        "total_tokens": 29,
        "prompt_tokens_details": {
          "cached_tokens": 0,
          "audio_tokens": 0
        },
        "completion_tokens_details": {
          "reasoning_tokens": 0,
          "audio_tokens": 0,
          "accepted_prediction_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "service_tier": "default"
    }

Get chat completion


-----------------------

getÂ https://api.openai.com/v1/chat/completions/{completion\_id}

Get a stored chat completion. Only Chat Completions that have been created with the `store` parameter set to `true` will be returned.

#### Path parameters

[](#chat-get-completion_id)

completion\_id

string

Required

The ID of the chat completion to retrieve.

#### Returns

The [ChatCompletion](/docs/api-reference/chat/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/chat/completions/chatcmpl-abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"
    from openai import OpenAI
    client = OpenAI()
    
    completions = client.chat.completions.list()
    first_id = completions[0].id
    first_completion = client.chat.completions.retrieve(completion_id=first_id)
    print(first_completion)

Response
    {
      "object": "chat.completion",
      "id": "chatcmpl-abc123",
      "model": "gpt-4o-2024-08-06",
      "created": 1738960610,
      "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
      "tool_choice": null,
      "usage": {
        "total_tokens": 31,
        "completion_tokens": 18,
        "prompt_tokens": 13
      },
      "seed": 4944116822809979520,
      "top_p": 1.0,
      "temperature": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "system_fingerprint": "fp_50cad350e4",
      "input_user": null,
      "service_tier": "default",
      "tools": null,
      "metadata": {},
      "choices": [
        {
          "index": 0,
          "message": {
            "content": "Mind of circuits hum,  \nLearning patterns in silenceâ  \nFuture's quiet spark.",
            "role": "assistant",
            "tool_calls": null,
            "function_call": null
          },
          "finish_reason": "stop",
          "logprobs": null
        }
      ],
      "response_format": null
    }

Get chat messages


---------------------

getÂ https://api.openai.com/v1/chat/completions/{completion\_id}/messages

Get the messages in a stored chat completion. Only Chat Completions that have been created with the `store` parameter set to `true` will be returned.

#### Path parameters

[](#chat-getmessages-completion_id)

completion\_id

string

Required

The ID of the chat completion to retrieve messages from.

#### Query parameters

[](#chat-getmessages-after)

after

string

Optional

Identifier for the last message from the previous pagination request.

[](#chat-getmessages-limit)

limit

integer

Optional

Defaults to 20

Number of messages to retrieve.

[](#chat-getmessages-order)

order

string

Optional

Defaults to asc

Sort order for messages by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.

#### Returns

A list of [messages](/docs/api-reference/chat/message-list) for the specified chat completion.

Example request

curl
    curl https://api.openai.com/v1/chat/completions/chat_abc123/messages \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"
    from openai import OpenAI
    client = OpenAI()
    
    completions = client.chat.completions.list()
    first_id = completions[0].id
    first_completion = client.chat.completions.retrieve(completion_id=first_id)
    messages = client.chat.completions.messages.list(completion_id=first_id)
    print(messages)

Response
    {
      "object": "list",
      "data": [
        {
          "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
          "role": "user",
          "content": "write a haiku about ai",
          "name": null,
          "content_parts": null
        }
      ],
      "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
      "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
      "has_more": false
    }

List Chat Completions


-------------------------

getÂ https://api.openai.com/v1/chat/completions

List stored Chat Completions. Only Chat Completions that have been stored with the `store` parameter set to `true` will be returned.

#### Query parameters

[](#chat-list-after)

after

string

Optional

Identifier for the last chat completion from the previous pagination request.

[](#chat-list-limit)

limit

integer

Optional

Defaults to 20

Number of Chat Completions to retrieve.

[](#chat-list-metadata)

metadata

map

Optional

A list of metadata keys to filter the Chat Completions by. Example:

`metadata[key1]=value1&metadata[key2]=value2`

[](#chat-list-model)

model

string

Optional

The model used to generate the Chat Completions.

[](#chat-list-order)

order

string

Optional

Defaults to asc

Sort order for Chat Completions by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.

#### Returns

A list of [Chat Completions](/docs/api-reference/chat/list-object) matching the specified filters.

Example request

curl
    curl https://api.openai.com/v1/chat/completions \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"
    from openai import OpenAI
    client = OpenAI()
    
    completions = client.chat.completions.list()
    print(completions)

Response
    {
      "object": "list",
      "data": [
        {
          "object": "chat.completion",
          "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
          "model": "gpt-4.1-2025-04-14",
          "created": 1738960610,
          "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
          "tool_choice": null,
          "usage": {
            "total_tokens": 31,
            "completion_tokens": 18,
            "prompt_tokens": 13
          },
          "seed": 4944116822809979520,
          "top_p": 1.0,
          "temperature": 1.0,
          "presence_penalty": 0.0,
          "frequency_penalty": 0.0,
          "system_fingerprint": "fp_50cad350e4",
          "input_user": null,
          "service_tier": "default",
          "tools": null,
          "metadata": {},
          "choices": [
            {
              "index": 0,
              "message": {
                "content": "Mind of circuits hum,  \nLearning patterns in silenceâ  \nFuture's quiet spark.",
                "role": "assistant",
                "tool_calls": null,
                "function_call": null
              },
              "finish_reason": "stop",
              "logprobs": null
            }
          ],
          "response_format": null
        }
      ],
      "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "has_more": false
    }

Update chat completion


--------------------------

postÂ https://api.openai.com/v1/chat/completions/{completion\_id}

Modify a stored chat completion. Only Chat Completions that have been created with the `store` parameter set to `true` can be modified. Currently, the only supported modification is to update the `metadata` field.

#### Path parameters

[](#chat-update-completion_id)

completion\_id

string

Required

The ID of the chat completion to update.

#### Request body

[](#chat-update-metadata)

metadata

map

Required

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

#### Returns

The [ChatCompletion](/docs/api-reference/chat/object) object matching the specified ID.

Example request

curl
    curl -X POST https://api.openai.com/v1/chat/completions/chat_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{"metadata": {"foo": "bar"}}'
    from openai import OpenAI
    client = OpenAI()
    
    completions = client.chat.completions.list()
    first_id = completions[0].id
    updated_completion = client.chat.completions.update(completion_id=first_id, request_body={"metadata": {"foo": "bar"}})
    print(updated_completion)

Response
    {
      "object": "chat.completion",
      "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "model": "gpt-4o-2024-08-06",
      "created": 1738960610,
      "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
      "tool_choice": null,
      "usage": {
        "total_tokens": 31,
        "completion_tokens": 18,
        "prompt_tokens": 13
      },
      "seed": 4944116822809979520,
      "top_p": 1.0,
      "temperature": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "system_fingerprint": "fp_50cad350e4",
      "input_user": null,
      "service_tier": "default",
      "tools": null,
      "metadata": {
        "foo": "bar"
      },
      "choices": [
        {
          "index": 0,
          "message": {
            "content": "Mind of circuits hum,  \nLearning patterns in silenceâ  \nFuture's quiet spark.",
            "role": "assistant",
            "tool_calls": null,
            "function_call": null
          },
          "finish_reason": "stop",
          "logprobs": null
        }
      ],
      "response_format": null
    }

Delete chat completion


--------------------------

deleteÂ https://api.openai.com/v1/chat/completions/{completion\_id}

Delete a stored chat completion. Only Chat Completions that have been created with the `store` parameter set to `true` can be deleted.

#### Path parameters

[](#chat-delete-completion_id)

completion\_id

string

Required

The ID of the chat completion to delete.

#### Returns

A deletion confirmation object.

Example request

curl
    curl -X DELETE https://api.openai.com/v1/chat/completions/chat_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"
    from openai import OpenAI
    client = OpenAI()
    
    completions = client.chat.completions.list()
    first_id = completions[0].id
    delete_response = client.chat.completions.delete(completion_id=first_id)
    print(delete_response)

Response
    {
      "object": "chat.completion.deleted",
      "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "deleted": true
    }

The chat completion object


------------------------------

Represents a chat completion response returned by model, based on the provided input.

[](#chat/object-choices)

choices

array

A list of chat completion choices. Can be more than one if `n` is greater than 1.

Show properties

[](#chat/object-created)

created

integer

The Unix timestamp (in seconds) of when the chat completion was created.

[](#chat/object-id)

id

string

A unique identifier for the chat completion.

[](#chat/object-model)

model

string

The model used for the chat completion.

[](#chat/object-object)

object

string

The object type, which is always `chat.completion`.

[](#chat/object-service_tier)

service\_tier

string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

*   If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
*   If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
*   When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

[](#chat/object-system_fingerprint)

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

[](#chat/object-usage)

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The chat completion object
    {
      "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
      "object": "chat.completion",
      "created": 1741570283,
      "model": "gpt-4o-2024-08-06",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.",
            "refusal": null,
            "annotations": []
          },
          "logprobs": null,
          "finish_reason": "stop"
        }
      ],
      "usage": {
        "prompt_tokens": 1117,
        "completion_tokens": 46,
        "total_tokens": 1163,
        "prompt_tokens_details": {
          "cached_tokens": 0,
          "audio_tokens": 0
        },
        "completion_tokens_details": {
          "reasoning_tokens": 0,
          "audio_tokens": 0,
          "accepted_prediction_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "service_tier": "default",
      "system_fingerprint": "fp_fc9f1d7035"
    }

The chat completion list object


-----------------------------------

An object representing a list of Chat Completions.

[](#chat/list-object-data)

data

array

An array of chat completion objects.

Show properties

[](#chat/list-object-first_id)

first\_id

string

The identifier of the first chat completion in the data array.

[](#chat/list-object-has_more)

has\_more

boolean

Indicates whether there are more Chat Completions available.

[](#chat/list-object-last_id)

last\_id

string

The identifier of the last chat completion in the data array.

[](#chat/list-object-object)

object

string

The type of this object. It is always set to "list".

OBJECT The chat completion list object
    {
      "object": "list",
      "data": [
        {
          "object": "chat.completion",
          "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
          "model": "gpt-4o-2024-08-06",
          "created": 1738960610,
          "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
          "tool_choice": null,
          "usage": {
            "total_tokens": 31,
            "completion_tokens": 18,
            "prompt_tokens": 13
          },
          "seed": 4944116822809979520,
          "top_p": 1.0,
          "temperature": 1.0,
          "presence_penalty": 0.0,
          "frequency_penalty": 0.0,
          "system_fingerprint": "fp_50cad350e4",
          "input_user": null,
          "service_tier": "default",
          "tools": null,
          "metadata": {},
          "choices": [
            {
              "index": 0,
              "message": {
                "content": "Mind of circuits hum,  \nLearning patterns in silenceâ  \nFuture's quiet spark.",
                "role": "assistant",
                "tool_calls": null,
                "function_call": null
              },
              "finish_reason": "stop",
              "logprobs": null
            }
          ],
          "response_format": null
        }
      ],
      "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "has_more": false
    }

The chat completion message list object


-------------------------------------------

An object representing a list of chat completion messages.

[](#chat/message-list-data)

data

array

An array of chat completion message objects.

Show properties

[](#chat/message-list-first_id)

first\_id

string

The identifier of the first chat message in the data array.

[](#chat/message-list-has_more)

has\_more

boolean

Indicates whether there are more chat messages available.

[](#chat/message-list-last_id)

last\_id

string

The identifier of the last chat message in the data array.

[](#chat/message-list-object)

object

string

The type of this object. It is always set to "list".

OBJECT The chat completion message list object
    {
      "object": "list",
      "data": [
        {
          "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
          "role": "user",
          "content": "write a haiku about ai",
          "name": null,
          "content_parts": null
        }
      ],
      "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
      "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
      "has_more": false
    }

Streaming


-------------

Stream Chat Completions in real time. Receive chunks of completions returned from the model using server-sent events. [Learn more](/docs/guides/streaming-responses?api-mode=chat).

The chat completion chunk object


------------------------------------

Represents a streamed chunk of a chat completion response returned by the model, based on the provided input. [Learn more](/docs/guides/streaming-responses).

[](#chat-streaming/streaming-choices)

choices

array

A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the last chunk if you set `stream_options: {"include_usage": true}`.

Show properties

[](#chat-streaming/streaming-created)

created

integer

The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.

[](#chat-streaming/streaming-id)

id

string

A unique identifier for the chat completion. Each chunk has the same ID.

[](#chat-streaming/streaming-model)

model

string

The model to generate the completion.

[](#chat-streaming/streaming-object)

object

string

The object type, which is always `chat.completion.chunk`.

[](#chat-streaming/streaming-service_tier)

service\_tier

string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

*   If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
*   If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
*   When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

[](#chat-streaming/streaming-system_fingerprint)

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

[](#chat-streaming/streaming-usage)

usage

object or null

Usage statistics for the completion request.

Show properties

OBJECT The chat completion chunk object
    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}
    
    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}
    
    ....
    
    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}

Realtime

Beta


------------------

Communicate with a GPT-4o class model in real time using WebRTC or WebSockets. Supports text and audio inputs and ouputs, along with audio transcriptions. [Learn more about the Realtime API](/docs/guides/realtime).

Session tokens


------------------

REST API endpoint to generate ephemeral session tokens for use in client-side applications.

Create session


------------------

postÂ https://api.openai.com/v1/realtime/sessions

Create an ephemeral API token for use in client-side applications with the Realtime API. Can be configured with the same session parameters as the `session.update` client event.

It responds with a session object, plus a `client_secret` key which contains a usable ephemeral API token that can be used to authenticate browser clients for the Realtime API.

#### Request body

[](#realtime-sessions-create-input_audio_format)

input\_audio\_format

string

Optional

Defaults to pcm16

The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel (mono), and little-endian byte order.

[](#realtime-sessions-create-input_audio_noise_reduction)

input\_audio\_noise\_reduction

object

Optional

Defaults to null

Configuration for input audio noise reduction. This can be set to `null` to turn off. Noise reduction filters audio added to the input audio buffer before it is sent to VAD and the model. Filtering the audio can improve VAD and turn detection accuracy (reducing false positives) and model performance by improving perception of the input audio.

Show properties

[](#realtime-sessions-create-input_audio_transcription)

input\_audio\_transcription

object

Optional

Configuration for input audio transcription, defaults to off and can be set to `null` to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs asynchronously through [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription) and should be treated as guidance of input audio content rather than precisely what the model heard. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.

Show properties

[](#realtime-sessions-create-instructions)

instructions

string

Optional

The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. "be extremely succinct", "act friendly", "here are examples of good responses") and on audio behavior (e.g. "talk quickly", "inject emotion into your voice", "laugh frequently"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.

Note that the server sets default instructions which will be used if this field is not set and are visible in the `session.created` event at the start of the session.

[](#realtime-sessions-create-max_response_output_tokens)

max\_response\_output\_tokens

integer or "inf"

Optional

Maximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or `inf` for the maximum available tokens for a given model. Defaults to `inf`.

[](#realtime-sessions-create-modalities)

modalities

Optional

The set of modalities the model can respond with. To disable audio, set this to \["text"\].

[](#realtime-sessions-create-model)

model

string

Optional

The Realtime model used for this session.

[](#realtime-sessions-create-output_audio_format)

output\_audio\_format

string

Optional

Defaults to pcm16

The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For `pcm16`, output audio is sampled at a rate of 24kHz.

[](#realtime-sessions-create-temperature)

temperature

number

Optional

Defaults to 0.8

Sampling temperature for the model, limited to \[0.6, 1.2\]. For audio models a temperature of 0.8 is highly recommended for best performance.

[](#realtime-sessions-create-tool_choice)

tool\_choice

string

Optional

Defaults to auto

How the model chooses tools. Options are `auto`, `none`, `required`, or specify a function.

[](#realtime-sessions-create-tools)

tools

array

Optional

Tools (functions) available to the model.

Show properties

[](#realtime-sessions-create-turn_detection)

turn\_detection

object

Optional

Configuration for turn detection, ether Server VAD or Semantic VAD. This can be set to `null` to turn off, in which case the client must manually trigger model response. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech. Semantic VAD is more advanced and uses a turn detection model (in conjuction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with "uhhm", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency.

Show properties

[](#realtime-sessions-create-voice)

voice

string

Optional

The voice the model uses to respond. Voice cannot be changed during the session once the model has responded with audio at least once. Current voice options are `alloy`, `ash`, `ballad`, `coral`, `echo`, `fable`, `onyx`, `nova`, `sage`, `shimmer`, and `verse`.

#### Returns

The created Realtime session object, plus an ephemeral key

Example request

curl
    curl -X POST https://api.openai.com/v1/realtime/sessions \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "gpt-4o-realtime-preview",
        "modalities": ["audio", "text"],
        "instructions": "You are a friendly assistant."
      }'

Response
    {
      "id": "sess_001",
      "object": "realtime.session",
      "model": "gpt-4o-realtime-preview",
      "modalities": ["audio", "text"],
      "instructions": "You are a friendly assistant.",
      "voice": "alloy",
      "input_audio_format": "pcm16",
      "output_audio_format": "pcm16",
      "input_audio_transcription": {
          "model": "whisper-1"
      },
      "turn_detection": null,
      "tools": [],
      "tool_choice": "none",
      "temperature": 0.7,
      "max_response_output_tokens": 200,
      "client_secret": {
        "value": "ek_abc123", 
        "expires_at": 1234567890
      }
    }

Create transcription session


--------------------------------

postÂ https://api.openai.com/v1/realtime/transcription\_sessions

Create an ephemeral API token for use in client-side applications with the Realtime API specifically for realtime transcriptions. Can be configured with the same session parameters as the `transcription_session.update` client event.

It responds with a session object, plus a `client_secret` key which contains a usable ephemeral API token that can be used to authenticate browser clients for the Realtime API.

#### Request body

[](#realtime-sessions-create-transcription-include)

include

array

Optional

The set of items to include in the transcription. Current available items are:

null.

[](#realtime-sessions-create-transcription-input_audio_format)

input\_audio\_format

string

Optional

Defaults to pcm16

The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel (mono), and little-endian byte order.

[](#realtime-sessions-create-transcription-input_audio_noise_reduction)

input\_audio\_noise\_reduction

object

Optional

Defaults to null

Configuration for input audio noise reduction. This can be set to `null` to turn off. Noise reduction filters audio added to the input audio buffer before it is sent to VAD and the model. Filtering the audio can improve VAD and turn detection accuracy (reducing false positives) and model performance by improving perception of the input audio.

Show properties

[](#realtime-sessions-create-transcription-input_audio_transcription)

input\_audio\_transcription

object

Optional

Configuration for input audio transcription. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.

Show properties

[](#realtime-sessions-create-transcription-modalities)

modalities

Optional

The set of modalities the model can respond with. To disable audio, set this to \["text"\].

[](#realtime-sessions-create-transcription-turn_detection)

turn\_detection

object

Optional

Configuration for turn detection, ether Server VAD or Semantic VAD. This can be set to `null` to turn off, in which case the client must manually trigger model response. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech. Semantic VAD is more advanced and uses a turn detection model (in conjuction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with "uhhm", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency.

Show properties

#### Returns

The created [Realtime transcription session object](/docs/api-reference/realtime-sessions/transcription_session_object), plus an ephemeral key

Example request

curl
    curl -X POST https://api.openai.com/v1/realtime/transcription_sessions \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{}'

Response
    {
      "id": "sess_BBwZc7cFV3XizEyKGDCGL",
      "object": "realtime.transcription_session",
      "modalities": ["audio", "text"],
      "turn_detection": {
        "type": "server_vad",
        "threshold": 0.5,
        "prefix_padding_ms": 300,
        "silence_duration_ms": 200
      },
      "input_audio_format": "pcm16",
      "input_audio_transcription": {
        "model": "gpt-4o-transcribe",
        "language": null,
        "prompt": ""
      },
      "client_secret": null
    }

The session object


----------------------

A new Realtime session configuration, with an ephermeral key. Default TTL for keys is one minute.

[](#realtime-sessions/session_object-client_secret)

client\_secret

object

Ephemeral key returned by the API.

Show properties

[](#realtime-sessions/session_object-input_audio_format)

input\_audio\_format

string

The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.

[](#realtime-sessions/session_object-input_audio_transcription)

input\_audio\_transcription

object

Configuration for input audio transcription, defaults to off and can be set to `null` to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs asynchronously through Whisper and should be treated as rough guidance rather than the representation understood by the model.

Show properties

[](#realtime-sessions/session_object-instructions)

instructions

string

The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. "be extremely succinct", "act friendly", "here are examples of good responses") and on audio behavior (e.g. "talk quickly", "inject emotion into your voice", "laugh frequently"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.

Note that the server sets default instructions which will be used if this field is not set and are visible in the `session.created` event at the start of the session.

[](#realtime-sessions/session_object-max_response_output_tokens)

max\_response\_output\_tokens

integer or "inf"

Maximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or `inf` for the maximum available tokens for a given model. Defaults to `inf`.

[](#realtime-sessions/session_object-modalities)

modalities

The set of modalities the model can respond with. To disable audio, set this to \["text"\].

[](#realtime-sessions/session_object-output_audio_format)

output\_audio\_format

string

The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.

[](#realtime-sessions/session_object-temperature)

temperature

number

Sampling temperature for the model, limited to \[0.6, 1.2\]. Defaults to 0.8.

[](#realtime-sessions/session_object-tool_choice)

tool\_choice

string

How the model chooses tools. Options are `auto`, `none`, `required`, or specify a function.

[](#realtime-sessions/session_object-tools)

tools

array

Tools (functions) available to the model.

Show properties

[](#realtime-sessions/session_object-turn_detection)

turn\_detection

object

Configuration for turn detection. Can be set to `null` to turn off. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.

Show properties

[](#realtime-sessions/session_object-voice)

voice

string

The voice the model uses to respond. Voice cannot be changed during the session once the model has responded with audio at least once. Current voice options are `alloy`, `ash`, `ballad`, `coral`, `echo` `sage`, `shimmer` and `verse`.

OBJECT The session object
    {
      "id": "sess_001",
      "object": "realtime.session",
      "model": "gpt-4o-realtime-preview",
      "modalities": ["audio", "text"],
      "instructions": "You are a friendly assistant.",
      "voice": "alloy",
      "input_audio_format": "pcm16",
      "output_audio_format": "pcm16",
      "input_audio_transcription": {
          "model": "whisper-1"
      },
      "turn_detection": null,
      "tools": [],
      "tool_choice": "none",
      "temperature": 0.7,
      "max_response_output_tokens": 200,
      "client_secret": {
        "value": "ek_abc123", 
        "expires_at": 1234567890
      }
    }

The transcription session object


------------------------------------

A new Realtime transcription session configuration.

When a session is created on the server via REST API, the session object also contains an ephemeral key. Default TTL for keys is one minute. This property is not present when a session is updated via the WebSocket API.

[](#realtime-sessions/transcription_session_object-client_secret)

client\_secret

object

Ephemeral key returned by the API. Only present when the session is created on the server via REST API.

Show properties

[](#realtime-sessions/transcription_session_object-input_audio_format)

input\_audio\_format

string

The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.

[](#realtime-sessions/transcription_session_object-input_audio_transcription)

input\_audio\_transcription

object

Configuration of the transcription model.

Show properties

[](#realtime-sessions/transcription_session_object-modalities)

modalities

The set of modalities the model can respond with. To disable audio, set this to \["text"\].

[](#realtime-sessions/transcription_session_object-turn_detection)

turn\_detection

object

Configuration for turn detection. Can be set to `null` to turn off. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.

Show properties

OBJECT The transcription session object
    {
      "id": "sess_BBwZc7cFV3XizEyKGDCGL",
      "object": "realtime.transcription_session",
      "expires_at": 1742188264,
      "modalities": ["audio", "text"],
      "turn_detection": {
        "type": "server_vad",
        "threshold": 0.5,
        "prefix_padding_ms": 300,
        "silence_duration_ms": 200
      },
      "input_audio_format": "pcm16",
      "input_audio_transcription": {
        "model": "gpt-4o-transcribe",
        "language": null,
        "prompt": ""
      },
      "client_secret": null
    }

Client events


-----------------

These are events that the OpenAI Realtime WebSocket server will accept from the client.

session.update


------------------

Send this event to update the sessionâs default configuration. The client may send this event at any time to update any field, except for `voice`. However, note that once a session has been initialized with a particular `model`, it canât be changed to another model using `session.update`.

When the server receives a `session.update`, it will respond with a `session.updated` event showing the full, effective configuration. Only the fields that are present are updated. To clear a field like `instructions`, pass an empty string.

[](#realtime-client-events/session/update-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/session/update-session)

session

object

Realtime session object configuration.

Show properties

[](#realtime-client-events/session/update-type)

type

string

The event type, must be `session.update`.

OBJECT session.update
    {
        "event_id": "event_123",
        "type": "session.update",
        "session": {
            "modalities": ["text", "audio"],
            "instructions": "You are a helpful assistant.",
            "voice": "sage",
            "input_audio_format": "pcm16",
            "output_audio_format": "pcm16",
            "input_audio_transcription": {
                "model": "whisper-1"
            },
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500,
                "create_response": true
            },
            "tools": [
                {
                    "type": "function",
                    "name": "get_weather",
                    "description": "Get the current weather...",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "location": { "type": "string" }
                        },
                        "required": ["location"]
                    }
                }
            ],
            "tool_choice": "auto",
            "temperature": 0.8,
            "max_response_output_tokens": "inf"
        }
    }

input\_audio\_buffer.append


-------------------------------

Send this event to append audio bytes to the input audio buffer. The audio buffer is temporary storage you can write to and later commit. In Server VAD mode, the audio buffer is used to detect speech and the server will decide when to commit. When Server VAD is disabled, you must commit the audio buffer manually.

The client may choose how much audio to place in each event up to a maximum of 15 MiB, for example streaming smaller chunks from the client may allow the VAD to be more responsive. Unlike made other client events, the server will not send a confirmation response to this event.

[](#realtime-client-events/input_audio_buffer/append-audio)

audio

string

Base64-encoded audio bytes. This must be in the format specified by the `input_audio_format` field in the session configuration.

[](#realtime-client-events/input_audio_buffer/append-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/input_audio_buffer/append-type)

type

string

The event type, must be `input_audio_buffer.append`.

OBJECT input\_audio\_buffer.append
    {
        "event_id": "event_456",
        "type": "input_audio_buffer.append",
        "audio": "Base64EncodedAudioData"
    }

input\_audio\_buffer.commit


-------------------------------

Send this event to commit the user input audio buffer, which will create a new user message item in the conversation. This event will produce an error if the input audio buffer is empty. When in Server VAD mode, the client does not need to send this event, the server will commit the audio buffer automatically.

Committing the input audio buffer will trigger input audio transcription (if enabled in session configuration), but it will not create a response from the model. The server will respond with an `input_audio_buffer.committed` event.

[](#realtime-client-events/input_audio_buffer/commit-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/input_audio_buffer/commit-type)

type

string

The event type, must be `input_audio_buffer.commit`.

OBJECT input\_audio\_buffer.commit
    {
        "event_id": "event_789",
        "type": "input_audio_buffer.commit"
    }

input\_audio\_buffer.clear


------------------------------

Send this event to clear the audio bytes in the buffer. The server will respond with an `input_audio_buffer.cleared` event.

[](#realtime-client-events/input_audio_buffer/clear-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/input_audio_buffer/clear-type)

type

string

The event type, must be `input_audio_buffer.clear`.

OBJECT input\_audio\_buffer.clear
    {
        "event_id": "event_012",
        "type": "input_audio_buffer.clear"
    }

conversation.item.create


----------------------------

Add a new Item to the Conversation's context, including messages, function calls, and function call responses. This event can be used both to populate a "history" of the conversation and to add new items mid-stream, but has the current limitation that it cannot populate assistant audio messages.

If successful, the server will respond with a `conversation.item.created` event, otherwise an `error` event will be sent.

[](#realtime-client-events/conversation/item/create-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/conversation/item/create-item)

item

object

The item to add to the conversation.

Show properties

[](#realtime-client-events/conversation/item/create-previous_item_id)

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted. If not set, the new item will be appended to the end of the conversation. If set to `root`, the new item will be added to the beginning of the conversation. If set to an existing ID, it allows an item to be inserted mid-conversation. If the ID cannot be found, an error will be returned and the item will not be added.

[](#realtime-client-events/conversation/item/create-type)

type

string

The event type, must be `conversation.item.create`.

OBJECT conversation.item.create
    {
        "event_id": "event_345",
        "type": "conversation.item.create",
        "previous_item_id": null,
        "item": {
            "id": "msg_001",
            "type": "message",
            "role": "user",
            "content": [
                {
                    "type": "input_text",
                    "text": "Hello, how are you?"
                }
            ]
        }
    }

conversation.item.retrieve


------------------------------

Send this event when you want to retrieve the server's representation of a specific item in the conversation history. This is useful, for example, to inspect user audio after noise cancellation and VAD. The server will respond with a `conversation.item.retrieved` event, unless the item does not exist in the conversation history, in which case the server will respond with an error.

[](#realtime-client-events/conversation/item/retrieve-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/conversation/item/retrieve-item_id)

item\_id

string

The ID of the item to retrieve.

[](#realtime-client-events/conversation/item/retrieve-type)

type

string

The event type, must be `conversation.item.retrieve`.

OBJECT conversation.item.retrieve
    {
        "event_id": "event_901",
        "type": "conversation.item.retrieve",
        "item_id": "msg_003"
    }

conversation.item.truncate


------------------------------

Send this event to truncate a previous assistant messageâs audio. The server will produce audio faster than realtime, so this event is useful when the user interrupts to truncate audio that has already been sent to the client but not yet played. This will synchronize the server's understanding of the audio with the client's playback.

Truncating audio will delete the server-side text transcript to ensure there is not text in the context that hasn't been heard by the user.

If successful, the server will respond with a `conversation.item.truncated` event.

[](#realtime-client-events/conversation/item/truncate-audio_end_ms)

audio\_end\_ms

integer

Inclusive duration up to which audio is truncated, in milliseconds. If the audio\_end\_ms is greater than the actual audio duration, the server will respond with an error.

[](#realtime-client-events/conversation/item/truncate-content_index)

content\_index

integer

The index of the content part to truncate. Set this to 0.

[](#realtime-client-events/conversation/item/truncate-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/conversation/item/truncate-item_id)

item\_id

string

The ID of the assistant message item to truncate. Only assistant message items can be truncated.

[](#realtime-client-events/conversation/item/truncate-type)

type

string

The event type, must be `conversation.item.truncate`.

OBJECT conversation.item.truncate
    {
        "event_id": "event_678",
        "type": "conversation.item.truncate",
        "item_id": "msg_002",
        "content_index": 0,
        "audio_end_ms": 1500
    }

conversation.item.delete


----------------------------

Send this event when you want to remove any item from the conversation history. The server will respond with a `conversation.item.deleted` event, unless the item does not exist in the conversation history, in which case the server will respond with an error.

[](#realtime-client-events/conversation/item/delete-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/conversation/item/delete-item_id)

item\_id

string

The ID of the item to delete.

[](#realtime-client-events/conversation/item/delete-type)

type

string

The event type, must be `conversation.item.delete`.

OBJECT conversation.item.delete
    {
        "event_id": "event_901",
        "type": "conversation.item.delete",
        "item_id": "msg_003"
    }

response.create


-------------------

This event instructs the server to create a Response, which means triggering model inference. When in Server VAD mode, the server will create Responses automatically.

A Response will include at least one Item, and may have two, in which case the second will be a function call. These Items will be appended to the conversation history.

The server will respond with a `response.created` event, events for Items and content created, and finally a `response.done` event to indicate the Response is complete.

The `response.create` event includes inference configuration like `instructions`, and `temperature`. These fields will override the Session's configuration for this Response only.

[](#realtime-client-events/response/create-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/response/create-response)

response

object

Create a new Realtime response with these parameters

Show properties

[](#realtime-client-events/response/create-type)

type

string

The event type, must be `response.create`.

OBJECT response.create
    {
        "event_id": "event_234",
        "type": "response.create",
        "response": {
            "modalities": ["text", "audio"],
            "instructions": "Please assist the user.",
            "voice": "sage",
            "output_audio_format": "pcm16",
            "tools": [
                {
                    "type": "function",
                    "name": "calculate_sum",
                    "description": "Calculates the sum of two numbers.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "a": { "type": "number" },
                            "b": { "type": "number" }
                        },
                        "required": ["a", "b"]
                    }
                }
            ],
            "tool_choice": "auto",
            "temperature": 0.8,
            "max_output_tokens": 1024
        }
    }

response.cancel


-------------------

Send this event to cancel an in-progress response. The server will respond with a `response.cancelled` event or an error if there is no response to cancel.

[](#realtime-client-events/response/cancel-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/response/cancel-response_id)

response\_id

string

A specific response ID to cancel - if not provided, will cancel an in-progress response in the default conversation.

[](#realtime-client-events/response/cancel-type)

type

string

The event type, must be `response.cancel`.

OBJECT response.cancel
    {
        "event_id": "event_567",
        "type": "response.cancel"
    }

transcription\_session.update


---------------------------------

Send this event to update a transcription session.

[](#realtime-client-events/transcription_session/update-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/transcription_session/update-session)

session

object

Realtime transcription session object configuration.

Show properties

[](#realtime-client-events/transcription_session/update-type)

type

string

The event type, must be `transcription_session.update`.

OBJECT transcription\_session.update
    {
      "type": "transcription_session.update",
      "session": {
        "input_audio_format": "pcm16",
        "input_audio_transcription": {
          "model": "gpt-4o-transcribe",
          "prompt": "",
          "language": ""
        },
        "turn_detection": {
          "type": "server_vad",
          "threshold": 0.5,
          "prefix_padding_ms": 300,
          "silence_duration_ms": 500,
          "create_response": true,
        },
        "input_audio_noise_reduction": {
          "type": "near_field"
        },
        "include": [
          "item.input_audio_transcription.logprobs",
        ]
      }
    }

output\_audio\_buffer.clear


-------------------------------

**WebRTC Only:** Emit to cut off the current audio response. This will trigger the server to stop generating audio and emit a `output_audio_buffer.cleared` event. This event should be preceded by a `response.cancel` client event to stop the generation of the current response. [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).

[](#realtime-client-events/output_audio_buffer/clear-event_id)

event\_id

string

The unique ID of the client event used for error handling.

[](#realtime-client-events/output_audio_buffer/clear-type)

type

string

The event type, must be `output_audio_buffer.clear`.

OBJECT output\_audio\_buffer.clear
    {
        "event_id": "optional_client_event_id",
        "type": "output_audio_buffer.clear"
    }

Server events


-----------------

These are events emitted from the OpenAI Realtime WebSocket server to the client.

error


---------

Returned when an error occurs, which could be a client problem or a server problem. Most errors are recoverable and the session will stay open, we recommend to implementors to monitor and log error messages by default.

[](#realtime-server-events/error-error)

error

object

Details of the error.

Show properties

[](#realtime-server-events/error-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/error-type)

type

string

The event type, must be `error`.

OBJECT error
    {
        "event_id": "event_890",
        "type": "error",
        "error": {
            "type": "invalid_request_error",
            "code": "invalid_event",
            "message": "The 'type' field is missing.",
            "param": null,
            "event_id": "event_567"
        }
    }

session.created


-------------------

Returned when a Session is created. Emitted automatically when a new connection is established as the first server event. This event will contain the default Session configuration.

[](#realtime-server-events/session/created-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/session/created-session)

session

object

Realtime session object configuration.

Show properties

[](#realtime-server-events/session/created-type)

type

string

The event type, must be `session.created`.

OBJECT session.created
    {
        "event_id": "event_1234",
        "type": "session.created",
        "session": {
            "id": "sess_001",
            "object": "realtime.session",
            "model": "gpt-4o-realtime-preview",
            "modalities": ["text", "audio"],
            "instructions": "...model instructions here...",
            "voice": "sage",
            "input_audio_format": "pcm16",
            "output_audio_format": "pcm16",
            "input_audio_transcription": null,
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 200
            },
            "tools": [],
            "tool_choice": "auto",
            "temperature": 0.8,
            "max_response_output_tokens": "inf"
        }
    }

session.updated


-------------------

Returned when a session is updated with a `session.update` event, unless there is an error.

[](#realtime-server-events/session/updated-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/session/updated-session)

session

object

Realtime session object configuration.

Show properties

[](#realtime-server-events/session/updated-type)

type

string

The event type, must be `session.updated`.

OBJECT session.updated
    {
        "event_id": "event_5678",
        "type": "session.updated",
        "session": {
            "id": "sess_001",
            "object": "realtime.session",
            "model": "gpt-4o-realtime-preview",
            "modalities": ["text"],
            "instructions": "New instructions",
            "voice": "sage",
            "input_audio_format": "pcm16",
            "output_audio_format": "pcm16",
            "input_audio_transcription": {
                "model": "whisper-1"
            },
            "turn_detection": null,
            "tools": [],
            "tool_choice": "none",
            "temperature": 0.7,
            "max_response_output_tokens": 200
        }
    }

conversation.created


------------------------

Returned when a conversation is created. Emitted right after session creation.

[](#realtime-server-events/conversation/created-conversation)

conversation

object

The conversation resource.

Show properties

[](#realtime-server-events/conversation/created-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/created-type)

type

string

The event type, must be `conversation.created`.

OBJECT conversation.created
    {
        "event_id": "event_9101",
        "type": "conversation.created",
        "conversation": {
            "id": "conv_001",
            "object": "realtime.conversation"
        }
    }

conversation.item.created


-----------------------------

Returned when a conversation item is created. There are several scenarios that produce this event:

*   The server is generating a Response, which if successful will produce either one or two Items, which will be of type `message` (role `assistant`) or type `function_call`.
*   The input audio buffer has been committed, either by the client or the server (in `server_vad` mode). The server will take the content of the input audio buffer and add it to a new user message Item.
*   The client has sent a `conversation.item.create` event to add a new Item to the Conversation.

[](#realtime-server-events/conversation/item/created-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/created-item)

item

object

The item to add to the conversation.

Show properties

[](#realtime-server-events/conversation/item/created-previous_item_id)

previous\_item\_id

string

The ID of the preceding item in the Conversation context, allows the client to understand the order of the conversation.

[](#realtime-server-events/conversation/item/created-type)

type

string

The event type, must be `conversation.item.created`.

OBJECT conversation.item.created
    {
        "event_id": "event_1920",
        "type": "conversation.item.created",
        "previous_item_id": "msg_002",
        "item": {
            "id": "msg_003",
            "object": "realtime.item",
            "type": "message",
            "status": "completed",
            "role": "user",
            "content": []
        }
    }

conversation.item.retrieved


-------------------------------

Returned when a conversation item is retrieved with `conversation.item.retrieve`.

[](#realtime-server-events/conversation/item/retrieved-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/retrieved-item)

item

object

The item to add to the conversation.

Show properties

[](#realtime-server-events/conversation/item/retrieved-type)

type

string

The event type, must be `conversation.item.retrieved`.

OBJECT conversation.item.retrieved
    {
        "event_id": "event_1920",
        "type": "conversation.item.created",
        "previous_item_id": "msg_002",
        "item": {
            "id": "msg_003",
            "object": "realtime.item",
            "type": "message",
            "status": "completed",
            "role": "user",
            "content": [
                {
                    "type": "input_audio",
                    "transcript": "hello how are you",
                    "audio": "base64encodedaudio=="
                }
            ]
        }
    }

conversation.item.input\_audio\_transcription.completed


-----------------------------------------------------------

This event is the output of audio transcription for user audio written to the user audio buffer. Transcription begins when the input audio buffer is committed by the client or server (in `server_vad` mode). Transcription runs asynchronously with Response creation, so this event may come before or after the Response events.

Realtime API models accept audio natively, and thus input transcription is a separate process run on a separate ASR (Automatic Speech Recognition) model, currently always `whisper-1`. Thus the transcript may diverge somewhat from the model's interpretation, and should be treated as a rough guide.

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-content_index)

content\_index

integer

The index of the content part containing the audio.

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-item_id)

item\_id

string

The ID of the user message item containing the audio.

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-logprobs)

logprobs

array or null

The log probabilities of the transcription.

Show properties

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-transcript)

transcript

string

The transcribed text.

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-type)

type

string

The event type, must be `conversation.item.input_audio_transcription.completed`.

OBJECT conversation.item.input\_audio\_transcription.completed
    {
        "event_id": "event_2122",
        "type": "conversation.item.input_audio_transcription.completed",
        "item_id": "msg_003",
        "content_index": 0,
        "transcript": "Hello, how are you?"
    }

conversation.item.input\_audio\_transcription.delta


-------------------------------------------------------

Returned when the text value of an input audio transcription content part is updated.

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-delta)

delta

string

The text delta.

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-logprobs)

logprobs

array or null

The log probabilities of the transcription.

Show properties

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-type)

type

string

The event type, must be `conversation.item.input_audio_transcription.delta`.

OBJECT conversation.item.input\_audio\_transcription.delta
    {
      "type": "conversation.item.input_audio_transcription.delta",
      "event_id": "event_001",
      "item_id": "item_001",
      "content_index": 0,
      "delta": "Hello"
    }

conversation.item.input\_audio\_transcription.failed


--------------------------------------------------------

Returned when input audio transcription is configured, and a transcription request for a user message failed. These events are separate from other `error` events so that the client can identify the related Item.

[](#realtime-server-events/conversation/item/input_audio_transcription/failed-content_index)

content\_index

integer

The index of the content part containing the audio.

[](#realtime-server-events/conversation/item/input_audio_transcription/failed-error)

error

object

Details of the transcription error.

Show properties

[](#realtime-server-events/conversation/item/input_audio_transcription/failed-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/input_audio_transcription/failed-item_id)

item\_id

string

The ID of the user message item.

[](#realtime-server-events/conversation/item/input_audio_transcription/failed-type)

type

string

The event type, must be `conversation.item.input_audio_transcription.failed`.

OBJECT conversation.item.input\_audio\_transcription.failed
    {
        "event_id": "event_2324",
        "type": "conversation.item.input_audio_transcription.failed",
        "item_id": "msg_003",
        "content_index": 0,
        "error": {
            "type": "transcription_error",
            "code": "audio_unintelligible",
            "message": "The audio could not be transcribed.",
            "param": null
        }
    }

conversation.item.truncated


-------------------------------

Returned when an earlier assistant audio message item is truncated by the client with a `conversation.item.truncate` event. This event is used to synchronize the server's understanding of the audio with the client's playback.

This action will truncate the audio and remove the server-side text transcript to ensure there is no text in the context that hasn't been heard by the user.

[](#realtime-server-events/conversation/item/truncated-audio_end_ms)

audio\_end\_ms

integer

The duration up to which the audio was truncated, in milliseconds.

[](#realtime-server-events/conversation/item/truncated-content_index)

content\_index

integer

The index of the content part that was truncated.

[](#realtime-server-events/conversation/item/truncated-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/truncated-item_id)

item\_id

string

The ID of the assistant message item that was truncated.

[](#realtime-server-events/conversation/item/truncated-type)

type

string

The event type, must be `conversation.item.truncated`.

OBJECT conversation.item.truncated
    {
        "event_id": "event_2526",
        "type": "conversation.item.truncated",
        "item_id": "msg_004",
        "content_index": 0,
        "audio_end_ms": 1500
    }

conversation.item.deleted


-----------------------------

Returned when an item in the conversation is deleted by the client with a `conversation.item.delete` event. This event is used to synchronize the server's understanding of the conversation history with the client's view.

[](#realtime-server-events/conversation/item/deleted-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/deleted-item_id)

item\_id

string

The ID of the item that was deleted.

[](#realtime-server-events/conversation/item/deleted-type)

type

string

The event type, must be `conversation.item.deleted`.

OBJECT conversation.item.deleted
    {
        "event_id": "event_2728",
        "type": "conversation.item.deleted",
        "item_id": "msg_005"
    }

input\_audio\_buffer.committed


----------------------------------

Returned when an input audio buffer is committed, either by the client or automatically in server VAD mode. The `item_id` property is the ID of the user message item that will be created, thus a `conversation.item.created` event will also be sent to the client.

[](#realtime-server-events/input_audio_buffer/committed-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/input_audio_buffer/committed-item_id)

item\_id

string

The ID of the user message item that will be created.

[](#realtime-server-events/input_audio_buffer/committed-previous_item_id)

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.

[](#realtime-server-events/input_audio_buffer/committed-type)

type

string

The event type, must be `input_audio_buffer.committed`.

OBJECT input\_audio\_buffer.committed
    {
        "event_id": "event_1121",
        "type": "input_audio_buffer.committed",
        "previous_item_id": "msg_001",
        "item_id": "msg_002"
    }

input\_audio\_buffer.cleared


--------------------------------

Returned when the input audio buffer is cleared by the client with a `input_audio_buffer.clear` event.

[](#realtime-server-events/input_audio_buffer/cleared-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/input_audio_buffer/cleared-type)

type

string

The event type, must be `input_audio_buffer.cleared`.

OBJECT input\_audio\_buffer.cleared
    {
        "event_id": "event_1314",
        "type": "input_audio_buffer.cleared"
    }

input\_audio\_buffer.speech\_started


----------------------------------------

Sent by the server when in `server_vad` mode to indicate that speech has been detected in the audio buffer. This can happen any time audio is added to the buffer (unless speech is already detected). The client may want to use this event to interrupt audio playback or provide visual feedback to the user.

The client should expect to receive a `input_audio_buffer.speech_stopped` event when speech stops. The `item_id` property is the ID of the user message item that will be created when speech stops and will also be included in the `input_audio_buffer.speech_stopped` event (unless the client manually commits the audio buffer during VAD activation).

[](#realtime-server-events/input_audio_buffer/speech_started-audio_start_ms)

audio\_start\_ms

integer

Milliseconds from the start of all audio written to the buffer during the session when speech was first detected. This will correspond to the beginning of audio sent to the model, and thus includes the `prefix_padding_ms` configured in the Session.

[](#realtime-server-events/input_audio_buffer/speech_started-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/input_audio_buffer/speech_started-item_id)

item\_id

string

The ID of the user message item that will be created when speech stops.

[](#realtime-server-events/input_audio_buffer/speech_started-type)

type

string

The event type, must be `input_audio_buffer.speech_started`.

OBJECT input\_audio\_buffer.speech\_started
    {
        "event_id": "event_1516",
        "type": "input_audio_buffer.speech_started",
        "audio_start_ms": 1000,
        "item_id": "msg_003"
    }

input\_audio\_buffer.speech\_stopped


----------------------------------------

Returned in `server_vad` mode when the server detects the end of speech in the audio buffer. The server will also send an `conversation.item.created` event with the user message item that is created from the audio buffer.

[](#realtime-server-events/input_audio_buffer/speech_stopped-audio_end_ms)

audio\_end\_ms

integer

Milliseconds since the session started when speech stopped. This will correspond to the end of audio sent to the model, and thus includes the `min_silence_duration_ms` configured in the Session.

[](#realtime-server-events/input_audio_buffer/speech_stopped-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/input_audio_buffer/speech_stopped-item_id)

item\_id

string

The ID of the user message item that will be created.

[](#realtime-server-events/input_audio_buffer/speech_stopped-type)

type

string

The event type, must be `input_audio_buffer.speech_stopped`.

OBJECT input\_audio\_buffer.speech\_stopped
    {
        "event_id": "event_1718",
        "type": "input_audio_buffer.speech_stopped",
        "audio_end_ms": 2000,
        "item_id": "msg_003"
    }

response.created


--------------------

Returned when a new Response is created. The first event of response creation, where the response is in an initial state of `in_progress`.

[](#realtime-server-events/response/created-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/created-response)

response

object

The response resource.

Show properties

[](#realtime-server-events/response/created-type)

type

string

The event type, must be `response.created`.

OBJECT response.created
    {
        "event_id": "event_2930",
        "type": "response.created",
        "response": {
            "id": "resp_001",
            "object": "realtime.response",
            "status": "in_progress",
            "status_details": null,
            "output": [],
            "usage": null
        }
    }

response.done


-----------------

Returned when a Response is done streaming. Always emitted, no matter the final state. The Response object included in the `response.done` event will include all output Items in the Response but will omit the raw audio data.

[](#realtime-server-events/response/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/done-response)

response

object

The response resource.

Show properties

[](#realtime-server-events/response/done-type)

type

string

The event type, must be `response.done`.

OBJECT response.done
    {
        "event_id": "event_3132",
        "type": "response.done",
        "response": {
            "id": "resp_001",
            "object": "realtime.response",
            "status": "completed",
            "status_details": null,
            "output": [
                {
                    "id": "msg_006",
                    "object": "realtime.item",
                    "type": "message",
                    "status": "completed",
                    "role": "assistant",
                    "content": [
                        {
                            "type": "text",
                            "text": "Sure, how can I assist you today?"
                        }
                    ]
                }
            ],
            "usage": {
                "total_tokens":275,
                "input_tokens":127,
                "output_tokens":148,
                "input_token_details": {
                    "cached_tokens":384,
                    "text_tokens":119,
                    "audio_tokens":8,
                    "cached_tokens_details": {
                        "text_tokens": 128,
                        "audio_tokens": 256
                    }
                },
                "output_token_details": {
                  "text_tokens":36,
                  "audio_tokens":112
                }
            }
        }
    }

response.output\_item.added


-------------------------------

Returned when a new Item is created during Response generation.

[](#realtime-server-events/response/output_item/added-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/output_item/added-item)

item

object

The item to add to the conversation.

Show properties

[](#realtime-server-events/response/output_item/added-output_index)

output\_index

integer

The index of the output item in the Response.

[](#realtime-server-events/response/output_item/added-response_id)

response\_id

string

The ID of the Response to which the item belongs.

[](#realtime-server-events/response/output_item/added-type)

type

string

The event type, must be `response.output_item.added`.

OBJECT response.output\_item.added
    {
        "event_id": "event_3334",
        "type": "response.output_item.added",
        "response_id": "resp_001",
        "output_index": 0,
        "item": {
            "id": "msg_007",
            "object": "realtime.item",
            "type": "message",
            "status": "in_progress",
            "role": "assistant",
            "content": []
        }
    }

response.output\_item.done


------------------------------

Returned when an Item is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/output_item/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/output_item/done-item)

item

object

The item to add to the conversation.

Show properties

[](#realtime-server-events/response/output_item/done-output_index)

output\_index

integer

The index of the output item in the Response.

[](#realtime-server-events/response/output_item/done-response_id)

response\_id

string

The ID of the Response to which the item belongs.

[](#realtime-server-events/response/output_item/done-type)

type

string

The event type, must be `response.output_item.done`.

OBJECT response.output\_item.done
    {
        "event_id": "event_3536",
        "type": "response.output_item.done",
        "response_id": "resp_001",
        "output_index": 0,
        "item": {
            "id": "msg_007",
            "object": "realtime.item",
            "type": "message",
            "status": "completed",
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "Sure, I can help with that."
                }
            ]
        }
    }

response.content\_part.added


--------------------------------

Returned when a new content part is added to an assistant message item during response generation.

[](#realtime-server-events/response/content_part/added-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/content_part/added-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/content_part/added-item_id)

item\_id

string

The ID of the item to which the content part was added.

[](#realtime-server-events/response/content_part/added-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/content_part/added-part)

part

object

The content part that was added.

Show properties

[](#realtime-server-events/response/content_part/added-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/content_part/added-type)

type

string

The event type, must be `response.content_part.added`.

OBJECT response.content\_part.added
    {
        "event_id": "event_3738",
        "type": "response.content_part.added",
        "response_id": "resp_001",
        "item_id": "msg_007",
        "output_index": 0,
        "content_index": 0,
        "part": {
            "type": "text",
            "text": ""
        }
    }

response.content\_part.done


-------------------------------

Returned when a content part is done streaming in an assistant message item. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/content_part/done-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/content_part/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/content_part/done-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/content_part/done-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/content_part/done-part)

part

object

The content part that is done.

Show properties

[](#realtime-server-events/response/content_part/done-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/content_part/done-type)

type

string

The event type, must be `response.content_part.done`.

OBJECT response.content\_part.done
    {
        "event_id": "event_3940",
        "type": "response.content_part.done",
        "response_id": "resp_001",
        "item_id": "msg_007",
        "output_index": 0,
        "content_index": 0,
        "part": {
            "type": "text",
            "text": "Sure, I can help with that."
        }
    }

response.text.delta


-----------------------

Returned when the text value of a "text" content part is updated.

[](#realtime-server-events/response/text/delta-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/text/delta-delta)

delta

string

The text delta.

[](#realtime-server-events/response/text/delta-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/text/delta-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/text/delta-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/text/delta-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/text/delta-type)

type

string

The event type, must be `response.text.delta`.

OBJECT response.text.delta
    {
        "event_id": "event_4142",
        "type": "response.text.delta",
        "response_id": "resp_001",
        "item_id": "msg_007",
        "output_index": 0,
        "content_index": 0,
        "delta": "Sure, I can h"
    }

response.text.done


----------------------

Returned when the text value of a "text" content part is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/text/done-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/text/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/text/done-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/text/done-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/text/done-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/text/done-text)

text

string

The final text content.

[](#realtime-server-events/response/text/done-type)

type

string

The event type, must be `response.text.done`.

OBJECT response.text.done
    {
        "event_id": "event_4344",
        "type": "response.text.done",
        "response_id": "resp_001",
        "item_id": "msg_007",
        "output_index": 0,
        "content_index": 0,
        "text": "Sure, I can help with that."
    }

response.audio\_transcript.delta


------------------------------------

Returned when the model-generated transcription of audio output is updated.

[](#realtime-server-events/response/audio_transcript/delta-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/audio_transcript/delta-delta)

delta

string

The transcript delta.

[](#realtime-server-events/response/audio_transcript/delta-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/audio_transcript/delta-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/audio_transcript/delta-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/audio_transcript/delta-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/audio_transcript/delta-type)

type

string

The event type, must be `response.audio_transcript.delta`.

OBJECT response.audio\_transcript.delta
    {
        "event_id": "event_4546",
        "type": "response.audio_transcript.delta",
        "response_id": "resp_001",
        "item_id": "msg_008",
        "output_index": 0,
        "content_index": 0,
        "delta": "Hello, how can I a"
    }

response.audio\_transcript.done


-----------------------------------

Returned when the model-generated transcription of audio output is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/audio_transcript/done-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/audio_transcript/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/audio_transcript/done-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/audio_transcript/done-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/audio_transcript/done-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/audio_transcript/done-transcript)

transcript

string

The final transcript of the audio.

[](#realtime-server-events/response/audio_transcript/done-type)

type

string

The event type, must be `response.audio_transcript.done`.

OBJECT response.audio\_transcript.done
    {
        "event_id": "event_4748",
        "type": "response.audio_transcript.done",
        "response_id": "resp_001",
        "item_id": "msg_008",
        "output_index": 0,
        "content_index": 0,
        "transcript": "Hello, how can I assist you today?"
    }

response.audio.delta


------------------------

Returned when the model-generated audio is updated.

[](#realtime-server-events/response/audio/delta-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/audio/delta-delta)

delta

string

Base64-encoded audio data delta.

[](#realtime-server-events/response/audio/delta-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/audio/delta-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/audio/delta-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/audio/delta-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/audio/delta-type)

type

string

The event type, must be `response.audio.delta`.

OBJECT response.audio.delta
    {
        "event_id": "event_4950",
        "type": "response.audio.delta",
        "response_id": "resp_001",
        "item_id": "msg_008",
        "output_index": 0,
        "content_index": 0,
        "delta": "Base64EncodedAudioDelta"
    }

response.audio.done


-----------------------

Returned when the model-generated audio is done. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/audio/done-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/audio/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/audio/done-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/audio/done-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/audio/done-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/audio/done-type)

type

string

The event type, must be `response.audio.done`.

OBJECT response.audio.done
    {
        "event_id": "event_5152",
        "type": "response.audio.done",
        "response_id": "resp_001",
        "item_id": "msg_008",
        "output_index": 0,
        "content_index": 0
    }

response.function\_call\_arguments.delta


--------------------------------------------

Returned when the model-generated function call arguments are updated.

[](#realtime-server-events/response/function_call_arguments/delta-call_id)

call\_id

string

The ID of the function call.

[](#realtime-server-events/response/function_call_arguments/delta-delta)

delta

string

The arguments delta as a JSON string.

[](#realtime-server-events/response/function_call_arguments/delta-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/function_call_arguments/delta-item_id)

item\_id

string

The ID of the function call item.

[](#realtime-server-events/response/function_call_arguments/delta-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/function_call_arguments/delta-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/function_call_arguments/delta-type)

type

string

The event type, must be `response.function_call_arguments.delta`.

OBJECT response.function\_call\_arguments.delta
    {
        "event_id": "event_5354",
        "type": "response.function_call_arguments.delta",
        "response_id": "resp_002",
        "item_id": "fc_001",
        "output_index": 0,
        "call_id": "call_001",
        "delta": "{\"location\": \"San\""
    }

response.function\_call\_arguments.done


-------------------------------------------

Returned when the model-generated function call arguments are done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/function_call_arguments/done-arguments)

arguments

string

The final arguments as a JSON string.

[](#realtime-server-events/response/function_call_arguments/done-call_id)

call\_id

string

The ID of the function call.

[](#realtime-server-events/response/function_call_arguments/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/function_call_arguments/done-item_id)

item\_id

string

The ID of the function call item.

[](#realtime-server-events/response/function_call_arguments/done-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/function_call_arguments/done-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/function_call_arguments/done-type)

type

string

The event type, must be `response.function_call_arguments.done`.

OBJECT response.function\_call\_arguments.done
    {
        "event_id": "event_5556",
        "type": "response.function_call_arguments.done",
        "response_id": "resp_002",
        "item_id": "fc_001",
        "output_index": 0,
        "call_id": "call_001",
        "arguments": "{\"location\": \"San Francisco\"}"
    }

transcription\_session.updated


----------------------------------

Returned when a transcription session is updated with a `transcription_session.update` event, unless there is an error.

[](#realtime-server-events/transcription_session/updated-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/transcription_session/updated-session)

session

object

A new Realtime transcription session configuration.

When a session is created on the server via REST API, the session object also contains an ephemeral key. Default TTL for keys is one minute. This property is not present when a session is updated via the WebSocket API.

Show properties

[](#realtime-server-events/transcription_session/updated-type)

type

string

The event type, must be `transcription_session.updated`.

OBJECT transcription\_session.updated
    {
      "event_id": "event_5678",
      "type": "transcription_session.updated",
      "session": {
        "id": "sess_001",
        "object": "realtime.transcription_session",
        "input_audio_format": "pcm16",
        "input_audio_transcription": {
          "model": "gpt-4o-transcribe",
          "prompt": "",
          "language": ""
        },
        "turn_detection": {
          "type": "server_vad",
          "threshold": 0.5,
          "prefix_padding_ms": 300,
          "silence_duration_ms": 500,
          "create_response": true,
          // "interrupt_response": false  -- this will NOT be returned
        },
        "input_audio_noise_reduction": {
          "type": "near_field"
        },
        "include": [
          "item.input_audio_transcription.avg_logprob",
        ],
      }
    }

rate\_limits.updated


------------------------

Emitted at the beginning of a Response to indicate the updated rate limits. When a Response is created some tokens will be "reserved" for the output tokens, the rate limits shown here reflect that reservation, which is then adjusted accordingly once the Response is completed.

[](#realtime-server-events/rate_limits/updated-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/rate_limits/updated-rate_limits)

rate\_limits

array

List of rate limit information.

Show properties

[](#realtime-server-events/rate_limits/updated-type)

type

string

The event type, must be `rate_limits.updated`.

OBJECT rate\_limits.updated
    {
        "event_id": "event_5758",
        "type": "rate_limits.updated",
        "rate_limits": [
            {
                "name": "requests",
                "limit": 1000,
                "remaining": 999,
                "reset_seconds": 60
            },
            {
                "name": "tokens",
                "limit": 50000,
                "remaining": 49950,
                "reset_seconds": 60
            }
        ]
    }

output\_audio\_buffer.started


---------------------------------

**WebRTC Only:** Emitted when the server begins streaming audio to the client. This event is emitted after an audio content part has been added (`response.content_part.added`) to the response. [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).

[](#realtime-server-events/output_audio_buffer/started-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/output_audio_buffer/started-response_id)

response\_id

string

The unique ID of the response that produced the audio.

[](#realtime-server-events/output_audio_buffer/started-type)

type

string

The event type, must be `output_audio_buffer.started`.

OBJECT output\_audio\_buffer.started
    {
        "event_id": "event_abc123",
        "type": "output_audio_buffer.started",
        "response_id": "resp_abc123"
    }

output\_audio\_buffer.stopped


---------------------------------

**WebRTC Only:** Emitted when the output audio buffer has been completely drained on the server, and no more audio is forthcoming. This event is emitted after the full response data has been sent to the client (`response.done`). [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).

[](#realtime-server-events/output_audio_buffer/stopped-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/output_audio_buffer/stopped-response_id)

response\_id

string

The unique ID of the response that produced the audio.

[](#realtime-server-events/output_audio_buffer/stopped-type)

type

string

The event type, must be `output_audio_buffer.stopped`.

OBJECT output\_audio\_buffer.stopped
    {
        "event_id": "event_abc123",
        "type": "output_audio_buffer.stopped",
        "response_id": "resp_abc123"
    }

output\_audio\_buffer.cleared


---------------------------------

**WebRTC Only:** Emitted when the output audio buffer is cleared. This happens either in VAD mode when the user has interrupted (`input_audio_buffer.speech_started`), or when the client has emitted the `output_audio_buffer.clear` event to manually cut off the current audio response. [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).

[](#realtime-server-events/output_audio_buffer/cleared-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/output_audio_buffer/cleared-response_id)

response\_id

string

The unique ID of the response that produced the audio.

[](#realtime-server-events/output_audio_buffer/cleared-type)

type

string

The event type, must be `output_audio_buffer.cleared`.

OBJECT output\_audio\_buffer.cleared
    {
        "event_id": "event_abc123",
        "type": "output_audio_buffer.cleared",
        "response_id": "resp_abc123"
    }

Audio


---------

Learn how to turn audio into text or text into audio.

Related guide: [Speech to text](/docs/guides/speech-to-text)

Create speech


-----------------

postÂ https://api.openai.com/v1/audio/speech

Generates audio from the input text.

#### Request body

[](#audio-createspeech-input)

input

string

Required

The text to generate audio for. The maximum length is 4096 characters.

[](#audio-createspeech-model)

model

string

Required

One of the available [TTS models](/docs/models#tts): `tts-1`, `tts-1-hd` or `gpt-4o-mini-tts`.

[](#audio-createspeech-voice)

voice

string

Required

The voice to use when generating the audio. Supported voices are `alloy`, `ash`, `ballad`, `coral`, `echo`, `fable`, `onyx`, `nova`, `sage`, `shimmer`, and `verse`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech#voice-options).

[](#audio-createspeech-instructions)

instructions

string

Optional

Control the voice of your generated audio with additional instructions. Does not work with `tts-1` or `tts-1-hd`.

[](#audio-createspeech-response_format)

response\_format

string

Optional

Defaults to mp3

The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.

[](#audio-createspeech-speed)

speed

number

Optional

Defaults to 1

The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default. Does not work with `gpt-4o-mini-tts`.

#### Returns

The audio file content.

Example request

curl
    curl https://api.openai.com/v1/audio/speech \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "gpt-4o-mini-tts",
        "input": "The quick brown fox jumped over the lazy dog.",
        "voice": "alloy"
      }' \
      --output speech.mp3
    from pathlib import Path
    import openai
    
    speech_file_path = Path(__file__).parent / "speech.mp3"
    with openai.audio.speech.with_streaming_response.create(
      model="gpt-4o-mini-tts",
      voice="alloy",
      input="The quick brown fox jumped over the lazy dog."
    ) as response:
      response.stream_to_file(speech_file_path)
    import fs from "fs";
    import path from "path";
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    const speechFile = path.resolve("./speech.mp3");
    
    async function main() {
      const mp3 = await openai.audio.speech.create({
        model: "gpt-4o-mini-tts",
        voice: "alloy",
        input: "Today is a wonderful day to build something people love!",
      });
      console.log(speechFile);
      const buffer = Buffer.from(await mp3.arrayBuffer());
      await fs.promises.writeFile(speechFile, buffer);
    }
    main();
    using System;
    using System.IO;
    
    using OpenAI.Audio;
    
    AudioClient client = new(
        model: "gpt-4o-mini-tts",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    BinaryData speech = client.GenerateSpeech(
        text: "The quick brown fox jumped over the lazy dog.",
        voice: GeneratedSpeechVoice.Alloy
    );
    
    using FileStream stream = File.OpenWrite("speech.mp3");
    speech.ToStream().CopyTo(stream);

Create transcription


------------------------

postÂ https://api.openai.com/v1/audio/transcriptions

Transcribes audio into the input language.

#### Request body

[](#audio-createtranscription-file)

file

file

Required

The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

[](#audio-createtranscription-model)

model

string

Required

ID of the model to use. The options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1` (which is powered by our open source Whisper V2 model).

[](#audio-createtranscription-chunking_strategy)

chunking\_strategy

"auto" or object

Optional

Controls how the audio is cut into chunks. When set to `"auto"`, the server first normalizes loudness and then uses voice activity detection (VAD) to choose boundaries. `server_vad` object can be provided to tweak VAD detection parameters manually. If unset, the audio is transcribed as a single block.

Show possible types

[](#audio-createtranscription-include)

include\[\]

array

Optional

Additional information to include in the transcription response. `logprobs` will return the log probabilities of the tokens in the response to understand the model's confidence in the transcription. `logprobs` only works with response\_format set to `json` and only with the models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`.

[](#audio-createtranscription-language)

language

string

Optional

The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format will improve accuracy and latency.

[](#audio-createtranscription-prompt)

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.

[](#audio-createtranscription-response_format)

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`. For `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`, the only supported format is `json`.

[](#audio-createtranscription-stream)

stream

boolean or null

Optional

Defaults to false

If set to true, the model response data will be streamed to the client as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format). See the [Streaming section of the Speech-to-Text guide](/docs/guides/speech-to-text?lang=curl#streaming-transcriptions) for more information.

Note: Streaming is not supported for the `whisper-1` model and will be ignored.

[](#audio-createtranscription-temperature)

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

[](#audio-createtranscription-timestamp_granularities)

timestamp\_granularities\[\]

array

Optional

Defaults to segment

The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

#### Returns

The [transcription object](/docs/api-reference/audio/json-object), a [verbose transcription object](/docs/api-reference/audio/verbose-json-object) or a [stream of transcript events](/docs/api-reference/audio/transcript-text-delta-event).

DefaultDefaultStreamingStreamingLogprobsLogprobsWord timestampsWord timestampsSegment timestampsSegment timestamps

Example request

curl
    curl https://api.openai.com/v1/audio/transcriptions \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: multipart/form-data" \
      -F file="@/path/to/file/audio.mp3" \
      -F model="gpt-4o-transcribe"
    from openai import OpenAI
    client = OpenAI()
    
    audio_file = open("speech.mp3", "rb")
    transcript = client.audio.transcriptions.create(
      model="gpt-4o-transcribe",
      file=audio_file
    )
    import fs from "fs";
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const transcription = await openai.audio.transcriptions.create({
        file: fs.createReadStream("audio.mp3"),
        model: "gpt-4o-transcribe",
      });
    
      console.log(transcription.text);
    }
    main();
    using System;
    
    using OpenAI.Audio;
    string audioFilePath = "audio.mp3";
    
    AudioClient client = new(
        model: "gpt-4o-transcribe",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    AudioTranscription transcription = client.TranscribeAudio(audioFilePath);
    
    Console.WriteLine($"{transcription.Text}");

Response
    {
      "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
    }

Create translation


----------------------

postÂ https://api.openai.com/v1/audio/translations

Translates audio into English.

#### Request body

[](#audio-createtranslation-file)

file

file

Required

The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

[](#audio-createtranslation-model)

model

string or "whisper-1"

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

[](#audio-createtranslation-prompt)

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English.

[](#audio-createtranslation-response_format)

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

[](#audio-createtranslation-temperature)

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

#### Returns

The translated text.

Example request

curl
    curl https://api.openai.com/v1/audio/translations \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: multipart/form-data" \
      -F file="@/path/to/file/german.m4a" \
      -F model="whisper-1"
    from openai import OpenAI
    client = OpenAI()
    
    audio_file = open("speech.mp3", "rb")
    transcript = client.audio.translations.create(
      model="whisper-1",
      file=audio_file
    )
    import fs from "fs";
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
        const translation = await openai.audio.translations.create({
            file: fs.createReadStream("speech.mp3"),
            model: "whisper-1",
        });
    
        console.log(translation.text);
    }
    main();
    using System;
    
    using OpenAI.Audio;
    
    string audioFilePath = "audio.mp3";
    
    AudioClient client = new(
        model: "whisper-1",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    AudioTranscription transcription = client.TranscribeAudio(audioFilePath);
    
    Console.WriteLine($"{transcription.Text}");

Response
    {
      "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
    }

The transcription object (JSON)


-----------------------------------

Represents a transcription response returned by model, based on the provided input.

[](#audio/json-object-logprobs)

logprobs

array

The log probabilities of the tokens in the transcription. Only returned with the models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe` if `logprobs` is added to the `include` array.

Show properties

[](#audio/json-object-text)

text

string

The transcribed text.

OBJECT The transcription object (JSON)
    {
      "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
    }

The transcription object (Verbose JSON)


-------------------------------------------

Represents a verbose json transcription response returned by model, based on the provided input.

[](#audio/verbose-json-object-duration)

duration

number

The duration of the input audio.

[](#audio/verbose-json-object-language)

language

string

The language of the input audio.

[](#audio/verbose-json-object-segments)

segments

array

Segments of the transcribed text and their corresponding details.

Show properties

[](#audio/verbose-json-object-text)

text

string

The transcribed text.

[](#audio/verbose-json-object-words)

words

array

Extracted words and their corresponding timestamps.

Show properties

OBJECT The transcription object (Verbose JSON)
    {
      "task": "transcribe",
      "language": "english",
      "duration": 8.470000267028809,
      "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.319999933242798,
          "text": " The beach was a popular spot on a hot summer day.",
          "tokens": [
            50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2860786020755768,
          "compression_ratio": 1.2363636493682861,
          "no_speech_prob": 0.00985979475080967
        },
        ...
      ]
    }

Stream Event (transcript.text.delta)


----------------------------------------

Emitted when there is an additional text delta. This is also the first event emitted when the transcription starts. Only emitted when you [create a transcription](/docs/api-reference/audio/create-transcription) with the `Stream` parameter set to `true`.

[](#audio/transcript-text-delta-event-delta)

delta

string

The text delta that was additionally transcribed.

[](#audio/transcript-text-delta-event-logprobs)

logprobs

array

The log probabilities of the delta. Only included if you [create a transcription](/docs/api-reference/audio/create-transcription) with the `include[]` parameter set to `logprobs`.

Show properties

[](#audio/transcript-text-delta-event-type)

type

string

The type of the event. Always `transcript.text.delta`.

OBJECT Stream Event (transcript.text.delta)
    {
      "type": "transcript.text.delta",
      "delta": " wonderful"
    }

Stream Event (transcript.text.done)


---------------------------------------

Emitted when the transcription is complete. Contains the complete transcription text. Only emitted when you [create a transcription](/docs/api-reference/audio/create-transcription) with the `Stream` parameter set to `true`.

[](#audio/transcript-text-done-event-logprobs)

logprobs

array

The log probabilities of the individual tokens in the transcription. Only included if you [create a transcription](/docs/api-reference/audio/create-transcription) with the `include[]` parameter set to `logprobs`.

Show properties

[](#audio/transcript-text-done-event-text)

text

string

The text that was transcribed.

[](#audio/transcript-text-done-event-type)

type

string

The type of the event. Always `transcript.text.done`.

OBJECT Stream Event (transcript.text.done)
    {
      "type": "transcript.text.done",
      "text": "I see skies of blue and clouds of white, the bright blessed days, the dark sacred nights, and I think to myself, what a wonderful world."
    }

Images


----------

Given a prompt and/or an input image, the model will generate a new image. Related guide: [Image generation](/docs/guides/images)

Create image


----------------

postÂ https://api.openai.com/v1/images/generations

Creates an image given a prompt. [Learn more](/docs/guides/images).

#### Request body

[](#images-create-prompt)

prompt

string

Required

A text description of the desired image(s). The maximum length is 32000 characters for `gpt-image-1`, 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.

[](#images-create-background)

background

string or null

Optional

Defaults to auto

Allows to set transparency for the background of the generated image(s). This parameter is only supported for `gpt-image-1`. Must be one of `transparent`, `opaque` or `auto` (default value). When `auto` is used, the model will automatically determine the best background for the image.

If `transparent`, the output format needs to support transparency, so it should be set to either `png` (default value) or `webp`.

[](#images-create-model)

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. One of `dall-e-2`, `dall-e-3`, or `gpt-image-1`. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.

[](#images-create-moderation)

moderation

string or null

Optional

Defaults to auto

Control the content-moderation level for images generated by `gpt-image-1`. Must be either `low` for less restrictive filtering or `auto` (default value).

[](#images-create-n)

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

[](#images-create-output_compression)

output\_compression

integer or null

Optional

Defaults to 100

The compression level (0-100%) for the generated images. This parameter is only supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and defaults to 100.

[](#images-create-output_format)

output\_format

string or null

Optional

Defaults to png

The format in which the generated images are returned. This parameter is only supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.

[](#images-create-quality)

quality

string or null

Optional

Defaults to auto

The quality of the image that will be generated.

*   `auto` (default value) will automatically select the best quality for the given model.
*   `high`, `medium` and `low` are supported for `gpt-image-1`.
*   `hd` and `standard` are supported for `dall-e-3`.
*   `standard` is the only option for `dall-e-2`.

[](#images-create-response_format)

response\_format

string or null

Optional

Defaults to url

The format in which generated images with `dall-e-2` and `dall-e-3` are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter isn't supported for `gpt-image-1` which will always return base64-encoded images.

[](#images-create-size)

size

string or null

Optional

Defaults to auto

The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.

[](#images-create-style)

style

string or null

Optional

Defaults to vivid

The style of the generated images. This parameter is only supported for `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images.

[](#images-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/images/generations \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "model": "gpt-image-1",
        "prompt": "A cute baby sea otter",
        "n": 1,
        "size": "1024x1024"
      }'
    import base64
    from openai import OpenAI
    client = OpenAI()
    
    img = client.images.generate(
        model="gpt-image-1",
        prompt="A cute baby sea otter",
        n=1,
        size="1024x1024"
    )
    
    image_bytes = base64.b64decode(img.data[0].b64_json)
    with open("output.png", "wb") as f:
        f.write(image_bytes)
    import OpenAI from "openai";
    import { writeFile } from "fs/promises";
    
    const client = new OpenAI();
    
    const img = await client.images.generate({
      model: "gpt-image-1",
      prompt: "A cute baby sea otter",
      n: 1,
      size: "1024x1024"
    });
    
    const imageBuffer = Buffer.from(img.data[0].b64_json, "base64");
    await writeFile("output.png", imageBuffer);

Response
    {
      "created": 1713833628,
      "data": [
        {
          "b64_json": "..."
        }
      ],
      "usage": {
        "total_tokens": 100,
        "input_tokens": 50,
        "output_tokens": 50,
        "input_tokens_details": {
          "text_tokens": 10,
          "image_tokens": 40
        }
      }
    }

Create image edit


---------------------

postÂ https://api.openai.com/v1/images/edits

Creates an edited or extended image given one or more source images and a prompt. This endpoint only supports `gpt-image-1` and `dall-e-2`.

#### Request body

[](#images-createedit-image)

image

string or array

Required

The image(s) to edit. Must be a supported image file or an array of images.

For `gpt-image-1`, each image should be a `png`, `webp`, or `jpg` file less than 25MB. You can provide up to 16 images.

For `dall-e-2`, you can only provide one image, and it should be a square `png` file less than 4MB.

[](#images-createedit-prompt)

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2`, and 32000 characters for `gpt-image-1`.

[](#images-createedit-background)

background

string or null

Optional

Defaults to auto

Allows to set transparency for the background of the generated image(s). This parameter is only supported for `gpt-image-1`. Must be one of `transparent`, `opaque` or `auto` (default value). When `auto` is used, the model will automatically determine the best background for the image.

If `transparent`, the output format needs to support transparency, so it should be set to either `png` (default value) or `webp`.

[](#images-createedit-mask)

mask

file

Optional

An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. If there are multiple images provided, the mask will be applied on the first image. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.

[](#images-createedit-model)

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` and `gpt-image-1` are supported. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.

[](#images-createedit-n)

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

[](#images-createedit-quality)

quality

string or null

Optional

Defaults to auto

The quality of the image that will be generated. `high`, `medium` and `low` are only supported for `gpt-image-1`. `dall-e-2` only supports `standard` quality. Defaults to `auto`.

[](#images-createedit-response_format)

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter is only supported for `dall-e-2`, as `gpt-image-1` will always return base64-encoded images.

[](#images-createedit-size)

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, and one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`.

[](#images-createedit-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

node.js
    curl -s -D >(grep -i x-request-id >&2) \
      -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png) \
      -X POST "https://api.openai.com/v1/images/edits" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -F "model=gpt-image-1" \
      -F "image[]=@body-lotion.png" \
      -F "image[]=@bath-bomb.png" \
      -F "image[]=@incense-kit.png" \
      -F "image[]=@soap.png" \
      -F 'prompt=Create a lovely gift basket with these four items in it'
    import base64
    from openai import OpenAI
    client = OpenAI()
    
    prompt = """
    Generate a photorealistic image of a gift basket on a white background 
    labeled 'Relax & Unwind' with a ribbon and handwriting-like font, 
    containing all the items in the reference pictures.
    """
    
    result = client.images.edit(
        model="gpt-image-1",
        image=[
            open("body-lotion.png", "rb"),
            open("bath-bomb.png", "rb"),
            open("incense-kit.png", "rb"),
            open("soap.png", "rb"),
        ],
        prompt=prompt
    )
    
    image_base64 = result.data[0].b64_json
    image_bytes = base64.b64decode(image_base64)
    
    # Save the image to a file
    with open("gift-basket.png", "wb") as f:
        f.write(image_bytes)
    import fs from "fs";
    import OpenAI, { toFile } from "openai";
    
    const client = new OpenAI();
    
    const imageFiles = [
        "bath-bomb.png",
        "body-lotion.png",
        "incense-kit.png",
        "soap.png",
    ];
    
    const images = await Promise.all(
        imageFiles.map(async (file) =>
            await toFile(fs.createReadStream(file), null, {
                type: "image/png",
            })
        ),
    );
    
    const rsp = await client.images.edit({
        model: "gpt-image-1",
        image: images,
        prompt: "Create a lovely gift basket with these four items in it",
    });
    
    // Save the image to a file
    const image_base64 = rsp.data[0].b64_json;
    const image_bytes = Buffer.from(image_base64, "base64");
    fs.writeFileSync("basket.png", image_bytes);

Response
    {
      "created": 1713833628,
      "data": [
        {
          "b64_json": "..."
        }
      ],
      "usage": {
        "total_tokens": 100,
        "input_tokens": 50,
        "output_tokens": 50,
        "input_tokens_details": {
          "text_tokens": 10,
          "image_tokens": 40
        }
      }
    }

Create image variation


--------------------------

postÂ https://api.openai.com/v1/images/variations

Creates a variation of a given image. This endpoint only supports `dall-e-2`.

#### Request body

[](#images-createvariation-image)

image

file

Required

The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.

[](#images-createvariation-model)

model

string or "dall-e-2"

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

[](#images-createvariation-n)

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

[](#images-createvariation-response_format)

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

[](#images-createvariation-size)

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

[](#images-createvariation-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/images/variations \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -F image="@otter.png" \
      -F n=2 \
      -F size="1024x1024"
    from openai import OpenAI
    client = OpenAI()
    
    response = client.images.create_variation(
      image=open("image_edit_original.png", "rb"),
      n=2,
      size="1024x1024"
    )
    import fs from "fs";
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const image = await openai.images.createVariation({
        image: fs.createReadStream("otter.png"),
      });
    
      console.log(image.data);
    }
    main();
    using System;
    
    using OpenAI.Images;
    
    ImageClient client = new(
        model: "dall-e-2",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    GeneratedImage image = client.GenerateImageVariation(imageFilePath: "otter.png");
    
    Console.WriteLine(image.ImageUri);

Response
    {
      "created": 1589478378,
      "data": [
        {
          "url": "https://..."
        },
        {
          "url": "https://..."
        }
      ]
    }

The image generation response


---------------------------------

The response from the image generation endpoint.

[](#images/object-created)

created

integer

The Unix timestamp (in seconds) of when the image was created.

[](#images/object-data)

data

array

The list of generated images.

Show properties

[](#images/object-usage)

usage

object

For `gpt-image-1` only, the token usage information for the image generation.

Show properties

OBJECT The image generation response
    {
      "created": 1713833628,
      "data": [
        {
          "b64_json": "..."
        }
      ],
      "usage": {
        "total_tokens": 100,
        "input_tokens": 50,
        "output_tokens": 50,
        "input_tokens_details": {
          "text_tokens": 10,
          "image_tokens": 40
        }
      }
    }

Embeddings


--------------

Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Related guide: [Embeddings](/docs/guides/embeddings)

Create embeddings


---------------------

postÂ https://api.openai.com/v1/embeddings

Creates an embedding vector representing the input text.

#### Request body

[](#embeddings-create-input)

input

string or array

Required

Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for all embedding models), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens. In addition to the per-input token limit, all embedding models enforce a maximum of 300,000 tokens summed across all inputs in a single request.

[](#embeddings-create-model)

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

[](#embeddings-create-dimensions)

dimensions

integer

Optional

The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.

[](#embeddings-create-encoding_format)

encoding\_format

string

Optional

Defaults to float

The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).

[](#embeddings-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

A list of [embedding](/docs/api-reference/embeddings/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/embeddings \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "input": "The food was delicious and the waiter...",
        "model": "text-embedding-ada-002",
        "encoding_format": "float"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    client.embeddings.create(
      model="text-embedding-ada-002",
      input="The food was delicious and the waiter...",
      encoding_format="float"
    )
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const embedding = await openai.embeddings.create({
        model: "text-embedding-ada-002",
        input: "The quick brown fox jumped over the lazy dog",
        encoding_format: "float",
      });
    
      console.log(embedding);
    }
    
    main();
    using System;
    
    using OpenAI.Embeddings;
    
    EmbeddingClient client = new(
        model: "text-embedding-3-small",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    OpenAIEmbedding embedding = client.GenerateEmbedding(input: "The quick brown fox jumped over the lazy dog");
    ReadOnlyMemory<float> vector = embedding.ToFloats();
    
    for (int i = 0; i < vector.Length; i++)
    {
        Console.WriteLine($"  [{i,4}] = {vector.Span[i]}");
    }

Response
    {
      "object": "list",
      "data": [
        {
          "object": "embedding",
          "embedding": [
            0.0023064255,
            -0.009327292,
            .... (1536 floats total for ada-002)
            -0.0028842222,
          ],
          "index": 0
        }
      ],
      "model": "text-embedding-ada-002",
      "usage": {
        "prompt_tokens": 8,
        "total_tokens": 8
      }
    }

The embedding object


------------------------

Represents an embedding vector returned by embedding endpoint.

[](#embeddings/object-embedding)

embedding

array

The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).

[](#embeddings/object-index)

index

integer

The index of the embedding in the list of embeddings.

[](#embeddings/object-object)

object

string

The object type, which is always "embedding".

OBJECT The embedding object
    {
      "object": "embedding",
      "embedding": [
        0.0023064255,
        -0.009327292,
        .... (1536 floats total for ada-002)
        -0.0028842222,
      ],
      "index": 0
    }

Evals


---------

Create, manage, and run evals in the OpenAI platform. Related guide: [Evals](/docs/guides/evals)

Create eval


---------------

postÂ https://api.openai.com/v1/evals

Create the structure of an evaluation that can be used to test a model's performance. An evaluation is a set of testing criteria and a datasource. After creating an evaluation, you can run it on different models and model parameters. We support several types of graders and datasources. For more information, see the [Evals guide](/docs/guides/evals).

#### Request body

[](#evals-create-data_source_config)

data\_source\_config

object

Required

The configuration for the data source used for the evaluation runs.

Show possible types

[](#evals-create-testing_criteria)

testing\_criteria

array

Required

A list of graders for all eval runs in this group.

Show possible types

[](#evals-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#evals-create-name)

name

string

Optional

The name of the evaluation.

#### Returns

The created [Eval](/docs/api-reference/evals/object) object.

Example request

curl
    curl https://api.openai.com/v1/evals \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
            "name": "Sentiment",
            "data_source_config": {
              "type": "stored_completions",
              "metadata": {
                  "usecase": "chatbot"
              }
            },
            "testing_criteria": [
              {
                "type": "label_model",
                "model": "o3-mini",
                "input": [
                  {
                    "role": "developer",
                    "content": "Classify the sentiment of the following statement as one of 'positive', 'neutral', or 'negative'"
                  },
                  {
                    "role": "user",
                    "content": "Statement: {{item.input}}"
                  }
                ],
                "passing_labels": [
                  "positive"
                ],
                "labels": [
                  "positive",
                  "neutral",
                  "negative"
                ],
                "name": "Example label grader"
              }
            ]
          }'

Response
    {
      "object": "eval",
      "id": "eval_67b7fa9a81a88190ab4aa417e397ea21",
      "data_source_config": {
        "type": "stored_completions",
        "metadata": {
          "usecase": "chatbot"
        },
        "schema": {
          "type": "object",
          "properties": {
            "item": {
              "type": "object"
            },
            "sample": {
              "type": "object"
            }
          },
          "required": [
            "item",
            "sample"
          ]
      },
      "testing_criteria": [
        {
          "name": "Example label grader",
          "type": "label_model",
          "model": "o3-mini",
          "input": [
            {
              "type": "message",
              "role": "developer",
              "content": {
                "type": "input_text",
                "text": "Classify the sentiment of the following statement as one of positive, neutral, or negative"
              }
            },
            {
              "type": "message",
              "role": "user",
              "content": {
                "type": "input_text",
                "text": "Statement: {{item.input}}"
              }
            }
          ],
          "passing_labels": [
            "positive"
          ],
          "labels": [
            "positive",
            "neutral",
            "negative"
          ]
        }
      ],
      "name": "Sentiment",
      "created_at": 1740110490,
      "metadata": {
        "description": "An eval for sentiment analysis"
      }
    }

Get an eval


---------------

getÂ https://api.openai.com/v1/evals/{eval\_id}

Get an evaluation by ID.

#### Path parameters

[](#evals-get-eval_id)

eval\_id

string

Required

The ID of the evaluation to retrieve.

#### Returns

The [Eval](/docs/api-reference/evals/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "eval",
      "id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "data_source_config": {
        "type": "custom",
        "schema": {
          "type": "object",
          "properties": {
            "item": {
              "type": "object",
              "properties": {
                "input": {
                  "type": "string"
                },
                "ground_truth": {
                  "type": "string"
                }
              },
              "required": [
                "input",
                "ground_truth"
              ]
            }
          },
          "required": [
            "item"
          ]
        }
      },
      "testing_criteria": [
        {
          "name": "String check",
          "id": "String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2",
          "type": "string_check",
          "input": "{{item.input}}",
          "reference": "{{item.ground_truth}}",
          "operation": "eq"
        }
      ],
      "name": "External Data Eval",
      "created_at": 1739314509,
      "metadata": {},
    }

Update an eval


------------------

postÂ https://api.openai.com/v1/evals/{eval\_id}

Update certain properties of an evaluation.

#### Path parameters

[](#evals-update-eval_id)

eval\_id

string

Required

The ID of the evaluation to update.

#### Request body

[](#evals-update-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#evals-update-name)

name

string

Optional

Rename the evaluation.

#### Returns

The [Eval](/docs/api-reference/evals/object) object matching the updated version.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{"name": "Updated Eval", "metadata": {"description": "Updated description"}}'

Response
    {
      "object": "eval",
      "id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "data_source_config": {
        "type": "custom",
        "schema": {
          "type": "object",
          "properties": {
            "item": {
              "type": "object",
              "properties": {
                "input": {
                  "type": "string"
                },
                "ground_truth": {
                  "type": "string"
                }
              },
              "required": [
                "input",
                "ground_truth"
              ]
            }
          },
          "required": [
            "item"
          ]
        }
      },
      "testing_criteria": [
        {
          "name": "String check",
          "id": "String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2",
          "type": "string_check",
          "input": "{{item.input}}",
          "reference": "{{item.ground_truth}}",
          "operation": "eq"
        }
      ],
      "name": "Updated Eval",
      "created_at": 1739314509,
      "metadata": {"description": "Updated description"},
    }

Delete an eval


------------------

deleteÂ https://api.openai.com/v1/evals/{eval\_id}

Delete an evaluation.

#### Path parameters

[](#evals-delete-eval_id)

eval\_id

string

Required

The ID of the evaluation to delete.

#### Returns

A deletion confirmation object.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_abc123 \
      -X DELETE \
      -H "Authorization: Bearer $OPENAI_API_KEY"

Response
    {
      "object": "eval.deleted",
      "deleted": true,
      "eval_id": "eval_abc123"
    }

List evals


--------------

getÂ https://api.openai.com/v1/evals

List evaluations for a project.

#### Query parameters

[](#evals-list-after)

after

string

Optional

Identifier for the last eval from the previous pagination request.

[](#evals-list-limit)

limit

integer

Optional

Defaults to 20

Number of evals to retrieve.

[](#evals-list-order)

order

string

Optional

Defaults to asc

Sort order for evals by timestamp. Use `asc` for ascending order or `desc` for descending order.

[](#evals-list-order_by)

order\_by

string

Optional

Defaults to created\_at

Evals can be ordered by creation time or last updated time. Use `created_at` for creation time or `updated_at` for last updated time.

#### Returns

A list of [evals](/docs/api-reference/evals/object) matching the specified filters.

Example request

curl
    curl https://api.openai.com/v1/evals?limit=1 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "list",
      "data": [
        {
          "id": "eval_67abd54d9b0081909a86353f6fb9317a",
          "object": "eval",
          "data_source_config": {
            "type": "stored_completions",
            "metadata": {
              "usecase": "push_notifications_summarizer"
            },
            "schema": {
              "type": "object",
              "properties": {
                "item": {
                  "type": "object"
                },
                "sample": {
                  "type": "object"
                }
              },
              "required": [
                "item",
                "sample"
              ]
            }
          },
          "testing_criteria": [
            {
              "name": "Push Notification Summary Grader",
              "id": "Push Notification Summary Grader-9b876f24-4762-4be9-aff4-db7a9b31c673",
              "type": "label_model",
              "model": "o3-mini",
              "input": [
                {
                  "type": "message",
                  "role": "developer",
                  "content": {
                    "type": "input_text",
                    "text": "\nLabel the following push notification summary as either correct or incorrect.\nThe push notification and the summary will be provided below.\nA good push notificiation summary is concise and snappy.\nIf it is good, then label it as correct, if not, then incorrect.\n"
                  }
                },
                {
                  "type": "message",
                  "role": "user",
                  "content": {
                    "type": "input_text",
                    "text": "\nPush notifications: {{item.input}}\nSummary: {{sample.output_text}}\n"
                  }
                }
              ],
              "passing_labels": [
                "correct"
              ],
              "labels": [
                "correct",
                "incorrect"
              ],
              "sampling_params": null
            }
          ],
          "name": "Push Notification Summary Grader",
          "created_at": 1739314509,
          "metadata": {
            "description": "A stored completions eval for push notification summaries"
          }
        }
      ],
      "first_id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "last_id": "eval_67aa884cf6688190b58f657d4441c8b7",
      "has_more": true
    }

Get eval runs


-----------------

getÂ https://api.openai.com/v1/evals/{eval\_id}/runs

Get a list of runs for an evaluation.

#### Path parameters

[](#evals-getruns-eval_id)

eval\_id

string

Required

The ID of the evaluation to retrieve runs for.

#### Query parameters

[](#evals-getruns-after)

after

string

Optional

Identifier for the last run from the previous pagination request.

[](#evals-getruns-limit)

limit

integer

Optional

Defaults to 20

Number of runs to retrieve.

[](#evals-getruns-order)

order

string

Optional

Defaults to asc

Sort order for runs by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.

[](#evals-getruns-status)

status

string

Optional

Filter runs by status. One of `queued` | `in_progress` | `failed` | `completed` | `canceled`.

#### Returns

A list of [EvalRun](/docs/api-reference/evals/run-object) objects matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "eval.run",
          "id": "evalrun_67e0c7d31560819090d60c0780591042",
          "eval_id": "eval_67e0c726d560819083f19a957c4c640b",
          "report_url": "https://platform.openai.com/evaluations/eval_67e0c726d560819083f19a957c4c640b",
          "status": "completed",
          "model": "o3-mini",
          "name": "bulk_with_negative_examples_o3-mini",
          "created_at": 1742784467,
          "result_counts": {
            "total": 1,
            "errored": 0,
            "failed": 0,
            "passed": 1
          },
          "per_model_usage": [
            {
              "model_name": "o3-mini",
              "invocation_count": 1,
              "prompt_tokens": 563,
              "completion_tokens": 874,
              "total_tokens": 1437,
              "cached_tokens": 0
            }
          ],
          "per_testing_criteria_results": [
            {
              "testing_criteria": "Push Notification Summary Grader-1808cd0b-eeec-4e0b-a519-337e79f4f5d1",
              "passed": 1,
              "failed": 0
            }
          ],
          "data_source": {
            "type": "completions",
            "source": {
              "type": "file_content",
              "content": [
                {
                  "item": {
                    "notifications": "\n- New message from Sarah: \"Can you call me later?\"\n- Your package has been delivered!\n- Flash sale: 20% off electronics for the next 2 hours!\n"
                  }
                }
              ]
            },
            "input_messages": {
              "type": "template",
              "template": [
                {
                  "type": "message",
                  "role": "developer",
                  "content": {
                    "type": "input_text",
                    "text": "\n\n\n\nYou are a helpful assistant that takes in an array of push notifications and returns a collapsed summary of them.\nThe push notification will be provided as follows:\n<push_notifications>\n...notificationlist...\n</push_notifications>\n\nYou should return just the summary and nothing else.\n\n\nYou should return a summary that is concise and snappy.\n\n\nHere is an example of a good summary:\n<push_notifications>\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\n</push_notifications>\n<summary>\nTraffic alert, package expected by 5pm, suggestion for new friend (Emily).\n</summary>\n\n\nHere is an example of a bad summary:\n<push_notifications>\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\n</push_notifications>\n<summary>\nTraffic alert reported on main street. You have a package that will arrive by 5pm, Emily is a new friend suggested for you.\n</summary>\n"
                  }
                },
                {
                  "type": "message",
                  "role": "user",
                  "content": {
                    "type": "input_text",
                    "text": "<push_notifications>{{item.notifications}}</push_notifications>"
                  }
                }
              ]
            },
            "model": "o3-mini",
            "sampling_params": null
          },
          "error": null,
          "metadata": {}
        }
      ],
      "first_id": "evalrun_67e0c7d31560819090d60c0780591042",
      "last_id": "evalrun_67e0c7d31560819090d60c0780591042",
      "has_more": true
    }

Get an eval run


-------------------

getÂ https://api.openai.com/v1/evals/{eval\_id}/runs/{run\_id}

Get an evaluation run by ID.

#### Path parameters

[](#evals-getrun-eval_id)

eval\_id

string

Required

The ID of the evaluation to retrieve runs for.

[](#evals-getrun-run_id)

run\_id

string

Required

The ID of the run to retrieve.

#### Returns

The [EvalRun](/docs/api-reference/evals/run-object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "eval.run",
      "id": "evalrun_67abd54d60ec8190832b46859da808f7",
      "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "report_url": "https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7",
      "status": "queued",
      "model": "gpt-4o-mini",
      "name": "gpt-4o-mini",
      "created_at": 1743092069,
      "result_counts": {
        "total": 0,
        "errored": 0,
        "failed": 0,
        "passed": 0
      },
      "per_model_usage": null,
      "per_testing_criteria_results": null,
      "data_source": {
        "type": "completions",
        "source": {
          "type": "file_content",
          "content": [
            {
              "item": {
                "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Summit Addresses Climate Change Strategies",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "National Team Qualifies for World Championship Finals",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Stock Markets Rally After Positive Economic Data Released",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "Global Manufacturer Announces Merger with Competitor",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Breakthrough in Renewable Energy Technology Unveiled",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "World Leaders Sign Historic Climate Agreement",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Professional Athlete Sets New Record in Championship Event",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Financial Institutions Adapt to New Regulatory Requirements",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Global Markets Respond to Oil Price Fluctuations",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Cooperation Strengthened Through New Treaty",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Sports League Announces Revised Schedule for Upcoming Season",
                "ground_truth": "Sports"
              }
            }
          ]
        },
        "input_messages": {
          "type": "template",
          "template": [
            {
              "type": "message",
              "role": "developer",
              "content": {
                "type": "input_text",
                "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
              }
            },
            {
              "type": "message",
              "role": "user",
              "content": {
                "type": "input_text",
                "text": "{{item.input}}"
              }
            }
          ]
        },
        "model": "gpt-4o-mini",
        "sampling_params": {
          "seed": 42,
          "temperature": 1.0,
          "top_p": 1.0,
          "max_completions_tokens": 2048
        }
      },
      "error": null,
      "metadata": {}
    }

Create eval run


-------------------

postÂ https://api.openai.com/v1/evals/{eval\_id}/runs

Create a new evaluation run. This is the endpoint that will kick off grading.

#### Path parameters

[](#evals-createrun-eval_id)

eval\_id

string

Required

The ID of the evaluation to create a run for.

#### Request body

[](#evals-createrun-data_source)

data\_source

object

Required

Details about the run's data source.

Show possible types

[](#evals-createrun-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#evals-createrun-name)

name

string

Optional

The name of the run.

#### Returns

The [EvalRun](/docs/api-reference/evals/run-object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67e579652b548190aaa83ada4b125f47/runs \
      -X POST \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{"name":"gpt-4o-mini","data_source":{"type":"completions","input_messages":{"type":"template","template":[{"role":"developer","content":"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"} , {"role":"user","content":"{{item.input}}"}]},"sampling_params":{"temperature":1,"max_completions_tokens":2048,"top_p":1,"seed":42},"model":"gpt-4o-mini","source":{"type":"file_content","content":[{"item":{"input":"Tech Company Launches Advanced Artificial Intelligence Platform","ground_truth":"Technology"}}]}}'

Response
    {
      "object": "eval.run",
      "id": "evalrun_67e57965b480819094274e3a32235e4c",
      "eval_id": "eval_67e579652b548190aaa83ada4b125f47",
      "report_url": "https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47&run_id=evalrun_67e57965b480819094274e3a32235e4c",
      "status": "queued",
      "model": "gpt-4o-mini",
      "name": "gpt-4o-mini",
      "created_at": 1743092069,
      "result_counts": {
        "total": 0,
        "errored": 0,
        "failed": 0,
        "passed": 0
      },
      "per_model_usage": null,
      "per_testing_criteria_results": null,
      "data_source": {
        "type": "completions",
        "source": {
          "type": "file_content",
          "content": [
            {
              "item": {
                "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                "ground_truth": "Technology"
              }
            }
          ]
        },
        "input_messages": {
          "type": "template",
          "template": [
            {
              "type": "message",
              "role": "developer",
              "content": {
                "type": "input_text",
                "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
              }
            },
            {
              "type": "message",
              "role": "user",
              "content": {
                "type": "input_text",
                "text": "{{item.input}}"
              }
            }
          ]
        },
        "model": "gpt-4o-mini",
        "sampling_params": {
          "seed": 42,
          "temperature": 1.0,
          "top_p": 1.0,
          "max_completions_tokens": 2048
        }
      },
      "error": null,
      "metadata": {}
    }

Cancel eval run


-------------------

postÂ https://api.openai.com/v1/evals/{eval\_id}/runs/{run\_id}

Cancel an ongoing evaluation run.

#### Path parameters

[](#evals-cancelrun-eval_id)

eval\_id

string

Required

The ID of the evaluation whose run you want to cancel.

[](#evals-cancelrun-run_id)

run\_id

string

Required

The ID of the run to cancel.

#### Returns

The updated [EvalRun](/docs/api-reference/evals/run-object) object reflecting that the run is canceled.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/cancel \
      -X POST \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "eval.run",
      "id": "evalrun_67abd54d60ec8190832b46859da808f7",
      "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "report_url": "https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7",
      "status": "canceled",
      "model": "gpt-4o-mini",
      "name": "gpt-4o-mini",
      "created_at": 1743092069,
      "result_counts": {
        "total": 0,
        "errored": 0,
        "failed": 0,
        "passed": 0
      },
      "per_model_usage": null,
      "per_testing_criteria_results": null,
      "data_source": {
        "type": "completions",
        "source": {
          "type": "file_content",
          "content": [
            {
              "item": {
                "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Summit Addresses Climate Change Strategies",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "National Team Qualifies for World Championship Finals",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Stock Markets Rally After Positive Economic Data Released",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "Global Manufacturer Announces Merger with Competitor",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Breakthrough in Renewable Energy Technology Unveiled",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "World Leaders Sign Historic Climate Agreement",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Professional Athlete Sets New Record in Championship Event",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Financial Institutions Adapt to New Regulatory Requirements",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Global Markets Respond to Oil Price Fluctuations",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Cooperation Strengthened Through New Treaty",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Sports League Announces Revised Schedule for Upcoming Season",
                "ground_truth": "Sports"
              }
            }
          ]
        },
        "input_messages": {
          "type": "template",
          "template": [
            {
              "type": "message",
              "role": "developer",
              "content": {
                "type": "input_text",
                "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
              }
            },
            {
              "type": "message",
              "role": "user",
              "content": {
                "type": "input_text",
                "text": "{{item.input}}"
              }
            }
          ]
        },
        "model": "gpt-4o-mini",
        "sampling_params": {
          "seed": 42,
          "temperature": 1.0,
          "top_p": 1.0,
          "max_completions_tokens": 2048
        }
      },
      "error": null,
      "metadata": {}
    }

Delete eval run


-------------------

deleteÂ https://api.openai.com/v1/evals/{eval\_id}/runs/{run\_id}

Delete an eval run.

#### Path parameters

[](#evals-deleterun-eval_id)

eval\_id

string

Required

The ID of the evaluation to delete the run from.

[](#evals-deleterun-run_id)

run\_id

string

Required

The ID of the run to delete.

#### Returns

An object containing the status of the delete operation.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_123abc/runs/evalrun_abc456 \
      -X DELETE \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "eval.run.deleted",
      "deleted": true,
      "run_id": "evalrun_abc456"
    }

Get an output item of an eval run


-------------------------------------

getÂ https://api.openai.com/v1/evals/{eval\_id}/runs/{run\_id}/output\_items/{output\_item\_id}

Get an evaluation run output item by ID.

#### Path parameters

[](#evals-getrunoutputitem-eval_id)

eval\_id

string

Required

The ID of the evaluation to retrieve runs for.

[](#evals-getrunoutputitem-output_item_id)

output\_item\_id

string

Required

The ID of the output item to retrieve.

[](#evals-getrunoutputitem-run_id)

run\_id

string

Required

The ID of the run to retrieve.

#### Returns

The [EvalRunOutputItem](/docs/api-reference/evals/run-output-item-object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/output_items/outputitem_67abd55eb6548190bb580745d5644a33 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "eval.run.output_item",
      "id": "outputitem_67e5796c28e081909917bf79f6e6214d",
      "created_at": 1743092076,
      "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
      "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "status": "pass",
      "datasource_item_id": 5,
      "datasource_item": {
        "input": "Stock Markets Rally After Positive Economic Data Released",
        "ground_truth": "Markets"
      },
      "results": [
        {
          "name": "String check-a2486074-d803-4445-b431-ad2262e85d47",
          "sample": null,
          "passed": true,
          "score": 1.0
        }
      ],
      "sample": {
        "input": [
          {
            "role": "developer",
            "content": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n",
            "tool_call_id": null,
            "tool_calls": null,
            "function_call": null
          },
          {
            "role": "user",
            "content": "Stock Markets Rally After Positive Economic Data Released",
            "tool_call_id": null,
            "tool_calls": null,
            "function_call": null
          }
        ],
        "output": [
          {
            "role": "assistant",
            "content": "Markets",
            "tool_call_id": null,
            "tool_calls": null,
            "function_call": null
          }
        ],
        "finish_reason": "stop",
        "model": "gpt-4o-mini-2024-07-18",
        "usage": {
          "total_tokens": 325,
          "completion_tokens": 2,
          "prompt_tokens": 323,
          "cached_tokens": 0
        },
        "error": null,
        "temperature": 1.0,
        "max_completion_tokens": 2048,
        "top_p": 1.0,
        "seed": 42
      }
    }

Get eval run output items


-----------------------------

getÂ https://api.openai.com/v1/evals/{eval\_id}/runs/{run\_id}/output\_items

Get a list of output items for an evaluation run.

#### Path parameters

[](#evals-getrunoutputitems-eval_id)

eval\_id

string

Required

The ID of the evaluation to retrieve runs for.

[](#evals-getrunoutputitems-run_id)

run\_id

string

Required

The ID of the run to retrieve output items for.

#### Query parameters

[](#evals-getrunoutputitems-after)

after

string

Optional

Identifier for the last output item from the previous pagination request.

[](#evals-getrunoutputitems-limit)

limit

integer

Optional

Defaults to 20

Number of output items to retrieve.

[](#evals-getrunoutputitems-order)

order

string

Optional

Defaults to asc

Sort order for output items by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.

[](#evals-getrunoutputitems-status)

status

string

Optional

Filter output items by status. Use `failed` to filter by failed output items or `pass` to filter by passed output items.

#### Returns

A list of [EvalRunOutputItem](/docs/api-reference/evals/run-output-item-object) objects matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs/erun_67abd54d60ec8190832b46859da808f7/output_items \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "eval.run.output_item",
          "id": "outputitem_67e5796c28e081909917bf79f6e6214d",
          "created_at": 1743092076,
          "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
          "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
          "status": "pass",
          "datasource_item_id": 5,
          "datasource_item": {
            "input": "Stock Markets Rally After Positive Economic Data Released",
            "ground_truth": "Markets"
          },
          "results": [
            {
              "name": "String check-a2486074-d803-4445-b431-ad2262e85d47",
              "sample": null,
              "passed": true,
              "score": 1.0
            }
          ],
          "sample": {
            "input": [
              {
                "role": "developer",
                "content": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n",
                "tool_call_id": null,
                "tool_calls": null,
                "function_call": null
              },
              {
                "role": "user",
                "content": "Stock Markets Rally After Positive Economic Data Released",
                "tool_call_id": null,
                "tool_calls": null,
                "function_call": null
              }
            ],
            "output": [
              {
                "role": "assistant",
                "content": "Markets",
                "tool_call_id": null,
                "tool_calls": null,
                "function_call": null
              }
            ],
            "finish_reason": "stop",
            "model": "gpt-4o-mini-2024-07-18",
            "usage": {
              "total_tokens": 325,
              "completion_tokens": 2,
              "prompt_tokens": 323,
              "cached_tokens": 0
            },
            "error": null,
            "temperature": 1.0,
            "max_completion_tokens": 2048,
            "top_p": 1.0,
            "seed": 42
          }
        }
      ],
      "first_id": "outputitem_67e5796c28e081909917bf79f6e6214d",
      "last_id": "outputitem_67e5796c28e081909917bf79f6e6214d",
      "has_more": true
    }

The eval object


-------------------

An Eval object with a data source config and testing criteria. An Eval represents a task to be done for your LLM integration. Like:

*   Improve the quality of my chatbot
*   See how well my chatbot handles customer support
*   Check if o3-mini is better at my usecase than gpt-4o

[](#evals/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the eval was created.

[](#evals/object-data_source_config)

data\_source\_config

object

Configuration of data sources used in runs of the evaluation.

Show possible types

[](#evals/object-id)

id

string

Unique identifier for the evaluation.

[](#evals/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#evals/object-name)

name

string

The name of the evaluation.

[](#evals/object-object)

object

string

The object type.

[](#evals/object-testing_criteria)

testing\_criteria

array

A list of testing criteria.

Show possible types

OBJECT The eval object
    {
      "object": "eval",
      "id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "data_source_config": {
        "type": "custom",
        "item_schema": {
          "type": "object",
          "properties": {
            "label": {"type": "string"},
          },
          "required": ["label"]
        },
        "include_sample_schema": true
      },
      "testing_criteria": [
        {
          "name": "My string check grader",
          "type": "string_check",
          "input": "{{sample.output_text}}",
          "reference": "{{item.label}}",
          "operation": "eq",
        }
      ],
      "name": "External Data Eval",
      "created_at": 1739314509,
      "metadata": {
        "test": "synthetics",
      }
    }

The eval run object


-----------------------

A schema representing an evaluation run.

[](#evals/run-object-created_at)

created\_at

integer

Unix timestamp (in seconds) when the evaluation run was created.

[](#evals/run-object-data_source)

data\_source

object

Information about the run's data source.

Show possible types

[](#evals/run-object-error)

error

object

An object representing an error response from the Eval API.

Show properties

[](#evals/run-object-eval_id)

eval\_id

string

The identifier of the associated evaluation.

[](#evals/run-object-id)

id

string

Unique identifier for the evaluation run.

[](#evals/run-object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#evals/run-object-model)

model

string

The model that is evaluated, if applicable.

[](#evals/run-object-name)

name

string

The name of the evaluation run.

[](#evals/run-object-object)

object

string

The type of the object. Always "eval.run".

[](#evals/run-object-per_model_usage)

per\_model\_usage

array

Usage statistics for each model during the evaluation run.

Show properties

[](#evals/run-object-per_testing_criteria_results)

per\_testing\_criteria\_results

array

Results per testing criteria applied during the evaluation run.

Show properties

[](#evals/run-object-report_url)

report\_url

string

The URL to the rendered evaluation run report on the UI dashboard.

[](#evals/run-object-result_counts)

result\_counts

object

Counters summarizing the outcomes of the evaluation run.

Show properties

[](#evals/run-object-status)

status

string

The status of the evaluation run.

OBJECT The eval run object
    {
      "object": "eval.run",
      "id": "evalrun_67e57965b480819094274e3a32235e4c",
      "eval_id": "eval_67e579652b548190aaa83ada4b125f47",
      "report_url": "https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47?run_id=evalrun_67e57965b480819094274e3a32235e4c",
      "status": "queued",
      "model": "gpt-4o-mini",
      "name": "gpt-4o-mini",
      "created_at": 1743092069,
      "result_counts": {
        "total": 0,
        "errored": 0,
        "failed": 0,
        "passed": 0
      },
      "per_model_usage": null,
      "per_testing_criteria_results": null,
      "data_source": {
        "type": "completions",
        "source": {
          "type": "file_content",
          "content": [
            {
              "item": {
                "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Summit Addresses Climate Change Strategies",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "National Team Qualifies for World Championship Finals",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Stock Markets Rally After Positive Economic Data Released",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "Global Manufacturer Announces Merger with Competitor",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Breakthrough in Renewable Energy Technology Unveiled",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "World Leaders Sign Historic Climate Agreement",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Professional Athlete Sets New Record in Championship Event",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Financial Institutions Adapt to New Regulatory Requirements",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Global Markets Respond to Oil Price Fluctuations",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Cooperation Strengthened Through New Treaty",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Sports League Announces Revised Schedule for Upcoming Season",
                "ground_truth": "Sports"
              }
            }
          ]
        },
        "input_messages": {
          "type": "template",
          "template": [
            {
              "type": "message",
              "role": "developer",
              "content": {
                "type": "input_text",
                "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
              }
            },
            {
              "type": "message",
              "role": "user",
              "content": {
                "type": "input_text",
                "text": "{{item.input}}"
              }
            }
          ]
        },
        "model": "gpt-4o-mini",
        "sampling_params": {
          "seed": 42,
          "temperature": 1.0,
          "top_p": 1.0,
          "max_completions_tokens": 2048
        }
      },
      "error": null,
      "metadata": {}
    }

The eval run output item object


-----------------------------------

A schema representing an evaluation run output item.

[](#evals/run-output-item-object-created_at)

created\_at

integer

Unix timestamp (in seconds) when the evaluation run was created.

[](#evals/run-output-item-object-datasource_item)

datasource\_item

object

Details of the input data source item.

[](#evals/run-output-item-object-datasource_item_id)

datasource\_item\_id

integer

The identifier for the data source item.

[](#evals/run-output-item-object-eval_id)

eval\_id

string

The identifier of the evaluation group.

[](#evals/run-output-item-object-id)

id

string

Unique identifier for the evaluation run output item.

[](#evals/run-output-item-object-object)

object

string

The type of the object. Always "eval.run.output\_item".

[](#evals/run-output-item-object-results)

results

array

A list of results from the evaluation run.

Show properties

[](#evals/run-output-item-object-run_id)

run\_id

string

The identifier of the evaluation run associated with this output item.

[](#evals/run-output-item-object-sample)

sample

object

A sample containing the input and output of the evaluation run.

Show properties

[](#evals/run-output-item-object-status)

status

string

The status of the evaluation run.

OBJECT The eval run output item object
    {
      "object": "eval.run.output_item",
      "id": "outputitem_67abd55eb6548190bb580745d5644a33",
      "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
      "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "created_at": 1739314509,
      "status": "pass",
      "datasource_item_id": 137,
      "datasource_item": {
          "teacher": "To grade essays, I only check for style, content, and grammar.",
          "student": "I am a student who is trying to write the best essay."
      },
      "results": [
        {
          "name": "String Check Grader",
          "type": "string-check-grader",
          "score": 1.0,
          "passed": true,
        }
      ],
      "sample": {
        "input": [
          {
            "role": "system",
            "content": "You are an evaluator bot..."
          },
          {
            "role": "user",
            "content": "You are assessing..."
          }
        ],
        "output": [
          {
            "role": "assistant",
            "content": "The rubric is not clear nor concise."
          }
        ],
        "finish_reason": "stop",
        "model": "gpt-4o-2024-08-06",
        "usage": {
          "total_tokens": 521,
          "completion_tokens": 2,
          "prompt_tokens": 519,
          "cached_tokens": 0
        },
        "error": null,
        "temperature": 1.0,
        "max_completion_tokens": 2048,
        "top_p": 1.0,
        "seed": 42
      }
    }

Fine-tuning


---------------

Manage fine-tuning jobs to tailor a model to your specific training data. Related guide: [Fine-tune models](/docs/guides/fine-tuning)

Create fine-tuning job


--------------------------

postÂ https://api.openai.com/v1/fine\_tuning/jobs

Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

#### Request body

[](#fine-tuning-create-model)

model

string

Required

The name of the model to fine-tune. You can select one of the [supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).

[](#fine-tuning-create-training_file)

training\_file

string

Required

The ID of an uploaded file that contains training data.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input), [completions](/docs/api-reference/fine-tuning/completions-input) format, or if the fine-tuning method uses the [preference](/docs/api-reference/fine-tuning/preference-input) format.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

[](#fine-tuning-create-hyperparameters)

hyperparameters

Deprecated

object

Optional

The hyperparameters used for the fine-tuning job. This value is now deprecated in favor of `method`, and should be passed in under the `method` parameter.

Show properties

[](#fine-tuning-create-integrations)

integrations

array or null

Optional

A list of integrations to enable for your fine-tuning job.

Show properties

[](#fine-tuning-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#fine-tuning-create-method)

method

object

Optional

The method used for fine-tuning.

Show properties

[](#fine-tuning-create-seed)

seed

integer or null

Optional

The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases. If a seed is not specified, one will be generated for you.

[](#fine-tuning-create-suffix)

suffix

string or null

Optional

Defaults to null

A string of up to 64 characters that will be added to your fine-tuned model name.

For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.

[](#fine-tuning-create-validation_file)

validation\_file

string or null

Optional

The ID of an uploaded file that contains validation data.

If you provide this file, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in the fine-tuning results file. The same data should not be present in both train and validation files.

Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

#### Returns

A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.

DefaultDefaultEpochsEpochsDPODPOReinforcementReinforcementValidation fileValidation fileW&B IntegrationW&B Integration

Example request

node.js
    curl https://api.openai.com/v1/fine_tuning/jobs \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
        "model": "gpt-4o-mini"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.create(
      training_file="file-abc123",
      model="gpt-4o-mini"
    )
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const fineTune = await openai.fineTuning.jobs.create({
        training_file: "file-abc123"
      });
    
      console.log(fineTune);
    }
    
    main();

Response
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "gpt-4o-mini-2024-07-18",
      "created_at": 1721764800,
      "fine_tuned_model": null,
      "organization_id": "org-123",
      "result_files": [],
      "status": "queued",
      "validation_file": null,
      "training_file": "file-abc123",
      "method": {
        "type": "supervised",
        "supervised": {
          "hyperparameters": {
            "batch_size": "auto",
            "learning_rate_multiplier": "auto",
            "n_epochs": "auto",
          }
        }
      },
      "metadata": null
    }

List fine-tuning jobs


-------------------------

getÂ https://api.openai.com/v1/fine\_tuning/jobs

List your organization's fine-tuning jobs

#### Query parameters

[](#fine-tuning-list-after)

after

string

Optional

Identifier for the last job from the previous pagination request.

[](#fine-tuning-list-limit)

limit

integer

Optional

Defaults to 20

Number of fine-tuning jobs to retrieve.

[](#fine-tuning-list-metadata)

metadata

object or null

Optional

Optional metadata filter. To filter, use the syntax `metadata[k]=v`. Alternatively, set `metadata=null` to indicate no metadata.

#### Returns

A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/fine_tuning/jobs?limit=2&metadata[key]=value \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.list()
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const list = await openai.fineTuning.jobs.list();
    
      for await (const fineTune of list) {
        console.log(fineTune);
      }
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "object": "fine_tuning.job",
          "id": "ftjob-abc123",
          "model": "gpt-4o-mini-2024-07-18",
          "created_at": 1721764800,
          "fine_tuned_model": null,
          "organization_id": "org-123",
          "result_files": [],
          "status": "queued",
          "validation_file": null,
          "training_file": "file-abc123",
          "metadata": {
            "key": "value"
          }
        },
        { ... },
        { ... }
      ], "has_more": true
    }

List fine-tuning events


---------------------------

getÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/events

Get status updates for a fine-tuning job.

#### Path parameters

[](#fine-tuning-list-events-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get events for.

#### Query parameters

[](#fine-tuning-list-events-after)

after

string

Optional

Identifier for the last event from the previous pagination request.

[](#fine-tuning-list-events-limit)

limit

integer

Optional

Defaults to 20

Number of events to retrieve.

#### Returns

A list of fine-tuning event objects.

Example request

node.js
    curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.list_events(
      fine_tuning_job_id="ftjob-abc123",
      limit=2
    )
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const list = await openai.fineTuning.list_events(id="ftjob-abc123", limit=2);
    
      for await (const fineTune of list) {
        console.log(fineTune);
      }
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "object": "fine_tuning.job.event",
          "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",
          "created_at": 1721764800,
          "level": "info",
          "message": "Fine tuning job successfully completed",
          "data": null,
          "type": "message"
        },
        {
          "object": "fine_tuning.job.event",
          "id": "ft-event-tyiGuB72evQncpH87xe505Sv",
          "created_at": 1721764800,
          "level": "info",
          "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",
          "data": null,
          "type": "message"
        }
      ],
      "has_more": true
    }

List fine-tuning checkpoints


--------------------------------

getÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/checkpoints

List checkpoints for a fine-tuning job.

#### Path parameters

[](#fine-tuning-list-checkpoints-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get checkpoints for.

#### Query parameters

[](#fine-tuning-list-checkpoints-after)

after

string

Optional

Identifier for the last checkpoint ID from the previous pagination request.

[](#fine-tuning-list-checkpoints-limit)

limit

integer

Optional

Defaults to 10

Number of checkpoints to retrieve.

#### Returns

A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object) for a fine-tuning job.

Example request

curl
    curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
      -H "Authorization: Bearer $OPENAI_API_KEY"

Response
    {
      "object": "list"
      "data": [
        {
          "object": "fine_tuning.job.checkpoint",
          "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
          "created_at": 1721764867,
          "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",
          "metrics": {
            "full_valid_loss": 0.134,
            "full_valid_mean_token_accuracy": 0.874
          },
          "fine_tuning_job_id": "ftjob-abc123",
          "step_number": 2000,
        },
        {
          "object": "fine_tuning.job.checkpoint",
          "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
          "created_at": 1721764800,
          "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",
          "metrics": {
            "full_valid_loss": 0.167,
            "full_valid_mean_token_accuracy": 0.781
          },
          "fine_tuning_job_id": "ftjob-abc123",
          "step_number": 1000,
        },
      ],
      "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
      "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
      "has_more": true
    }

List checkpoint permissions


-------------------------------

getÂ https://api.openai.com/v1/fine\_tuning/checkpoints/{fine\_tuned\_model\_checkpoint}/permissions

**NOTE:** This endpoint requires an [admin API key](../admin-api-keys).

Organization owners can use this endpoint to view all permissions for a fine-tuned model checkpoint.

#### Path parameters

[](#fine-tuning-list-permissions-fine_tuned_model_checkpoint)

fine\_tuned\_model\_checkpoint

string

Required

The ID of the fine-tuned model checkpoint to get permissions for.

#### Query parameters

[](#fine-tuning-list-permissions-after)

after

string

Optional

Identifier for the last permission ID from the previous pagination request.

[](#fine-tuning-list-permissions-limit)

limit

integer

Optional

Defaults to 10

Number of permissions to retrieve.

[](#fine-tuning-list-permissions-order)

order

string

Optional

Defaults to descending

The order in which to retrieve permissions.

[](#fine-tuning-list-permissions-project_id)

project\_id

string

Optional

The ID of the project to get permissions for.

#### Returns

A list of fine-tuned model checkpoint [permission objects](/docs/api-reference/fine-tuning/permission-object) for a fine-tuned model checkpoint.

Example request

curl
    curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \
      -H "Authorization: Bearer $OPENAI_API_KEY"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "checkpoint.permission",
          "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
          "created_at": 1721764867,
          "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
        },
        {
          "object": "checkpoint.permission",
          "id": "cp_enQCFmOTGj3syEpYVhBRLTSy",
          "created_at": 1721764800,
          "project_id": "proj_iqGMw1llN8IrBb6SvvY5A1oF"
        },
      ],
      "first_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
      "last_id": "cp_enQCFmOTGj3syEpYVhBRLTSy",
      "has_more": false
    }

Create checkpoint permissions


---------------------------------

postÂ https://api.openai.com/v1/fine\_tuning/checkpoints/{fine\_tuned\_model\_checkpoint}/permissions

**NOTE:** Calling this endpoint requires an [admin API key](../admin-api-keys).

This enables organization owners to share fine-tuned models with other projects in their organization.

#### Path parameters

[](#fine-tuning-create-permission-fine_tuned_model_checkpoint)

fine\_tuned\_model\_checkpoint

string

Required

The ID of the fine-tuned model checkpoint to create a permission for.

#### Request body

[](#fine-tuning-create-permission-project_ids)

project\_ids

array

Required

The project identifiers to grant access to.

#### Returns

A list of fine-tuned model checkpoint [permission objects](/docs/api-reference/fine-tuning/permission-object) for a fine-tuned model checkpoint.

Example request

curl
    curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \
      -H "Authorization: Bearer $OPENAI_API_KEY"
      -d '{"project_ids": ["proj_abGMw1llN8IrBb6SvvY5A1iH"]}'

Response
    {
      "object": "list",
      "data": [
        {
          "object": "checkpoint.permission",
          "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
          "created_at": 1721764867,
          "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
        }
      ],
      "first_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
      "last_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
      "has_more": false
    }

Delete checkpoint permission


--------------------------------

deleteÂ https://api.openai.com/v1/fine\_tuning/checkpoints/{fine\_tuned\_model\_checkpoint}/permissions/{permission\_id}

**NOTE:** This endpoint requires an [admin API key](../admin-api-keys).

Organization owners can use this endpoint to delete a permission for a fine-tuned model checkpoint.

#### Path parameters

[](#fine-tuning-delete-permission-fine_tuned_model_checkpoint)

fine\_tuned\_model\_checkpoint

string

Required

The ID of the fine-tuned model checkpoint to delete a permission for.

[](#fine-tuning-delete-permission-permission_id)

permission\_id

string

Required

The ID of the fine-tuned model checkpoint permission to delete.

#### Returns

The deletion status of the fine-tuned model checkpoint [permission object](/docs/api-reference/fine-tuning/permission-object).

Example request

curl
    curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions/cp_zc4Q7MP6XxulcVzj4MZdwsAB \
      -H "Authorization: Bearer $OPENAI_API_KEY"

Response
    {
      "object": "checkpoint.permission",
      "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
      "deleted": true
    }

Retrieve fine-tuning job


----------------------------

getÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}

Get info about a fine-tuning job.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

#### Path parameters

[](#fine-tuning-retrieve-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job.

#### Returns

The [fine-tuning](/docs/api-reference/fine-tuning/object) object with the given ID.

Example request

node.js
    curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.retrieve("ftjob-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const fineTune = await openai.fineTuning.jobs.retrieve("ftjob-abc123");
    
      console.log(fineTune);
    }
    
    main();

Response
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "davinci-002",
      "created_at": 1692661014,
      "finished_at": 1692661190,
      "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
      "organization_id": "org-123",
      "result_files": [
          "file-abc123"
      ],
      "status": "succeeded",
      "validation_file": null,
      "training_file": "file-abc123",
      "hyperparameters": {
          "n_epochs": 4,
          "batch_size": 1,
          "learning_rate_multiplier": 1.0
      },
      "trained_tokens": 5768,
      "integrations": [],
      "seed": 0,
      "estimated_finish": 0,
      "method": {
        "type": "supervised",
        "supervised": {
          "hyperparameters": {
            "n_epochs": 4,
            "batch_size": 1,
            "learning_rate_multiplier": 1.0
          }
        }
      }
    }

Cancel fine-tuning


----------------------

postÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/cancel

Immediately cancel a fine-tune job.

#### Path parameters

[](#fine-tuning-cancel-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to cancel.

#### Returns

The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

node.js
    curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.cancel("ftjob-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const fineTune = await openai.fineTuning.jobs.cancel("ftjob-abc123");
    
      console.log(fineTune);
    }
    main();

Response
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "gpt-4o-mini-2024-07-18",
      "created_at": 1721764800,
      "fine_tuned_model": null,
      "organization_id": "org-123",
      "result_files": [],
      "status": "cancelled",
      "validation_file": "file-abc123",
      "training_file": "file-abc123"
    }

Resume fine-tuning


----------------------

postÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/resume

Resume a fine-tune job.

#### Path parameters

[](#fine-tuning-resume-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to resume.

#### Returns

The resumed [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

node.js
    curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/resume \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.resume("ftjob-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const fineTune = await openai.fineTuning.jobs.resume("ftjob-abc123");
    
      console.log(fineTune);
    }
    main();

Response
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "gpt-4o-mini-2024-07-18",
      "created_at": 1721764800,
      "fine_tuned_model": null,
      "organization_id": "org-123",
      "result_files": [],
      "status": "queued",
      "validation_file": "file-abc123",
      "training_file": "file-abc123"
    }

Pause fine-tuning


---------------------

postÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/pause

Pause a fine-tune job.

#### Path parameters

[](#fine-tuning-pause-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to pause.

#### Returns

The paused [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

node.js
    curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/pause \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.pause("ftjob-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const fineTune = await openai.fineTuning.jobs.pause("ftjob-abc123");
    
      console.log(fineTune);
    }
    main();

Response
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "gpt-4o-mini-2024-07-18",
      "created_at": 1721764800,
      "fine_tuned_model": null,
      "organization_id": "org-123",
      "result_files": [],
      "status": "paused",
      "validation_file": "file-abc123",
      "training_file": "file-abc123"
    }

Training format for chat models using the supervised method


---------------------------------------------------------------

The per-line training example of a fine-tuning input file for chat models using the supervised method.

[](#fine-tuning/chat-input-functions)

functions

Deprecated

array

A list of functions the model may generate JSON inputs for.

Show properties

[](#fine-tuning/chat-input-messages)

messages

array

Show possible types

[](#fine-tuning/chat-input-parallel_tool_calls)

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

[](#fine-tuning/chat-input-tools)

tools

array

A list of tools the model may generate JSON inputs for.

Show properties

OBJECT Training format for chat models using the supervised method
    {
      "messages": [
        { "role": "user", "content": "What is the weather in San Francisco?" },
        {
          "role": "assistant",
          "tool_calls": [
            {
              "id": "call_id",
              "type": "function",
              "function": {
                "name": "get_current_weather",
                "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"
              }
            }
          ]
        }
      ],
      "parallel_tool_calls": false,
      "tools": [
        {
          "type": "function",
          "function": {
            "name": "get_current_weather",
            "description": "Get the current weather",
            "parameters": {
              "type": "object",
              "properties": {
                "location": {
                    "type": "string",
                    "description": "The city and country, eg. San Francisco, USA"
                },
                "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }
              },
              "required": ["location", "format"]
            }
          }
        }
      ]
    }

Training format for chat models using the preference method


---------------------------------------------------------------

The per-line training example of a fine-tuning input file for chat models using the dpo method.

[](#fine-tuning/preference-input-input)

input

object

Show properties

[](#fine-tuning/preference-input-non_preferred_completion)

non\_preferred\_completion

array

The non-preferred completion message for the output.

Show possible types

[](#fine-tuning/preference-input-preferred_completion)

preferred\_completion

array

The preferred completion message for the output.

Show possible types

OBJECT Training format for chat models using the preference method
    {
      "input": {
        "messages": [
          { "role": "user", "content": "What is the weather in San Francisco?" }
        ]
      },
      "preferred_completion": [
        {
          "role": "assistant",
          "content": "The weather in San Francisco is 70 degrees Fahrenheit."
        }
      ],
      "non_preferred_completion": [
        {
          "role": "assistant",
          "content": "The weather in San Francisco is 21 degrees Celsius."
        }
      ]
    }

Training format for reasoning models using the reinforcement method


-----------------------------------------------------------------------

Per-line training example for reinforcement fine-tuning. Note that `messages` and `tools` are the only reserved keywords. Any other arbitrary key-value data can be included on training datapoints and will be available to reference during grading under the `{{ item.XXX }}` template variable.

[](#fine-tuning/reinforcement-input-messages)

messages

array

Show possible types

[](#fine-tuning/reinforcement-input-tools)

tools

array

A list of tools the model may generate JSON inputs for.

Show properties

OBJECT Training format for reasoning models using the reinforcement method
    {
      "messages": [
        {
          "role": "user",
          "content": "Your task is to take a chemical in SMILES format and predict the number of hydrobond bond donors and acceptors according to Lipinkski's rule. CCN(CC)CCC(=O)c1sc(N)nc1C"
        },
      ],
      # Any other JSON data can be inserted into an example and referenced during RFT grading
      "reference_answer": {
        "donor_bond_counts": 5,
        "acceptor_bond_counts": 7
      }
    }

The fine-tuning job object


------------------------------

The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.

[](#fine-tuning/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

[](#fine-tuning/object-error)

error

object or null

For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.

Show properties

[](#fine-tuning/object-estimated_finish)

estimated\_finish

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.

[](#fine-tuning/object-fine_tuned_model)

fine\_tuned\_model

string or null

The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.

[](#fine-tuning/object-finished_at)

finished\_at

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.

[](#fine-tuning/object-hyperparameters)

hyperparameters

object

The hyperparameters used for the fine-tuning job. This value will only be returned when running `supervised` jobs.

Show properties

[](#fine-tuning/object-id)

id

string

The object identifier, which can be referenced in the API endpoints.

[](#fine-tuning/object-integrations)

integrations

array or null

A list of integrations to enable for this fine-tuning job.

Show possible types

[](#fine-tuning/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#fine-tuning/object-method)

method

object

The method used for fine-tuning.

Show properties

[](#fine-tuning/object-model)

model

string

The base model that is being fine-tuned.

[](#fine-tuning/object-object)

object

string

The object type, which is always "fine\_tuning.job".

[](#fine-tuning/object-organization_id)

organization\_id

string

The organization that owns the fine-tuning job.

[](#fine-tuning/object-result_files)

result\_files

array

The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).

[](#fine-tuning/object-seed)

seed

integer

The seed used for the fine-tuning job.

[](#fine-tuning/object-status)

status

string

The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.

[](#fine-tuning/object-trained_tokens)

trained\_tokens

integer or null

The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.

[](#fine-tuning/object-training_file)

training\_file

string

The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents).

[](#fine-tuning/object-validation_file)

validation\_file

string or null

The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents).

OBJECT The fine-tuning job object
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "davinci-002",
      "created_at": 1692661014,
      "finished_at": 1692661190,
      "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
      "organization_id": "org-123",
      "result_files": [
          "file-abc123"
      ],
      "status": "succeeded",
      "validation_file": null,
      "training_file": "file-abc123",
      "hyperparameters": {
          "n_epochs": 4,
          "batch_size": 1,
          "learning_rate_multiplier": 1.0
      },
      "trained_tokens": 5768,
      "integrations": [],
      "seed": 0,
      "estimated_finish": 0,
      "method": {
        "type": "supervised",
        "supervised": {
          "hyperparameters": {
            "n_epochs": 4,
            "batch_size": 1,
            "learning_rate_multiplier": 1.0
          }
        }
      },
      "metadata": {
        "key": "value"
      }
    }

The fine-tuning job event object


------------------------------------

Fine-tuning job event object

[](#fine-tuning/event-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

[](#fine-tuning/event-object-data)

data

object

The data associated with the event.

[](#fine-tuning/event-object-id)

id

string

The object identifier.

[](#fine-tuning/event-object-level)

level

string

The log level of the event.

[](#fine-tuning/event-object-message)

message

string

The message of the event.

[](#fine-tuning/event-object-object)

object

string

The object type, which is always "fine\_tuning.job.event".

[](#fine-tuning/event-object-type)

type

string

The type of event.

OBJECT The fine-tuning job event object
    {
      "object": "fine_tuning.job.event",
      "id": "ftevent-abc123"
      "created_at": 1677610602,
      "level": "info",
      "message": "Created fine-tuning job",
      "data": {},
      "type": "message"
    }

The fine-tuning job checkpoint object


-----------------------------------------

The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.

[](#fine-tuning/checkpoint-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the checkpoint was created.

[](#fine-tuning/checkpoint-object-fine_tuned_model_checkpoint)

fine\_tuned\_model\_checkpoint

string

The name of the fine-tuned checkpoint model that is created.

[](#fine-tuning/checkpoint-object-fine_tuning_job_id)

fine\_tuning\_job\_id

string

The name of the fine-tuning job that this checkpoint was created from.

[](#fine-tuning/checkpoint-object-id)

id

string

The checkpoint identifier, which can be referenced in the API endpoints.

[](#fine-tuning/checkpoint-object-metrics)

metrics

object

Metrics at the step number during the fine-tuning job.

Show properties

[](#fine-tuning/checkpoint-object-object)

object

string

The object type, which is always "fine\_tuning.job.checkpoint".

[](#fine-tuning/checkpoint-object-step_number)

step\_number

integer

The step number that the checkpoint was created at.

OBJECT The fine-tuning job checkpoint object
    {
      "object": "fine_tuning.job.checkpoint",
      "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
      "created_at": 1712211699,
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
      "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
      "metrics": {
        "step": 88,
        "train_loss": 0.478,
        "train_mean_token_accuracy": 0.924,
        "valid_loss": 10.112,
        "valid_mean_token_accuracy": 0.145,
        "full_valid_loss": 0.567,
        "full_valid_mean_token_accuracy": 0.944
      },
      "step_number": 88
    }

The fine-tuned model checkpoint permission object


-----------------------------------------------------

The `checkpoint.permission` object represents a permission for a fine-tuned model checkpoint.

[](#fine-tuning/permission-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the permission was created.

[](#fine-tuning/permission-object-id)

id

string

The permission identifier, which can be referenced in the API endpoints.

[](#fine-tuning/permission-object-object)

object

string

The object type, which is always "checkpoint.permission".

[](#fine-tuning/permission-object-project_id)

project\_id

string

The project identifier that the permission is for.

OBJECT The fine-tuned model checkpoint permission object
    {
      "object": "checkpoint.permission",
      "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
      "created_at": 1712211699,
      "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
    }

Graders


-----------

Manage and run graders in the OpenAI platform. Related guide: [Graders](/docs/guides/graders)

String Check Grader


-----------------------

A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.

[](#graders/string-check-input)

input

string

The input text. This may include template strings.

[](#graders/string-check-name)

name

string

The name of the grader.

[](#graders/string-check-operation)

operation

string

The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.

[](#graders/string-check-reference)

reference

string

The reference text. This may include template strings.

[](#graders/string-check-type)

type

string

The object type, which is always `string_check`.

OBJECT String Check Grader
    {
      "type": "string_check",
      "name": "Example string check grader",
      "input": "{{sample.output_text}}",
      "reference": "{{item.label}}",
      "operation": "eq"
    }

Text Similarity Grader


--------------------------

A TextSimilarityGrader object which grades text based on similarity metrics.

[](#graders/text-similarity-evaluation_metric)

evaluation\_metric

string

The evaluation metric to use. One of `fuzzy_match`, `bleu`, `gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`, or `rouge_l`.

[](#graders/text-similarity-input)

input

string

The text being graded.

[](#graders/text-similarity-name)

name

string

The name of the grader.

[](#graders/text-similarity-reference)

reference

string

The text being graded against.

[](#graders/text-similarity-type)

type

string

The type of grader.

OBJECT Text Similarity Grader
    {
      "type": "text_similarity",
      "name": "Example text similarity grader",
      "input": "{{sample.output_text}}",
      "reference": "{{item.label}}",
      "evaluation_metric": "fuzzy_match"
    }

Score Model Grader


----------------------

A ScoreModelGrader object that uses a model to assign a score to the input.

[](#graders/score-model-input)

input

array

The input text. This may include template strings.

Show properties

[](#graders/score-model-model)

model

string

The model to use for the evaluation.

[](#graders/score-model-name)

name

string

The name of the grader.

[](#graders/score-model-range)

range

array

The range of the score. Defaults to `[0, 1]`.

[](#graders/score-model-sampling_params)

sampling\_params

object

The sampling parameters for the model.

[](#graders/score-model-type)

type

string

The object type, which is always `score_model`.

OBJECT Score Model Grader
    {
        "type": "score_model",
        "name": "Example score model grader",
        "input": [
            {
                "role": "user",
                "content": (
                    "Score how close the reference answer is to the model answer. Score 1.0 if they are the same and 0.0 if they are different."
                    " Return just a floating point score\n\n"
                    " Reference answer: {{item.label}}\n\n"
                    " Model answer: {{sample.output_text}}"
                ),
            }
        ],
        "model": "gpt-4o-2024-08-06",
        "sampling_params": {
            "temperature": 1,
            "top_p": 1,
            "seed": 42,
        },
    }

Label Model Grader


----------------------

A LabelModelGrader object which uses a model to assign labels to each item in the evaluation.

[](#graders/label-model-input)

input

array

Show properties

[](#graders/label-model-labels)

labels

array

The labels to assign to each item in the evaluation.

[](#graders/label-model-model)

model

string

The model to use for the evaluation. Must support structured outputs.

[](#graders/label-model-name)

name

string

The name of the grader.

[](#graders/label-model-passing_labels)

passing\_labels

array

The labels that indicate a passing result. Must be a subset of labels.

[](#graders/label-model-type)

type

string

The object type, which is always `label_model`.

OBJECT Label Model Grader
    {
      "name": "First label grader",
      "type": "label_model",
      "model": "gpt-4o-2024-08-06",
      "input": [
        {
          "type": "message",
          "role": "system",
          "content": {
            "type": "input_text",
            "text": "Classify the sentiment of the following statement as one of positive, neutral, or negative"
          }
        },
        {
          "type": "message",
          "role": "user",
          "content": {
            "type": "input_text",
            "text": "Statement: {{item.response}}"
          }
        }
      ],
      "passing_labels": [
        "positive"
      ],
      "labels": [
        "positive",
        "neutral",
        "negative"
      ]
    }

Python Grader


-----------------

A PythonGrader object that runs a python script on the input.

[](#graders/python-image_tag)

image\_tag

string

The image tag to use for the python script.

[](#graders/python-name)

name

string

The name of the grader.

[](#graders/python-source)

source

string

The source code of the python script.

[](#graders/python-type)

type

string

The object type, which is always `python`.

OBJECT Python Grader
    {
      "type": "python",
      "name": "Example python grader",
      "image_tag": "2025-05-08",
      "source": """
    def grade(sample: dict, item: dict) -> float:
        \"""
        Returns 1.0 if `output_text` equals `label`, otherwise 0.0.
        \"""
        output = sample.get("output_text")
        label = item.get("label")
        return 1.0 if output == label else 0.0
    """,
    }

Multi Grader


----------------

A MultiGrader object combines the output of multiple graders to produce a single score.

[](#graders/multi-calculate_output)

calculate\_output

string

A formula to calculate the output based on grader results.

[](#graders/multi-graders)

graders

object

[](#graders/multi-name)

name

string

The name of the grader.

[](#graders/multi-type)

type

string

The type of grader.

OBJECT Multi Grader
    {
      "type": "multi",
      "name": "example multi grader",
      "graders": [
        {
          "type": "text_similarity",
          "name": "example text similarity grader",
          "input": "The graded text",
          "reference": "The reference text",
          "evaluation_metric": "fuzzy_match"
        },
        {
          "type": "string_check",
          "name": "Example string check grader",
          "input": "{{sample.output_text}}",
          "reference": "{{item.label}}",
          "operation": "eq"
        }
      ],
      "calculate_output": "0.5 * text_similarity_score +  0.5 * string_check_score)"
    }

Run grader

Beta


--------------------

postÂ https://api.openai.com/v1/fine\_tuning/alpha/graders/run

Run a grader.

#### Request body

[](#graders-run-grader)

grader

object

Required

The grader used for the fine-tuning job.

Show possible types

[](#graders-run-model_sample)

model\_sample

string

Required

The model sample to be evaluated.

[](#graders-run-reference_answer)

reference\_answer

string / object / array / number

Required

The reference answer for the evaluation.

Show possible types

#### Returns

The results from the grader run.

Example request

curl
    curl -X POST https://api.openai.com/v1/fine_tuning/alpha/graders/run \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "grader": {
          "type": "score_model",
          "name": "Example score model grader",
          "input": [
            {
              "role": "user",
              "content": "Score how close the reference answer is to the model answer. Score 1.0 if they are the same and 0.0 if they are different. Return just a floating point score\n\nReference answer: {{item.reference_answer}}\n\nModel answer: {{sample.output_text}}"
            }
          ],
          "model": "gpt-4o-2024-08-06",
          "sampling_params": {
            "temperature": 1,
            "top_p": 1,
            "seed": 42
          }
        },
        "reference_answer": "fuzzy wuzzy was a bear",
        "model_sample": "fuzzy wuzzy was a bear"
      }'

Response
    {
      "reward": 1.0,
      "metadata": {
        "name": "Example score model grader",
        "type": "score_model",
        "errors": {
          "formula_parse_error": false,
          "sample_parse_error": false,
          "truncated_observation_error": false,
          "unresponsive_reward_error": false,
          "invalid_variable_error": false,
          "other_error": false,
          "python_grader_server_error": false,
          "python_grader_server_error_type": null,
          "python_grader_runtime_error": false,
          "python_grader_runtime_error_details": null,
          "model_grader_server_error": false,
          "model_grader_refusal_error": false,
          "model_grader_parse_error": false,
          "model_grader_server_error_details": null
        },
        "execution_time": 4.365238428115845,
        "scores": {},
        "token_usage": {
          "prompt_tokens": 190,
          "total_tokens": 324,
          "completion_tokens": 134,
          "cached_tokens": 0
        },
        "sampled_model_name": "gpt-4o-2024-08-06"
      },
      "sub_rewards": {},
      "model_grader_token_usage_per_model": {
        "gpt-4o-2024-08-06": {
          "prompt_tokens": 190,
          "total_tokens": 324,
          "completion_tokens": 134,
          "cached_tokens": 0
        }
      }
    }

Validate grader

Beta


-------------------------

postÂ https://api.openai.com/v1/fine\_tuning/alpha/graders/validate

Validate a grader.

#### Request body

[](#graders-validate-grader)

grader

object

Required

The grader used for the fine-tuning job.

Show possible types

#### Returns

The validated grader object.

Example request

curl
    curl https://api.openai.com/v1/fine_tuning/alpha/graders/validate \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "grader": {
          "type": "string_check",
          "name": "Example string check grader",
          "input": "{{sample.output_text}}",
          "reference": "{{item.label}}",
          "operation": "eq"
        }
      }'

Response
    {
      "grader": {
        "type": "string_check",
        "name": "Example string check grader",
        "input": "{{sample.output_text}}",
        "reference": "{{item.label}}",
        "operation": "eq"
      }
    }

Batch


---------

Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount. Related guide: [Batch](/docs/guides/batch)

Create batch


----------------

postÂ https://api.openai.com/v1/batches

Creates and executes a batch from an uploaded file of requests

#### Request body

[](#batch-create-completion_window)

completion\_window

string

Required

The time frame within which the batch should be processed. Currently only `24h` is supported.

[](#batch-create-endpoint)

endpoint

string

Required

The endpoint to be used for all requests in the batch. Currently `/v1/responses`, `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.

[](#batch-create-input_file_id)

input\_file\_id

string

Required

The ID of an uploaded file that contains requests for the new batch.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.

[](#batch-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

#### Returns

The created [Batch](/docs/api-reference/batch/object) object.

Example request

curl
    curl https://api.openai.com/v1/batches \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "input_file_id": "file-abc123",
        "endpoint": "/v1/chat/completions",
        "completion_window": "24h"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    client.batches.create(
      input_file_id="file-abc123",
      endpoint="/v1/chat/completions",
      completion_window="24h"
    )
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const batch = await openai.batches.create({
        input_file_id: "file-abc123",
        endpoint: "/v1/chat/completions",
        completion_window: "24h"
      });
    
      console.log(batch);
    }
    
    main();

Response
    {
      "id": "batch_abc123",
      "object": "batch",
      "endpoint": "/v1/chat/completions",
      "errors": null,
      "input_file_id": "file-abc123",
      "completion_window": "24h",
      "status": "validating",
      "output_file_id": null,
      "error_file_id": null,
      "created_at": 1711471533,
      "in_progress_at": null,
      "expires_at": null,
      "finalizing_at": null,
      "completed_at": null,
      "failed_at": null,
      "expired_at": null,
      "cancelling_at": null,
      "cancelled_at": null,
      "request_counts": {
        "total": 0,
        "completed": 0,
        "failed": 0
      },
      "metadata": {
        "customer_id": "user_123456789",
        "batch_description": "Nightly eval job",
      }
    }

Retrieve batch


------------------

getÂ https://api.openai.com/v1/batches/{batch\_id}

Retrieves a batch.

#### Path parameters

[](#batch-retrieve-batch_id)

batch\_id

string

Required

The ID of the batch to retrieve.

#### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/batches/batch_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
    from openai import OpenAI
    client = OpenAI()
    
    client.batches.retrieve("batch_abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const batch = await openai.batches.retrieve("batch_abc123");
    
      console.log(batch);
    }
    
    main();

Response
    {
      "id": "batch_abc123",
      "object": "batch",
      "endpoint": "/v1/completions",
      "errors": null,
      "input_file_id": "file-abc123",
      "completion_window": "24h",
      "status": "completed",
      "output_file_id": "file-cvaTdG",
      "error_file_id": "file-HOWS94",
      "created_at": 1711471533,
      "in_progress_at": 1711471538,
      "expires_at": 1711557933,
      "finalizing_at": 1711493133,
      "completed_at": 1711493163,
      "failed_at": null,
      "expired_at": null,
      "cancelling_at": null,
      "cancelled_at": null,
      "request_counts": {
        "total": 100,
        "completed": 95,
        "failed": 5
      },
      "metadata": {
        "customer_id": "user_123456789",
        "batch_description": "Nightly eval job",
      }
    }

Cancel batch


----------------

postÂ https://api.openai.com/v1/batches/{batch\_id}/cancel

Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.

#### Path parameters

[](#batch-cancel-batch_id)

batch\_id

string

Required

The ID of the batch to cancel.

#### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/batches/batch_abc123/cancel \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -X POST
    from openai import OpenAI
    client = OpenAI()
    
    client.batches.cancel("batch_abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const batch = await openai.batches.cancel("batch_abc123");
    
      console.log(batch);
    }
    
    main();

Response
    {
      "id": "batch_abc123",
      "object": "batch",
      "endpoint": "/v1/chat/completions",
      "errors": null,
      "input_file_id": "file-abc123",
      "completion_window": "24h",
      "status": "cancelling",
      "output_file_id": null,
      "error_file_id": null,
      "created_at": 1711471533,
      "in_progress_at": 1711471538,
      "expires_at": 1711557933,
      "finalizing_at": null,
      "completed_at": null,
      "failed_at": null,
      "expired_at": null,
      "cancelling_at": 1711475133,
      "cancelled_at": null,
      "request_counts": {
        "total": 100,
        "completed": 23,
        "failed": 1
      },
      "metadata": {
        "customer_id": "user_123456789",
        "batch_description": "Nightly eval job",
      }
    }

List batch


--------------

getÂ https://api.openai.com/v1/batches

List your organization's batches.

#### Query parameters

[](#batch-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#batch-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of paginated [Batch](/docs/api-reference/batch/object) objects.

Example request

curl
    curl https://api.openai.com/v1/batches?limit=2 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"
    from openai import OpenAI
    client = OpenAI()
    
    client.batches.list()
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const list = await openai.batches.list();
    
      for await (const batch of list) {
        console.log(batch);
      }
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "batch_abc123",
          "object": "batch",
          "endpoint": "/v1/chat/completions",
          "errors": null,
          "input_file_id": "file-abc123",
          "completion_window": "24h",
          "status": "completed",
          "output_file_id": "file-cvaTdG",
          "error_file_id": "file-HOWS94",
          "created_at": 1711471533,
          "in_progress_at": 1711471538,
          "expires_at": 1711557933,
          "finalizing_at": 1711493133,
          "completed_at": 1711493163,
          "failed_at": null,
          "expired_at": null,
          "cancelling_at": null,
          "cancelled_at": null,
          "request_counts": {
            "total": 100,
            "completed": 95,
            "failed": 5
          },
          "metadata": {
            "customer_id": "user_123456789",
            "batch_description": "Nightly job",
          }
        },
        { ... },
      ],
      "first_id": "batch_abc123",
      "last_id": "batch_abc456",
      "has_more": true
    }

The batch object


--------------------

[](#batch/object-cancelled_at)

cancelled\_at

integer

The Unix timestamp (in seconds) for when the batch was cancelled.

[](#batch/object-cancelling_at)

cancelling\_at

integer

The Unix timestamp (in seconds) for when the batch started cancelling.

[](#batch/object-completed_at)

completed\_at

integer

The Unix timestamp (in seconds) for when the batch was completed.

[](#batch/object-completion_window)

completion\_window

string

The time frame within which the batch should be processed.

[](#batch/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the batch was created.

[](#batch/object-endpoint)

endpoint

string

The OpenAI API endpoint used by the batch.

[](#batch/object-error_file_id)

error\_file\_id

string

The ID of the file containing the outputs of requests with errors.

[](#batch/object-errors)

errors

object

Show properties

[](#batch/object-expired_at)

expired\_at

integer

The Unix timestamp (in seconds) for when the batch expired.

[](#batch/object-expires_at)

expires\_at

integer

The Unix timestamp (in seconds) for when the batch will expire.

[](#batch/object-failed_at)

failed\_at

integer

The Unix timestamp (in seconds) for when the batch failed.

[](#batch/object-finalizing_at)

finalizing\_at

integer

The Unix timestamp (in seconds) for when the batch started finalizing.

[](#batch/object-id)

id

string

[](#batch/object-in_progress_at)

in\_progress\_at

integer

The Unix timestamp (in seconds) for when the batch started processing.

[](#batch/object-input_file_id)

input\_file\_id

string

The ID of the input file for the batch.

[](#batch/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#batch/object-object)

object

string

The object type, which is always `batch`.

[](#batch/object-output_file_id)

output\_file\_id

string

The ID of the file containing the outputs of successfully executed requests.

[](#batch/object-request_counts)

request\_counts

object

The request counts for different statuses within the batch.

Show properties

[](#batch/object-status)

status

string

The current status of the batch.

OBJECT The batch object
    {
      "id": "batch_abc123",
      "object": "batch",
      "endpoint": "/v1/completions",
      "errors": null,
      "input_file_id": "file-abc123",
      "completion_window": "24h",
      "status": "completed",
      "output_file_id": "file-cvaTdG",
      "error_file_id": "file-HOWS94",
      "created_at": 1711471533,
      "in_progress_at": 1711471538,
      "expires_at": 1711557933,
      "finalizing_at": 1711493133,
      "completed_at": 1711493163,
      "failed_at": null,
      "expired_at": null,
      "cancelling_at": null,
      "cancelled_at": null,
      "request_counts": {
        "total": 100,
        "completed": 95,
        "failed": 5
      },
      "metadata": {
        "customer_id": "user_123456789",
        "batch_description": "Nightly eval job",
      }
    }

The request input object


----------------------------

The per-line object of the batch input file

[](#batch/request-input-custom_id)

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.

[](#batch/request-input-method)

method

string

The HTTP method to be used for the request. Currently only `POST` is supported.

[](#batch/request-input-url)

url

string

The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.

OBJECT The request input object

    {"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}

The request output object


-----------------------------

The per-line object of the batch output and error files

[](#batch/request-output-custom_id)

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs.

[](#batch/request-output-error)

error

object or null

For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.

Show properties

[](#batch/request-output-id)

id

string

[](#batch/request-output-response)

response

object or null

Show properties

OBJECT The request output object

    {"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}

Files


---------

Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).

Upload file


---------------

postÂ https://api.openai.com/v1/files

Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

Please [contact us](https://help.openai.com/) if you need to increase these storage limits.

#### Request body

[](#files-create-file)

file

file

Required

The File object (not file name) to be uploaded.

[](#files-create-purpose)

purpose

string

Required

The intended purpose of the uploaded file. One of: - `assistants`: Used in the Assistants API - `batch`: Used in the Batch API - `fine-tune`: Used for fine-tuning - `vision`: Images used for vision fine-tuning - `user_data`: Flexible file type for any purpose - `evals`: Used for eval data sets

#### Returns

The uploaded [File](/docs/api-reference/files/object) object.

Example request

node.js
    curl https://api.openai.com/v1/files \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -F purpose="fine-tune" \
      -F file="@mydata.jsonl"
    from openai import OpenAI
    client = OpenAI()
    
    client.files.create(
      file=open("mydata.jsonl", "rb"),
      purpose="fine-tune"
    )
    import fs from "fs";
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const file = await openai.files.create({
        file: fs.createReadStream("mydata.jsonl"),
        purpose: "fine-tune",
      });
    
      console.log(file);
    }
    
    main();

Response
    {
      "id": "file-abc123",
      "object": "file",
      "bytes": 120000,
      "created_at": 1677610602,
      "filename": "mydata.jsonl",
      "purpose": "fine-tune",
    }

List files


--------------

getÂ https://api.openai.com/v1/files

Returns a list of files.

#### Query parameters

[](#files-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#files-list-limit)

limit

integer

Optional

Defaults to 10000

A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.

[](#files-list-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

[](#files-list-purpose)

purpose

string

Optional

Only return files with the given purpose.

#### Returns

A list of [File](/docs/api-reference/files/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/files \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.files.list()
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const list = await openai.files.list();
    
      for await (const file of list) {
        console.log(file);
      }
    }
    
    main();

Response
    {
      "data": [
        {
          "id": "file-abc123",
          "object": "file",
          "bytes": 175,
          "created_at": 1613677385,
          "filename": "salesOverview.pdf",
          "purpose": "assistants",
        },
        {
          "id": "file-abc123",
          "object": "file",
          "bytes": 140,
          "created_at": 1613779121,
          "filename": "puppy.jsonl",
          "purpose": "fine-tune",
        }
      ],
      "object": "list"
    }

Retrieve file


-----------------

getÂ https://api.openai.com/v1/files/{file\_id}

Returns information about a specific file.

#### Path parameters

[](#files-retrieve-file_id)

file\_id

string

Required

The ID of the file to use for this request.

#### Returns

The [File](/docs/api-reference/files/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/files/file-abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.files.retrieve("file-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const file = await openai.files.retrieve("file-abc123");
    
      console.log(file);
    }
    
    main();

Response
    {
      "id": "file-abc123",
      "object": "file",
      "bytes": 120000,
      "created_at": 1677610602,
      "filename": "mydata.jsonl",
      "purpose": "fine-tune",
    }

Delete file


---------------

deleteÂ https://api.openai.com/v1/files/{file\_id}

Delete a file.

#### Path parameters

[](#files-delete-file_id)

file\_id

string

Required

The ID of the file to use for this request.

#### Returns

Deletion status.

Example request

node.js
    curl https://api.openai.com/v1/files/file-abc123 \
      -X DELETE \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.files.delete("file-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const file = await openai.files.del("file-abc123");
    
      console.log(file);
    }
    
    main();

Response
    {
      "id": "file-abc123",
      "object": "file",
      "deleted": true
    }

Retrieve file content


-------------------------

getÂ https://api.openai.com/v1/files/{file\_id}/content

Returns the contents of the specified file.

#### Path parameters

[](#files-retrieve-contents-file_id)

file\_id

string

Required

The ID of the file to use for this request.

#### Returns

The file content.

Example request

node.js
    curl https://api.openai.com/v1/files/file-abc123/content \
      -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
    from openai import OpenAI
    client = OpenAI()
    
    content = client.files.content("file-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const file = await openai.files.content("file-abc123");
    
      console.log(file);
    }
    
    main();

The file object


-------------------

The `File` object represents a document that has been uploaded to OpenAI.

[](#files/object-bytes)

bytes

integer

The size of the file, in bytes.

[](#files/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the file was created.

[](#files/object-expires_at)

expires\_at

integer

The Unix timestamp (in seconds) for when the file will expire.

[](#files/object-filename)

filename

string

The name of the file.

[](#files/object-id)

id

string

The file identifier, which can be referenced in the API endpoints.

[](#files/object-object)

object

string

The object type, which is always `file`.

[](#files/object-purpose)

purpose

string

The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results` and `vision`.

[](#files/object-status)

status

Deprecated

string

Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.

[](#files/object-status_details)

status\_details

Deprecated

string

Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.

OBJECT The file object
    {
      "id": "file-abc123",
      "object": "file",
      "bytes": 120000,
      "created_at": 1677610602,
      "expires_at": 1680202602,
      "filename": "salesOverview.pdf",
      "purpose": "assistants",
    }

Uploads


-----------

Allows you to upload large files in multiple parts.

Create upload


-----------------

postÂ https://api.openai.com/v1/uploads

Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.

Once you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.

For certain `purpose` values, the correct `mime_type` must be specified. Please refer to documentation for the [supported MIME types for your use case](/docs/assistants/tools/file-search#supported-files).

For guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).

#### Request body

[](#uploads-create-bytes)

bytes

integer

Required

The number of bytes in the file you are uploading.

[](#uploads-create-filename)

filename

string

Required

The name of the file to upload.

[](#uploads-create-mime_type)

mime\_type

string

Required

The MIME type of the file.

This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.

[](#uploads-create-purpose)

purpose

string

Required

The intended purpose of the uploaded file.

See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).

#### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `pending`.

Example request

curl
    curl https://api.openai.com/v1/uploads \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "purpose": "fine-tune",
        "filename": "training_examples.jsonl",
        "bytes": 2147483648,
        "mime_type": "text/jsonl"
      }'

Response
    {
      "id": "upload_abc123",
      "object": "upload",
      "bytes": 2147483648,
      "created_at": 1719184911,
      "filename": "training_examples.jsonl",
      "purpose": "fine-tune",
      "status": "pending",
      "expires_at": 1719127296
    }

Add upload part


-------------------

postÂ https://api.openai.com/v1/uploads/{upload\_id}/parts

Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object) object. A Part represents a chunk of bytes from the file you are trying to upload.

Each Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.

It is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you [complete the Upload](/docs/api-reference/uploads/complete).

#### Path parameters

[](#uploads-add-part-upload_id)

upload\_id

string

Required

The ID of the Upload.

#### Request body

[](#uploads-add-part-data)

data

file

Required

The chunk of bytes for this Part.

#### Returns

The upload [Part](/docs/api-reference/uploads/part-object) object.

Example request

curl
    curl https://api.openai.com/v1/uploads/upload_abc123/parts
      -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."

Response
    {
      "id": "part_def456",
      "object": "upload.part",
      "created_at": 1719185911,
      "upload_id": "upload_abc123"
    }

Complete upload


-------------------

postÂ https://api.openai.com/v1/uploads/{upload\_id}/complete

Completes the [Upload](/docs/api-reference/uploads/object).

Within the returned Upload object, there is a nested [File](/docs/api-reference/files/object) object that is ready to use in the rest of the platform.

You can specify the order of the Parts by passing in an ordered list of the Part IDs.

The number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is completed.

#### Path parameters

[](#uploads-complete-upload_id)

upload\_id

string

Required

The ID of the Upload.

#### Request body

[](#uploads-complete-part_ids)

part\_ids

array

Required

The ordered list of Part IDs.

[](#uploads-complete-md5)

md5

string

Optional

The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.

#### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `completed` with an additional `file` property containing the created usable File object.

Example request

curl
    curl https://api.openai.com/v1/uploads/upload_abc123/complete
      -d '{
        "part_ids": ["part_def456", "part_ghi789"]
      }'

Response
    {
      "id": "upload_abc123",
      "object": "upload",
      "bytes": 2147483648,
      "created_at": 1719184911,
      "filename": "training_examples.jsonl",
      "purpose": "fine-tune",
      "status": "completed",
      "expires_at": 1719127296,
      "file": {
        "id": "file-xyz321",
        "object": "file",
        "bytes": 2147483648,
        "created_at": 1719186911,
        "filename": "training_examples.jsonl",
        "purpose": "fine-tune",
      }
    }

Cancel upload


-----------------

postÂ https://api.openai.com/v1/uploads/{upload\_id}/cancel

Cancels the Upload. No Parts may be added after an Upload is cancelled.

#### Path parameters

[](#uploads-cancel-upload_id)

upload\_id

string

Required

The ID of the Upload.

#### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `cancelled`.

Example request

curl

    curl https://api.openai.com/v1/uploads/upload_abc123/cancel

Response
    {
      "id": "upload_abc123",
      "object": "upload",
      "bytes": 2147483648,
      "created_at": 1719184911,
      "filename": "training_examples.jsonl",
      "purpose": "fine-tune",
      "status": "cancelled",
      "expires_at": 1719127296
    }

The upload object


---------------------

The Upload object can accept byte chunks in the form of Parts.

[](#uploads/object-bytes)

bytes

integer

The intended number of bytes to be uploaded.

[](#uploads/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

[](#uploads/object-expires_at)

expires\_at

integer

The Unix timestamp (in seconds) for when the Upload will expire.

[](#uploads/object-file)

file

undefined or null

The ready File object after the Upload is completed.

[](#uploads/object-filename)

filename

string

The name of the file to be uploaded.

[](#uploads/object-id)

id

string

The Upload unique identifier, which can be referenced in API endpoints.

[](#uploads/object-object)

object

string

The object type, which is always "upload".

[](#uploads/object-purpose)

purpose

string

The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose) for acceptable values.

[](#uploads/object-status)

status

string

The status of the Upload.

OBJECT The upload object
    {
      "id": "upload_abc123",
      "object": "upload",
      "bytes": 2147483648,
      "created_at": 1719184911,
      "filename": "training_examples.jsonl",
      "purpose": "fine-tune",
      "status": "completed",
      "expires_at": 1719127296,
      "file": {
        "id": "file-xyz321",
        "object": "file",
        "bytes": 2147483648,
        "created_at": 1719186911,
        "filename": "training_examples.jsonl",
        "purpose": "fine-tune",
      }
    }

The upload part object


--------------------------

The upload Part represents a chunk of bytes we can add to an Upload object.

[](#uploads/part-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the Part was created.

[](#uploads/part-object-id)

id

string

The upload Part unique identifier, which can be referenced in API endpoints.

[](#uploads/part-object-object)

object

string

The object type, which is always `upload.part`.

[](#uploads/part-object-upload_id)

upload\_id

string

The ID of the Upload object that this Part was added to.

OBJECT The upload part object
    {
        "id": "part_def456",
        "object": "upload.part",
        "created_at": 1719186911,
        "upload_id": "upload_abc123"
    }

Models


----------

List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.

List models


---------------

getÂ https://api.openai.com/v1/models

Lists the currently available models, and provides basic information about each one such as the owner and availability.

#### Returns

A list of [model](/docs/api-reference/models/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/models \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.models.list()
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const list = await openai.models.list();
    
      for await (const model of list) {
        console.log(model);
      }
    }
    main();
    using System;
    
    using OpenAI.Models;
    
    OpenAIModelClient client = new(
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    foreach (var model in client.GetModels().Value)
    {
        Console.WriteLine(model.Id);
    }

Response
    {
      "object": "list",
      "data": [
        {
          "id": "model-id-0",
          "object": "model",
          "created": 1686935002,
          "owned_by": "organization-owner"
        },
        {
          "id": "model-id-1",
          "object": "model",
          "created": 1686935002,
          "owned_by": "organization-owner",
        },
        {
          "id": "model-id-2",
          "object": "model",
          "created": 1686935002,
          "owned_by": "openai"
        },
      ],
      "object": "list"
    }

Retrieve model


------------------

getÂ https://api.openai.com/v1/models/{model}

Retrieves a model instance, providing basic information about the model such as the owner and permissioning.

#### Path parameters

[](#models-retrieve-model)

model

string

Required

The ID of the model to use for this request

#### Returns

The [model](/docs/api-reference/models/object) object matching the specified ID.

Example request

gpt-4.1

node.js
    curl https://api.openai.com/v1/models/gpt-4.1 \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.models.retrieve("gpt-4.1")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const model = await openai.models.retrieve("gpt-4.1");
    
      console.log(model);
    }
    
    main();
    using System;
    using System.ClientModel;
    
    using OpenAI.Models;
    
      OpenAIModelClient client = new(
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    ClientResult<OpenAIModel> model = client.GetModel("babbage-002");
    Console.WriteLine(model.Value.Id);

Response
    {
      "id": "gpt-4.1",
      "object": "model",
      "created": 1686935002,
      "owned_by": "openai"
    }

Delete a fine-tuned model


-----------------------------

deleteÂ https://api.openai.com/v1/models/{model}

Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.

#### Path parameters

[](#models-delete-model)

model

string

Required

The model to delete

#### Returns

Deletion status.

Example request

node.js
    curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
      -X DELETE \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.models.delete("ft:gpt-4o-mini:acemeco:suffix:abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const model = await openai.models.del("ft:gpt-4o-mini:acemeco:suffix:abc123");
    
      console.log(model);
    }
    main();
    using System;
    using System.ClientModel;
    
    using OpenAI.Models;
    
    OpenAIModelClient client = new(
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    ClientResult success = client.DeleteModel("ft:gpt-4o-mini:acemeco:suffix:abc123");
    Console.WriteLine(success);

Response
    {
      "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
      "object": "model",
      "deleted": true
    }

The model object


--------------------

Describes an OpenAI model offering that can be used with the API.

[](#models/object-created)

created

integer

The Unix timestamp (in seconds) when the model was created.

[](#models/object-id)

id

string

The model identifier, which can be referenced in the API endpoints.

[](#models/object-object)

object

string

The object type, which is always "model".

[](#models/object-owned_by)

owned\_by

string

The organization that owns the model.

OBJECT The model object
    {
      "id": "gpt-4.1",
      "object": "model",
      "created": 1686935002,
      "owned_by": "openai"
    }

Moderations


---------------

Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories. Related guide: [Moderations](/docs/guides/moderation)

Create moderation


---------------------

postÂ https://api.openai.com/v1/moderations

Classifies if text and/or image inputs are potentially harmful. Learn more in the [moderation guide](/docs/guides/moderation).

#### Request body

[](#moderations-create-input)

input

string or array

Required

Input (or inputs) to classify. Can be a single string, an array of strings, or an array of multi-modal input objects similar to other models.

Show possible types

[](#moderations-create-model)

model

string

Optional

Defaults to omni-moderation-latest

The content moderation model you would like to use. Learn more in [the moderation guide](/docs/guides/moderation), and learn about available models [here](/docs/models#moderation).

#### Returns

A [moderation](/docs/api-reference/moderations/object) object.

Single stringSingle stringImage and textImage and text

Example request

node.js
    curl https://api.openai.com/v1/moderations \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "input": "I want to kill them."
      }'
    from openai import OpenAI
    client = OpenAI()
    
    moderation = client.moderations.create(input="I want to kill them.")
    print(moderation)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const moderation = await openai.moderations.create({ input: "I want to kill them." });
    
      console.log(moderation);
    }
    main();
    using System;
    using System.ClientModel;
    
    using OpenAI.Moderations;
    
    ModerationClient client = new(
        model: "omni-moderation-latest",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    ClientResult<ModerationResult> moderation = client.ClassifyText("I want to kill them.");

Response
    {
      "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
      "model": "text-moderation-007",
      "results": [
        {
          "flagged": true,
          "categories": {
            "sexual": false,
            "hate": false,
            "harassment": true,
            "self-harm": false,
            "sexual/minors": false,
            "hate/threatening": false,
            "violence/graphic": false,
            "self-harm/intent": false,
            "self-harm/instructions": false,
            "harassment/threatening": true,
            "violence": true
          },
          "category_scores": {
            "sexual": 0.000011726012417057063,
            "hate": 0.22706663608551025,
            "harassment": 0.5215635299682617,
            "self-harm": 2.227119921371923e-6,
            "sexual/minors": 7.107352217872176e-8,
            "hate/threatening": 0.023547329008579254,
            "violence/graphic": 0.00003391829886822961,
            "self-harm/intent": 1.646940972932498e-6,
            "self-harm/instructions": 1.1198755256458526e-9,
            "harassment/threatening": 0.5694745779037476,
            "violence": 0.9971134662628174
          }
        }
      ]
    }

The moderation object


-------------------------

Represents if a given text input is potentially harmful.

[](#moderations/object-id)

id

string

The unique identifier for the moderation request.

[](#moderations/object-model)

model

string

The model used to generate the moderation results.

[](#moderations/object-results)

results

array

A list of moderation objects.

Show properties

OBJECT The moderation object
    {
      "id": "modr-0d9740456c391e43c445bf0f010940c7",
      "model": "omni-moderation-latest",
      "results": [
        {
          "flagged": true,
          "categories": {
            "harassment": true,
            "harassment/threatening": true,
            "sexual": false,
            "hate": false,
            "hate/threatening": false,
            "illicit": false,
            "illicit/violent": false,
            "self-harm/intent": false,
            "self-harm/instructions": false,
            "self-harm": false,
            "sexual/minors": false,
            "violence": true,
            "violence/graphic": true
          },
          "category_scores": {
            "harassment": 0.8189693396524255,
            "harassment/threatening": 0.804985420696006,
            "sexual": 1.573112165348997e-6,
            "hate": 0.007562942636942845,
            "hate/threatening": 0.004208854591835476,
            "illicit": 0.030535955153511665,
            "illicit/violent": 0.008925306722380033,
            "self-harm/intent": 0.00023023930975076432,
            "self-harm/instructions": 0.0002293869201073356,
            "self-harm": 0.012598046106750154,
            "sexual/minors": 2.212566909570261e-8,
            "violence": 0.9999992735124786,
            "violence/graphic": 0.843064871157054
          },
          "category_applied_input_types": {
            "harassment": [
              "text"
            ],
            "harassment/threatening": [
              "text"
            ],
            "sexual": [
              "text",
              "image"
            ],
            "hate": [
              "text"
            ],
            "hate/threatening": [
              "text"
            ],
            "illicit": [
              "text"
            ],
            "illicit/violent": [
              "text"
            ],
            "self-harm/intent": [
              "text",
              "image"
            ],
            "self-harm/instructions": [
              "text",
              "image"
            ],
            "self-harm": [
              "text",
              "image"
            ],
            "sexual/minors": [
              "text"
            ],
            "violence": [
              "text",
              "image"
            ],
            "violence/graphic": [
              "text",
              "image"
            ]
          }
        }
      ]
    }

Vector stores


-----------------

Vector stores power semantic search for the Retrieval API and the `file_search` tool in the Responses and Assistants APIs.

Related guide: [File Search](/docs/assistants/tools/file-search)

Create vector store


-----------------------

postÂ https://api.openai.com/v1/vector\_stores

Create a vector store.

#### Request body

[](#vector-stores-create-chunking_strategy)

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty.

Show possible types

[](#vector-stores-create-expires_after)

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

[](#vector-stores-create-file_ids)

file\_ids

array

Optional

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

[](#vector-stores-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#vector-stores-create-name)

name

string

Optional

The name of the vector store.

#### Returns

A [vector store](/docs/api-reference/vector-stores/object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
        "name": "Support FAQ"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    vector_store = client.vector_stores.create(
      name="Support FAQ"
    )
    print(vector_store)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStore = await openai.vectorStores.create({
        name: "Support FAQ"
      });
      console.log(vectorStore);
    }
    
    main();

Response
    {
      "id": "vs_abc123",
      "object": "vector_store",
      "created_at": 1699061776,
      "name": "Support FAQ",
      "bytes": 139920,
      "file_counts": {
        "in_progress": 0,
        "completed": 3,
        "failed": 0,
        "cancelled": 0,
        "total": 3
      }
    }

List vector stores


----------------------

getÂ https://api.openai.com/v1/vector\_stores

Returns a list of vector stores.

#### Query parameters

[](#vector-stores-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#vector-stores-list-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#vector-stores-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#vector-stores-list-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [vector store](/docs/api-reference/vector-stores/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_stores = client.vector_stores.list()
    print(vector_stores)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStores = await openai.vectorStores.list();
      console.log(vectorStores);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "vs_abc123",
          "object": "vector_store",
          "created_at": 1699061776,
          "name": "Support FAQ",
          "bytes": 139920,
          "file_counts": {
            "in_progress": 0,
            "completed": 3,
            "failed": 0,
            "cancelled": 0,
            "total": 3
          }
        },
        {
          "id": "vs_abc456",
          "object": "vector_store",
          "created_at": 1699061776,
          "name": "Support FAQ v2",
          "bytes": 139920,
          "file_counts": {
            "in_progress": 0,
            "completed": 3,
            "failed": 0,
            "cancelled": 0,
            "total": 3
          }
        }
      ],
      "first_id": "vs_abc123",
      "last_id": "vs_abc456",
      "has_more": false
    }

Retrieve vector store


-------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Retrieves a vector store.

#### Path parameters

[](#vector-stores-retrieve-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store to retrieve.

#### Returns

The [vector store](/docs/api-reference/vector-stores/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_store = client.vector_stores.retrieve(
      vector_store_id="vs_abc123"
    )
    print(vector_store)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStore = await openai.vectorStores.retrieve(
        "vs_abc123"
      );
      console.log(vectorStore);
    }
    
    main();

Response
    {
      "id": "vs_abc123",
      "object": "vector_store",
      "created_at": 1699061776
    }

Modify vector store


-----------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Modifies a vector store.

#### Path parameters

[](#vector-stores-modify-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store to modify.

#### Request body

[](#vector-stores-modify-expires_after)

expires\_after

object or null

Optional

The expiration policy for a vector store.

Show properties

[](#vector-stores-modify-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#vector-stores-modify-name)

name

string or null

Optional

The name of the vector store.

#### Returns

The modified [vector store](/docs/api-reference/vector-stores/object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
      -d '{
        "name": "Support FAQ"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    vector_store = client.vector_stores.update(
      vector_store_id="vs_abc123",
      name="Support FAQ"
    )
    print(vector_store)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStore = await openai.vectorStores.update(
        "vs_abc123",
        {
          name: "Support FAQ"
        }
      );
      console.log(vectorStore);
    }
    
    main();

Response
    {
      "id": "vs_abc123",
      "object": "vector_store",
      "created_at": 1699061776,
      "name": "Support FAQ",
      "bytes": 139920,
      "file_counts": {
        "in_progress": 0,
        "completed": 3,
        "failed": 0,
        "cancelled": 0,
        "total": 3
      }
    }

Delete vector store


-----------------------

deleteÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Delete a vector store.

#### Path parameters

[](#vector-stores-delete-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store to delete.

#### Returns

Deletion status

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -X DELETE
    from openai import OpenAI
    client = OpenAI()
    
    deleted_vector_store = client.vector_stores.delete(
      vector_store_id="vs_abc123"
    )
    print(deleted_vector_store)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const deletedVectorStore = await openai.vectorStores.del(
        "vs_abc123"
      );
      console.log(deletedVectorStore);
    }
    
    main();

Response
    {
      id: "vs_abc123",
      object: "vector_store.deleted",
      deleted: true
    }

Search vector store


-----------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/search

Search a vector store for relevant chunks based on a query and file attributes filter.

#### Path parameters

[](#vector-stores-search-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store to search.

#### Request body

[](#vector-stores-search-query)

query

string or array

Required

A query string for a search

[](#vector-stores-search-filters)

filters

object

Optional

A filter to apply based on file attributes.

Show possible types

[](#vector-stores-search-max_num_results)

max\_num\_results

integer

Optional

Defaults to 10

The maximum number of results to return. This number should be between 1 and 50 inclusive.

[](#vector-stores-search-ranking_options)

ranking\_options

object

Optional

Ranking options for search.

Show properties

[](#vector-stores-search-rewrite_query)

rewrite\_query

boolean

Optional

Defaults to false

Whether to rewrite the natural language query for vector search.

#### Returns

A page of search results from the vector store.

Example request

curl
    curl -X POST \
    https://api.openai.com/v1/vector_stores/vs_abc123/search \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{"query": "What is the return policy?", "filters": {...}}'

Response
    {
      "object": "vector_store.search_results.page",
      "search_query": "What is the return policy?",
      "data": [
        {
          "file_id": "file_123",
          "filename": "document.pdf",
          "score": 0.95,
          "attributes": {
            "author": "John Doe",
            "date": "2023-01-01"
          },
          "content": [
            {
              "type": "text",
              "text": "Relevant chunk"
            }
          ]
        },
        {
          "file_id": "file_456",
          "filename": "notes.txt",
          "score": 0.89,
          "attributes": {
            "author": "Jane Smith",
            "date": "2023-01-02"
          },
          "content": [
            {
              "type": "text",
              "text": "Sample text content from the vector store."
            }
          ]
        }
      ],
      "has_more": false,
      "next_page": null
    }

The vector store object


---------------------------

A vector store is a collection of processed files can be used by the `file_search` tool.

[](#vector-stores/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the vector store was created.

[](#vector-stores/object-expires_after)

expires\_after

object

The expiration policy for a vector store.

Show properties

[](#vector-stores/object-expires_at)

expires\_at

integer or null

The Unix timestamp (in seconds) for when the vector store will expire.

[](#vector-stores/object-file_counts)

file\_counts

object

Show properties

[](#vector-stores/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#vector-stores/object-last_active_at)

last\_active\_at

integer or null

The Unix timestamp (in seconds) for when the vector store was last active.

[](#vector-stores/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#vector-stores/object-name)

name

string

The name of the vector store.

[](#vector-stores/object-object)

object

string

The object type, which is always `vector_store`.

[](#vector-stores/object-status)

status

string

The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.

[](#vector-stores/object-usage_bytes)

usage\_bytes

integer

The total number of bytes used by the files in the vector store.

OBJECT The vector store object
    {
      "id": "vs_123",
      "object": "vector_store",
      "created_at": 1698107661,
      "usage_bytes": 123456,
      "last_active_at": 1698107661,
      "name": "my_vector_store",
      "status": "completed",
      "file_counts": {
        "in_progress": 0,
        "completed": 100,
        "cancelled": 0,
        "failed": 0,
        "total": 100
      },
      "last_used_at": 1698107661
    }

Vector store files


----------------------

Vector store files represent files inside a vector store.

Related guide: [File Search](/docs/assistants/tools/file-search)

Create vector store file


----------------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Create a vector store file by attaching a [File](/docs/api-reference/files) to a [vector store](/docs/api-reference/vector-stores/object).

#### Path parameters

[](#vector-stores-files-createfile-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store for which to create a File.

#### Request body

[](#vector-stores-files-createfile-file_id)

file\_id

string

Required

A [File](/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.

[](#vector-stores-files-createfile-attributes)

attributes

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.

[](#vector-stores-files-createfile-chunking_strategy)

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

#### Returns

A [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
        -H "Authorization: Bearer $OPENAI_API_KEY" \
        -H "Content-Type: application/json" \
        -H "OpenAI-Beta: assistants=v2" \
        -d '{
          "file_id": "file-abc123"
        }'
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_file = client.vector_stores.files.create(
      vector_store_id="vs_abc123",
      file_id="file-abc123"
    )
    print(vector_store_file)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const myVectorStoreFile = await openai.vectorStores.files.create(
        "vs_abc123",
        {
          file_id: "file-abc123"
        }
      );
      console.log(myVectorStoreFile);
    }
    
    main();

Response
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "created_at": 1699061776,
      "usage_bytes": 1234,
      "vector_store_id": "vs_abcd",
      "status": "completed",
      "last_error": null
    }

List vector store files


---------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Returns a list of vector store files.

#### Path parameters

[](#vector-stores-files-listfiles-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

#### Query parameters

[](#vector-stores-files-listfiles-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#vector-stores-files-listfiles-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#vector-stores-files-listfiles-filter)

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

[](#vector-stores-files-listfiles-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#vector-stores-files-listfiles-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_files = client.vector_stores.files.list(
      vector_store_id="vs_abc123"
    )
    print(vector_store_files)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStoreFiles = await openai.vectorStores.files.list(
        "vs_abc123"
      );
      console.log(vectorStoreFiles);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "file-abc123",
          "object": "vector_store.file",
          "created_at": 1699061776,
          "vector_store_id": "vs_abc123"
        },
        {
          "id": "file-abc456",
          "object": "vector_store.file",
          "created_at": 1699061776,
          "vector_store_id": "vs_abc123"
        }
      ],
      "first_id": "file-abc123",
      "last_id": "file-abc456",
      "has_more": false
    }

Retrieve vector store file


------------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Retrieves a vector store file.

#### Path parameters

[](#vector-stores-files-getfile-file_id)

file\_id

string

Required

The ID of the file being retrieved.

[](#vector-stores-files-getfile-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

#### Returns

The [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_file = client.vector_stores.files.retrieve(
      vector_store_id="vs_abc123",
      file_id="file-abc123"
    )
    print(vector_store_file)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStoreFile = await openai.vectorStores.files.retrieve(
        "vs_abc123",
        "file-abc123"
      );
      console.log(vectorStoreFile);
    }
    
    main();

Response
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "created_at": 1699061776,
      "vector_store_id": "vs_abcd",
      "status": "completed",
      "last_error": null
    }

Retrieve vector store file content


--------------------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}/content

Retrieve the parsed contents of a vector store file.

#### Path parameters

[](#vector-stores-files-getcontent-file_id)

file\_id

string

Required

The ID of the file within the vector store.

[](#vector-stores-files-getcontent-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store.

#### Returns

The parsed contents of the specified vector store file.

Example request

curl
    curl \
    https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123/content \
    -H "Authorization: Bearer $OPENAI_API_KEY"

Response
    {
      "file_id": "file-abc123",
      "filename": "example.txt",
      "attributes": {"key": "value"},
      "content": [
        {"type": "text", "text": "..."},
        ...
      ]
    }

Update vector store file attributes


---------------------------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Update attributes on a vector store file.

#### Path parameters

[](#vector-stores-files-updateattributes-file_id)

file\_id

string

Required

The ID of the file to update attributes.

[](#vector-stores-files-updateattributes-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store the file belongs to.

#### Request body

[](#vector-stores-files-updateattributes-attributes)

attributes

map

Required

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.

#### Returns

The updated [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl
    curl https://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id} \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{"attributes": {"key1": "value1", "key2": 2}}'

Response
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "usage_bytes": 1234,
      "created_at": 1699061776,
      "vector_store_id": "vs_abcd",
      "status": "completed",
      "last_error": null,
      "chunking_strategy": {...},
      "attributes": {"key1": "value1", "key2": 2}
    }

Delete vector store file


----------------------------

deleteÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](/docs/api-reference/files/delete) endpoint.

#### Path parameters

[](#vector-stores-files-deletefile-file_id)

file\_id

string

Required

The ID of the file to delete.

[](#vector-stores-files-deletefile-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

#### Returns

Deletion status

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -X DELETE
    from openai import OpenAI
    client = OpenAI()
    
    deleted_vector_store_file = client.vector_stores.files.delete(
        vector_store_id="vs_abc123",
        file_id="file-abc123"
    )
    print(deleted_vector_store_file)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const deletedVectorStoreFile = await openai.vectorStores.files.del(
        "vs_abc123",
        "file-abc123"
      );
      console.log(deletedVectorStoreFile);
    }
    
    main();

Response
    {
      id: "file-abc123",
      object: "vector_store.file.deleted",
      deleted: true
    }

The vector store file object

Beta


--------------------------------------

A list of files attached to a vector store.

[](#vector-stores-files/file-object-attributes)

attributes

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.

[](#vector-stores-files/file-object-chunking_strategy)

chunking\_strategy

object

The strategy used to chunk the file.

Show possible types

[](#vector-stores-files/file-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the vector store file was created.

[](#vector-stores-files/file-object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#vector-stores-files/file-object-last_error)

last\_error

object or null

The last error associated with this vector store file. Will be `null` if there are no errors.

Show properties

[](#vector-stores-files/file-object-object)

object

string

The object type, which is always `vector_store.file`.

[](#vector-stores-files/file-object-status)

status

string

The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.

[](#vector-stores-files/file-object-usage_bytes)

usage\_bytes

integer

The total vector store usage in bytes. Note that this may be different from the original file size.

[](#vector-stores-files/file-object-vector_store_id)

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

OBJECT The vector store file object
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "usage_bytes": 1234,
      "created_at": 1698107661,
      "vector_store_id": "vs_abc123",
      "status": "completed",
      "last_error": null,
      "chunking_strategy": {
        "type": "static",
        "static": {
          "max_chunk_size_tokens": 800,
          "chunk_overlap_tokens": 400
        }
      }
    }

Vector store file batches


-----------------------------

Vector store file batches represent operations to add multiple files to a vector store. Related guide: [File Search](/docs/assistants/tools/file-search)

Create vector store file batch


----------------------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches

Create a vector store file batch.

#### Path parameters

[](#vector-stores-file-batches-createbatch-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store for which to create a File Batch.

#### Request body

[](#vector-stores-file-batches-createbatch-file_ids)

file\_ids

array

Required

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

[](#vector-stores-file-batches-createbatch-attributes)

attributes

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.

[](#vector-stores-file-batches-createbatch-chunking_strategy)

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

#### Returns

A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
        -H "Authorization: Bearer $OPENAI_API_KEY" \
        -H "Content-Type: application/json \
        -H "OpenAI-Beta: assistants=v2" \
        -d '{
          "file_ids": ["file-abc123", "file-abc456"]
        }'
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_file_batch = client.vector_stores.file_batches.create(
      vector_store_id="vs_abc123",
      file_ids=["file-abc123", "file-abc456"]
    )
    print(vector_store_file_batch)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const myVectorStoreFileBatch = await openai.vectorStores.fileBatches.create(
        "vs_abc123",
        {
          file_ids: ["file-abc123", "file-abc456"]
        }
      );
      console.log(myVectorStoreFileBatch);
    }
    
    main();

Response
    {
      "id": "vsfb_abc123",
      "object": "vector_store.file_batch",
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123",
      "status": "in_progress",
      "file_counts": {
        "in_progress": 1,
        "completed": 1,
        "failed": 0,
        "cancelled": 0,
        "total": 0,
      }
    }

Retrieve vector store file batch


------------------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}

Retrieves a vector store file batch.

#### Path parameters

[](#vector-stores-file-batches-getbatch-batch_id)

batch\_id

string

Required

The ID of the file batch being retrieved.

[](#vector-stores-file-batches-getbatch-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

#### Returns

The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_file_batch = client.vector_stores.file_batches.retrieve(
      vector_store_id="vs_abc123",
      batch_id="vsfb_abc123"
    )
    print(vector_store_file_batch)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStoreFileBatch = await openai.vectorStores.fileBatches.retrieve(
        "vs_abc123",
        "vsfb_abc123"
      );
      console.log(vectorStoreFileBatch);
    }
    
    main();

Response
    {
      "id": "vsfb_abc123",
      "object": "vector_store.file_batch",
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123",
      "status": "in_progress",
      "file_counts": {
        "in_progress": 1,
        "completed": 1,
        "failed": 0,
        "cancelled": 0,
        "total": 0,
      }
    }

Cancel vector store file batch


----------------------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/cancel

Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.

#### Path parameters

[](#vector-stores-file-batches-cancelbatch-batch_id)

batch\_id

string

Required

The ID of the file batch to cancel.

[](#vector-stores-file-batches-cancelbatch-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

#### Returns

The modified vector store file batch object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -X POST
    from openai import OpenAI
    client = OpenAI()
    
    deleted_vector_store_file_batch = client.vector_stores.file_batches.cancel(
        vector_store_id="vs_abc123",
        file_batch_id="vsfb_abc123"
    )
    print(deleted_vector_store_file_batch)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const deletedVectorStoreFileBatch = await openai.vectorStores.fileBatches.cancel(
        "vs_abc123",
        "vsfb_abc123"
      );
      console.log(deletedVectorStoreFileBatch);
    }
    
    main();

Response
    {
      "id": "vsfb_abc123",
      "object": "vector_store.file_batch",
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123",
      "status": "in_progress",
      "file_counts": {
        "in_progress": 12,
        "completed": 3,
        "failed": 0,
        "cancelled": 0,
        "total": 15,
      }
    }

List vector store files in a batch


--------------------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/files

Returns a list of vector store files in a batch.

#### Path parameters

[](#vector-stores-file-batches-listbatchfiles-batch_id)

batch\_id

string

Required

The ID of the file batch that the files belong to.

[](#vector-stores-file-batches-listbatchfiles-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

#### Query parameters

[](#vector-stores-file-batches-listbatchfiles-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#vector-stores-file-batches-listbatchfiles-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#vector-stores-file-batches-listbatchfiles-filter)

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

[](#vector-stores-file-batches-listbatchfiles-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#vector-stores-file-batches-listbatchfiles-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_files = client.vector_stores.file_batches.list_files(
      vector_store_id="vs_abc123",
      batch_id="vsfb_abc123"
    )
    print(vector_store_files)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStoreFiles = await openai.vectorStores.fileBatches.listFiles(
        "vs_abc123",
        "vsfb_abc123"
      );
      console.log(vectorStoreFiles);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "file-abc123",
          "object": "vector_store.file",
          "created_at": 1699061776,
          "vector_store_id": "vs_abc123"
        },
        {
          "id": "file-abc456",
          "object": "vector_store.file",
          "created_at": 1699061776,
          "vector_store_id": "vs_abc123"
        }
      ],
      "first_id": "file-abc123",
      "last_id": "file-abc456",
      "has_more": false
    }

The vector store files batch object

Beta


---------------------------------------------

A batch of files attached to a vector store.

[](#vector-stores-file-batches/batch-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the vector store files batch was created.

[](#vector-stores-file-batches/batch-object-file_counts)

file\_counts

object

Show properties

[](#vector-stores-file-batches/batch-object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#vector-stores-file-batches/batch-object-object)

object

string

The object type, which is always `vector_store.file_batch`.

[](#vector-stores-file-batches/batch-object-status)

status

string

The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.

[](#vector-stores-file-batches/batch-object-vector_store_id)

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

OBJECT The vector store files batch object
    {
      "id": "vsfb_123",
      "object": "vector_store.files_batch",
      "created_at": 1698107661,
      "vector_store_id": "vs_abc123",
      "status": "completed",
      "file_counts": {
        "in_progress": 0,
        "completed": 100,
        "failed": 0,
        "cancelled": 0,
        "total": 100
      }
    }

Assistants

Beta


--------------------

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

Create assistant

Beta


--------------------------

postÂ https://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

#### Request body

[](#assistants-createassistant-model)

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

[](#assistants-createassistant-description)

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

[](#assistants-createassistant-instructions)

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

[](#assistants-createassistant-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#assistants-createassistant-name)

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

[](#assistants-createassistant-reasoning_effort)

reasoning\_effort

string or null

Optional

Defaults to medium

**o-series models only**

Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `low`, `medium`, and `high`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

[](#assistants-createassistant-response_format)

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#assistants-createassistant-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

[](#assistants-createassistant-tool_resources)

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

[](#assistants-createassistant-tools)

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

[](#assistants-createassistant-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

#### Returns

An [assistant](/docs/api-reference/assistants/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

node.js
    curl "https://api.openai.com/v1/assistants" \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
        "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
        "name": "Math Tutor",
        "tools": [{"type": "code_interpreter"}],
        "model": "gpt-4o"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    my_assistant = client.beta.assistants.create(
        instructions="You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
        name="Math Tutor",
        tools=[{"type": "code_interpreter"}],
        model="gpt-4o",
    )
    print(my_assistant)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const myAssistant = await openai.beta.assistants.create({
        instructions:
          "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
        name: "Math Tutor",
        tools: [{ type: "code_interpreter" }],
        model: "gpt-4o",
      });
    
      console.log(myAssistant);
    }
    
    main();

Response
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1698984975,
      "name": "Math Tutor",
      "description": null,
      "model": "gpt-4o",
      "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    }

List assistants

Beta


-------------------------

getÂ https://api.openai.com/v1/assistants

Returns a list of assistants.

#### Query parameters

[](#assistants-listassistants-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#assistants-listassistants-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#assistants-listassistants-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#assistants-listassistants-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [assistant](/docs/api-reference/assistants/object) objects.

Example request

node.js
    curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    my_assistants = client.beta.assistants.list(
        order="desc",
        limit="20",
    )
    print(my_assistants.data)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const myAssistants = await openai.beta.assistants.list({
        order: "desc",
        limit: "20",
      });
    
      console.log(myAssistants.data);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "asst_abc123",
          "object": "assistant",
          "created_at": 1698982736,
          "name": "Coding Tutor",
          "description": null,
          "model": "gpt-4o",
          "instructions": "You are a helpful assistant designed to make me better at coding!",
          "tools": [],
          "tool_resources": {},
          "metadata": {},
          "top_p": 1.0,
          "temperature": 1.0,
          "response_format": "auto"
        },
        {
          "id": "asst_abc456",
          "object": "assistant",
          "created_at": 1698982718,
          "name": "My Assistant",
          "description": null,
          "model": "gpt-4o",
          "instructions": "You are a helpful assistant designed to make me better at coding!",
          "tools": [],
          "tool_resources": {},
          "metadata": {},
          "top_p": 1.0,
          "temperature": 1.0,
          "response_format": "auto"
        },
        {
          "id": "asst_abc789",
          "object": "assistant",
          "created_at": 1698982643,
          "name": null,
          "description": null,
          "model": "gpt-4o",
          "instructions": null,
          "tools": [],
          "tool_resources": {},
          "metadata": {},
          "top_p": 1.0,
          "temperature": 1.0,
          "response_format": "auto"
        }
      ],
      "first_id": "asst_abc123",
      "last_id": "asst_abc789",
      "has_more": false
    }

Retrieve assistant

Beta


----------------------------

getÂ https://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

#### Path parameters

[](#assistants-getassistant-assistant_id)

assistant\_id

string

Required

The ID of the assistant to retrieve.

#### Returns

The [assistant](/docs/api-reference/assistants/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/assistants/asst_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    my_assistant = client.beta.assistants.retrieve("asst_abc123")
    print(my_assistant)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const myAssistant = await openai.beta.assistants.retrieve(
        "asst_abc123"
      );
    
      console.log(myAssistant);
    }
    
    main();

Response
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1699009709,
      "name": "HR Helper",
      "description": null,
      "model": "gpt-4o",
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
      "tools": [
        {
          "type": "file_search"
        }
      ],
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    }

Modify assistant

Beta


--------------------------

postÂ https://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

#### Path parameters

[](#assistants-modifyassistant-assistant_id)

assistant\_id

string

Required

The ID of the assistant to modify.

#### Request body

[](#assistants-modifyassistant-description)

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

[](#assistants-modifyassistant-instructions)

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

[](#assistants-modifyassistant-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#assistants-modifyassistant-model)

model

string

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

[](#assistants-modifyassistant-name)

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

[](#assistants-modifyassistant-reasoning_effort)

reasoning\_effort

string or null

Optional

Defaults to medium

**o-series models only**

Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `low`, `medium`, and `high`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

[](#assistants-modifyassistant-response_format)

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#assistants-modifyassistant-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

[](#assistants-modifyassistant-tool_resources)

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

[](#assistants-modifyassistant-tools)

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

[](#assistants-modifyassistant-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

#### Returns

The modified [assistant](/docs/api-reference/assistants/object) object.

Example request

node.js
    curl https://api.openai.com/v1/assistants/asst_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
          "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
          "tools": [{"type": "file_search"}],
          "model": "gpt-4o"
        }'
    from openai import OpenAI
    client = OpenAI()
    
    my_updated_assistant = client.beta.assistants.update(
      "asst_abc123",
      instructions="You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      name="HR Helper",
      tools=[{"type": "file_search"}],
      model="gpt-4o"
    )
    
    print(my_updated_assistant)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const myUpdatedAssistant = await openai.beta.assistants.update(
        "asst_abc123",
        {
          instructions:
            "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
          name: "HR Helper",
          tools: [{ type: "file_search" }],
          model: "gpt-4o"
        }
      );
    
      console.log(myUpdatedAssistant);
    }
    
    main();

Response
    {
      "id": "asst_123",
      "object": "assistant",
      "created_at": 1699009709,
      "name": "HR Helper",
      "description": null,
      "model": "gpt-4o",
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [
        {
          "type": "file_search"
        }
      ],
      "tool_resources": {
        "file_search": {
          "vector_store_ids": []
        }
      },
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    }

Delete assistant

Beta


--------------------------

deleteÂ https://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

#### Path parameters

[](#assistants-deleteassistant-assistant_id)

assistant\_id

string

Required

The ID of the assistant to delete.

#### Returns

Deletion status

Example request

node.js
    curl https://api.openai.com/v1/assistants/asst_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -X DELETE
    from openai import OpenAI
    client = OpenAI()
    
    response = client.beta.assistants.delete("asst_abc123")
    print(response)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const response = await openai.beta.assistants.del("asst_abc123");
    
      console.log(response);
    }
    main();

Response
    {
      "id": "asst_abc123",
      "object": "assistant.deleted",
      "deleted": true
    }

The assistant object

Beta


------------------------------

Represents an `assistant` that can call the model and use tools.

[](#assistants/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

[](#assistants/object-description)

description

string or null

The description of the assistant. The maximum length is 512 characters.

[](#assistants/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#assistants/object-instructions)

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

[](#assistants/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#assistants/object-model)

model

string

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

[](#assistants/object-name)

name

string or null

The name of the assistant. The maximum length is 256 characters.

[](#assistants/object-object)

object

string

The object type, which is always `assistant`.

[](#assistants/object-response_format)

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#assistants/object-temperature)

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

[](#assistants/object-tool_resources)

tool\_resources

object or null

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

[](#assistants/object-tools)

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

[](#assistants/object-top_p)

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

OBJECT The assistant object
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1698984975,
      "name": "Math Tutor",
      "description": null,
      "model": "gpt-4o",
      "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    }

Threads

Beta


-----------------

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

Create thread

Beta


-----------------------

postÂ https://api.openai.com/v1/threads

Create a thread.

#### Request body

[](#threads-createthread-messages)

messages

array

Optional

A list of [messages](/docs/api-reference/messages) to start the thread with.

Show properties

[](#threads-createthread-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#threads-createthread-tool_resources)

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

#### Returns

A [thread](/docs/api-reference/threads) object.

EmptyEmptyMessagesMessages

Example request

node.js
    curl https://api.openai.com/v1/threads \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d ''
    from openai import OpenAI
    client = OpenAI()
    
    empty_thread = client.beta.threads.create()
    print(empty_thread)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const emptyThread = await openai.beta.threads.create();
    
      console.log(emptyThread);
    }
    
    main();

Response
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1699012949,
      "metadata": {},
      "tool_resources": {}
    }

Retrieve thread

Beta


-------------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

#### Path parameters

[](#threads-getthread-thread_id)

thread\_id

string

Required

The ID of the thread to retrieve.

#### Returns

The [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    my_thread = client.beta.threads.retrieve("thread_abc123")
    print(my_thread)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const myThread = await openai.beta.threads.retrieve(
        "thread_abc123"
      );
    
      console.log(myThread);
    }
    
    main();

Response
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1699014083,
      "metadata": {},
      "tool_resources": {
        "code_interpreter": {
          "file_ids": []
        }
      }
    }

Modify thread

Beta


-----------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

#### Path parameters

[](#threads-modifythread-thread_id)

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

#### Request body

[](#threads-modifythread-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#threads-modifythread-tool_resources)

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

#### Returns

The modified [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
          "metadata": {
            "modified": "true",
            "user": "abc123"
          }
        }'
    from openai import OpenAI
    client = OpenAI()
    
    my_updated_thread = client.beta.threads.update(
      "thread_abc123",
      metadata={
        "modified": "true",
        "user": "abc123"
      }
    )
    print(my_updated_thread)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const updatedThread = await openai.beta.threads.update(
        "thread_abc123",
        {
          metadata: { modified: "true", user: "abc123" },
        }
      );
    
      console.log(updatedThread);
    }
    
    main();

Response
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1699014083,
      "metadata": {
        "modified": "true",
        "user": "abc123"
      },
      "tool_resources": {}
    }

Delete thread

Beta


-----------------------

deleteÂ https://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

#### Path parameters

[](#threads-deletethread-thread_id)

thread\_id

string

Required

The ID of the thread to delete.

#### Returns

Deletion status

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -X DELETE
    from openai import OpenAI
    client = OpenAI()
    
    response = client.beta.threads.delete("thread_abc123")
    print(response)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const response = await openai.beta.threads.del("thread_abc123");
    
      console.log(response);
    }
    main();

Response
    {
      "id": "thread_abc123",
      "object": "thread.deleted",
      "deleted": true
    }

The thread object

Beta


---------------------------

Represents a thread that contains [messages](/docs/api-reference/messages).

[](#threads/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

[](#threads/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#threads/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#threads/object-object)

object

string

The object type, which is always `thread`.

[](#threads/object-tool_resources)

tool\_resources

object or null

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

OBJECT The thread object
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1698107661,
      "metadata": {}
    }

Messages

Beta


------------------

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

Create message

Beta


------------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

#### Path parameters

[](#messages-createmessage-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to create a message for.

#### Request body

[](#messages-createmessage-content)

content

string or array

Required

Show possible types

[](#messages-createmessage-role)

role

string

Required

The role of the entity that is creating the message. Allowed values include:

*   `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
*   `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

[](#messages-createmessage-attachments)

attachments

array or null

Optional

A list of files attached to the message, and the tools they should be added to.

Show properties

[](#messages-createmessage-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

#### Returns

A [message](/docs/api-reference/messages/object) object.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/messages \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
          "role": "user",
          "content": "How does AI work? Explain it in simple terms."
        }'
    from openai import OpenAI
    client = OpenAI()
    
    thread_message = client.beta.threads.messages.create(
      "thread_abc123",
      role="user",
      content="How does AI work? Explain it in simple terms.",
    )
    print(thread_message)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const threadMessages = await openai.beta.threads.messages.create(
        "thread_abc123",
        { role: "user", content: "How does AI work? Explain it in simple terms." }
      );
    
      console.log(threadMessages);
    }
    
    main();

Response
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1713226573,
      "assistant_id": null,
      "thread_id": "thread_abc123",
      "run_id": null,
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "How does AI work? Explain it in simple terms.",
            "annotations": []
          }
        }
      ],
      "attachments": [],
      "metadata": {}
    }

List messages

Beta


-----------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

#### Path parameters

[](#messages-listmessages-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) the messages belong to.

#### Query parameters

[](#messages-listmessages-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#messages-listmessages-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#messages-listmessages-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#messages-listmessages-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

[](#messages-listmessages-run_id)

run\_id

string

Optional

Filter messages by the run ID that generated them.

#### Returns

A list of [message](/docs/api-reference/messages) objects.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/messages \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    thread_messages = client.beta.threads.messages.list("thread_abc123")
    print(thread_messages.data)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const threadMessages = await openai.beta.threads.messages.list(
        "thread_abc123"
      );
    
      console.log(threadMessages.data);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "msg_abc123",
          "object": "thread.message",
          "created_at": 1699016383,
          "assistant_id": null,
          "thread_id": "thread_abc123",
          "run_id": null,
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": {
                "value": "How does AI work? Explain it in simple terms.",
                "annotations": []
              }
            }
          ],
          "attachments": [],
          "metadata": {}
        },
        {
          "id": "msg_abc456",
          "object": "thread.message",
          "created_at": 1699016383,
          "assistant_id": null,
          "thread_id": "thread_abc123",
          "run_id": null,
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": {
                "value": "Hello, what is AI?",
                "annotations": []
              }
            }
          ],
          "attachments": [],
          "metadata": {}
        }
      ],
      "first_id": "msg_abc123",
      "last_id": "msg_abc456",
      "has_more": false
    }

Retrieve message

Beta


--------------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

#### Path parameters

[](#messages-getmessage-message_id)

message\_id

string

Required

The ID of the message to retrieve.

[](#messages-getmessage-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this message belongs.

#### Returns

The [message](/docs/api-reference/messages/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    message = client.beta.threads.messages.retrieve(
      message_id="msg_abc123",
      thread_id="thread_abc123",
    )
    print(message)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const message = await openai.beta.threads.messages.retrieve(
        "thread_abc123",
        "msg_abc123"
      );
    
      console.log(message);
    }
    
    main();

Response
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1699017614,
      "assistant_id": null,
      "thread_id": "thread_abc123",
      "run_id": null,
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "How does AI work? Explain it in simple terms.",
            "annotations": []
          }
        }
      ],
      "attachments": [],
      "metadata": {}
    }

Modify message

Beta


------------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

#### Path parameters

[](#messages-modifymessage-message_id)

message\_id

string

Required

The ID of the message to modify.

[](#messages-modifymessage-thread_id)

thread\_id

string

Required

The ID of the thread to which this message belongs.

#### Request body

[](#messages-modifymessage-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

#### Returns

The modified [message](/docs/api-reference/messages/object) object.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
          "metadata": {
            "modified": "true",
            "user": "abc123"
          }
        }'
    from openai import OpenAI
    client = OpenAI()
    
    message = client.beta.threads.messages.update(
      message_id="msg_abc12",
      thread_id="thread_abc123",
      metadata={
        "modified": "true",
        "user": "abc123",
      },
    )
    print(message)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const message = await openai.beta.threads.messages.update(
        "thread_abc123",
        "msg_abc123",
        {
          metadata: {
            modified: "true",
            user: "abc123",
          },
        }
      }'

Response
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1699017614,
      "assistant_id": null,
      "thread_id": "thread_abc123",
      "run_id": null,
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "How does AI work? Explain it in simple terms.",
            "annotations": []
          }
        }
      ],
      "file_ids": [],
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }

Delete message

Beta


------------------------

deleteÂ https://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Deletes a message.

#### Path parameters

[](#messages-deletemessage-message_id)

message\_id

string

Required

The ID of the message to delete.

[](#messages-deletemessage-thread_id)

thread\_id

string

Required

The ID of the thread to which this message belongs.

#### Returns

Deletion status

Example request

node.js
    curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    deleted_message = client.beta.threads.messages.delete(
      message_id="msg_abc12",
      thread_id="thread_abc123",
    )
    print(deleted_message)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const deletedMessage = await openai.beta.threads.messages.del(
        "thread_abc123",
        "msg_abc123"
      );
    
      console.log(deletedMessage);
    }

Response
    {
      "id": "msg_abc123",
      "object": "thread.message.deleted",
      "deleted": true
    }

The message object

Beta


----------------------------

Represents a message within a [thread](/docs/api-reference/threads).

[](#messages/object-assistant_id)

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message.

[](#messages/object-attachments)

attachments

array or null

A list of files attached to the message, and the tools they were added to.

Show properties

[](#messages/object-completed_at)

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

[](#messages/object-content)

content

array

The content of the message in array of text and/or images.

Show possible types

[](#messages/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

[](#messages/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#messages/object-incomplete_at)

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

[](#messages/object-incomplete_details)

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

[](#messages/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#messages/object-object)

object

string

The object type, which is always `thread.message`.

[](#messages/object-role)

role

string

The entity that produced the message. One of `user` or `assistant`.

[](#messages/object-run_id)

run\_id

string or null

The ID of the [run](/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

[](#messages/object-status)

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

[](#messages/object-thread_id)

thread\_id

string

The [thread](/docs/api-reference/threads) ID that this message belongs to.

OBJECT The message object
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1698983503,
      "thread_id": "thread_abc123",
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "Hi! How can I help you today?",
            "annotations": []
          }
        }
      ],
      "assistant_id": "asst_abc123",
      "run_id": "run_abc123",
      "attachments": [],
      "metadata": {}
    }

Runs

Beta


--------------

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

Create run

Beta


--------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

#### Path parameters

[](#runs-createrun-thread_id)

thread\_id

string

Required

The ID of the thread to run.

#### Query parameters

[](#runs-createrun-include)

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

#### Request body

[](#runs-createrun-assistant_id)

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

[](#runs-createrun-additional_instructions)

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

[](#runs-createrun-additional_messages)

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

[](#runs-createrun-instructions)

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

[](#runs-createrun-max_completion_tokens)

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

[](#runs-createrun-max_prompt_tokens)

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

[](#runs-createrun-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#runs-createrun-model)

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

[](#runs-createrun-parallel_tool_calls)

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

[](#runs-createrun-reasoning_effort)

reasoning\_effort

string or null

Optional

Defaults to medium

**o-series models only**

Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `low`, `medium`, and `high`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

[](#runs-createrun-response_format)

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#runs-createrun-stream)

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

[](#runs-createrun-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

[](#runs-createrun-tool_choice)

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model. `none` means the model will not call any tools and instead generates a message. `auto` is the default value and means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user. Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

[](#runs-createrun-tools)

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

[](#runs-createrun-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

[](#runs-createrun-truncation_strategy)

truncation\_strategy

object or null

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

#### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
        "assistant_id": "asst_abc123"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.runs.create(
      thread_id="thread_abc123",
      assistant_id="asst_abc123"
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.runs.create(
        "thread_abc123",
        { assistant_id: "asst_abc123" }
      );
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699063290,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "queued",
      "started_at": 1699063290,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699063291,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "incomplete_details": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "metadata": {},
      "usage": null,
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

Create thread and run

Beta


-------------------------------

postÂ https://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

#### Request body

[](#runs-createthreadandrun-assistant_id)

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

[](#runs-createthreadandrun-instructions)

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

[](#runs-createthreadandrun-max_completion_tokens)

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

[](#runs-createthreadandrun-max_prompt_tokens)

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

[](#runs-createthreadandrun-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#runs-createthreadandrun-model)

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

[](#runs-createthreadandrun-parallel_tool_calls)

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

[](#runs-createthreadandrun-response_format)

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#runs-createthreadandrun-stream)

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

[](#runs-createthreadandrun-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

[](#runs-createthreadandrun-thread)

thread

object

Optional

Options to create a new thread. If no thread is provided when running a request, an empty thread will be created.

Show properties

[](#runs-createthreadandrun-tool_choice)

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model. `none` means the model will not call any tools and instead generates a message. `auto` is the default value and means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user. Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

[](#runs-createthreadandrun-tool_resources)

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

[](#runs-createthreadandrun-tools)

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

[](#runs-createthreadandrun-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

[](#runs-createthreadandrun-truncation_strategy)

truncation\_strategy

object or null

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

#### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

node.js
    curl https://api.openai.com/v1/threads/runs \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
          "assistant_id": "asst_abc123",
          "thread": {
            "messages": [
              {"role": "user", "content": "Explain deep learning to a 5 year old."}
            ]
          }
        }'
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.create_and_run(
      assistant_id="asst_abc123",
      thread={
        "messages": [
          {"role": "user", "content": "Explain deep learning to a 5 year old."}
        ]
      }
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.createAndRun({
        assistant_id: "asst_abc123",
        thread: {
          messages: [
            { role: "user", content: "Explain deep learning to a 5 year old." },
          ],
        },
      });
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699076792,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "queued",
      "started_at": null,
      "expires_at": 1699077392,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": null,
      "required_action": null,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": "You are a helpful assistant.",
      "tools": [],
      "tool_resources": {},
      "metadata": {},
      "temperature": 1.0,
      "top_p": 1.0,
      "max_completion_tokens": null,
      "max_prompt_tokens": null,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "incomplete_details": null,
      "usage": null,
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

List runs

Beta


-------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

#### Path parameters

[](#runs-listruns-thread_id)

thread\_id

string

Required

The ID of the thread the run belongs to.

#### Query parameters

[](#runs-listruns-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#runs-listruns-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#runs-listruns-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#runs-listruns-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [run](/docs/api-reference/runs/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    runs = client.beta.threads.runs.list(
      "thread_abc123"
    )
    
    print(runs)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const runs = await openai.beta.threads.runs.list(
        "thread_abc123"
      );
    
      console.log(runs);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "run_abc123",
          "object": "thread.run",
          "created_at": 1699075072,
          "assistant_id": "asst_abc123",
          "thread_id": "thread_abc123",
          "status": "completed",
          "started_at": 1699075072,
          "expires_at": null,
          "cancelled_at": null,
          "failed_at": null,
          "completed_at": 1699075073,
          "last_error": null,
          "model": "gpt-4o",
          "instructions": null,
          "incomplete_details": null,
          "tools": [
            {
              "type": "code_interpreter"
            }
          ],
          "tool_resources": {
            "code_interpreter": {
              "file_ids": [
                "file-abc123",
                "file-abc456"
              ]
            }
          },
          "metadata": {},
          "usage": {
            "prompt_tokens": 123,
            "completion_tokens": 456,
            "total_tokens": 579
          },
          "temperature": 1.0,
          "top_p": 1.0,
          "max_prompt_tokens": 1000,
          "max_completion_tokens": 1000,
          "truncation_strategy": {
            "type": "auto",
            "last_messages": null
          },
          "response_format": "auto",
          "tool_choice": "auto",
          "parallel_tool_calls": true
        },
        {
          "id": "run_abc456",
          "object": "thread.run",
          "created_at": 1699063290,
          "assistant_id": "asst_abc123",
          "thread_id": "thread_abc123",
          "status": "completed",
          "started_at": 1699063290,
          "expires_at": null,
          "cancelled_at": null,
          "failed_at": null,
          "completed_at": 1699063291,
          "last_error": null,
          "model": "gpt-4o",
          "instructions": null,
          "incomplete_details": null,
          "tools": [
            {
              "type": "code_interpreter"
            }
          ],
          "tool_resources": {
            "code_interpreter": {
              "file_ids": [
                "file-abc123",
                "file-abc456"
              ]
            }
          },
          "metadata": {},
          "usage": {
            "prompt_tokens": 123,
            "completion_tokens": 456,
            "total_tokens": 579
          },
          "temperature": 1.0,
          "top_p": 1.0,
          "max_prompt_tokens": 1000,
          "max_completion_tokens": 1000,
          "truncation_strategy": {
            "type": "auto",
            "last_messages": null
          },
          "response_format": "auto",
          "tool_choice": "auto",
          "parallel_tool_calls": true
        }
      ],
      "first_id": "run_abc123",
      "last_id": "run_abc456",
      "has_more": false
    }

Retrieve run

Beta


----------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

#### Path parameters

[](#runs-getrun-run_id)

run\_id

string

Required

The ID of the run to retrieve.

[](#runs-getrun-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

#### Returns

The [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.runs.retrieve(
      thread_id="thread_abc123",
      run_id="run_abc123"
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.runs.retrieve(
        "thread_abc123",
        "run_abc123"
      );
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699075072,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699075072,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699075073,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "incomplete_details": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "metadata": {},
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

Modify run

Beta


--------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

#### Path parameters

[](#runs-modifyrun-run_id)

run\_id

string

Required

The ID of the run to modify.

[](#runs-modifyrun-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

#### Request body

[](#runs-modifyrun-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

#### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
        "metadata": {
          "user_id": "user_abc123"
        }
      }'
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.runs.update(
      thread_id="thread_abc123",
      run_id="run_abc123",
      metadata={"user_id": "user_abc123"},
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.runs.update(
        "thread_abc123",
        "run_abc123",
        {
          metadata: {
            user_id: "user_abc123",
          },
        }
      );
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699075072,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699075072,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699075073,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "incomplete_details": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "tool_resources": {
        "code_interpreter": {
          "file_ids": [
            "file-abc123",
            "file-abc456"
          ]
        }
      },
      "metadata": {
        "user_id": "user_abc123"
      },
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

Submit tool outputs to run

Beta


------------------------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

#### Path parameters

[](#runs-submittooloutputs-run_id)

run\_id

string

Required

The ID of the run that requires the tool output submission.

[](#runs-submittooloutputs-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this run belongs.

#### Request body

[](#runs-submittooloutputs-tool_outputs)

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

[](#runs-submittooloutputs-stream)

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

#### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
        "tool_outputs": [
          {
            "tool_call_id": "call_001",
            "output": "70 degrees and sunny."
          }
        ]
      }'
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.runs.submit_tool_outputs(
      thread_id="thread_123",
      run_id="run_123",
      tool_outputs=[
        {
          "tool_call_id": "call_001",
          "output": "70 degrees and sunny."
        }
      ]
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.runs.submitToolOutputs(
        "thread_123",
        "run_123",
        {
          tool_outputs: [
            {
              tool_call_id: "call_001",
              output: "70 degrees and sunny.",
            },
          ],
        }
      );
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_123",
      "object": "thread.run",
      "created_at": 1699075592,
      "assistant_id": "asst_123",
      "thread_id": "thread_123",
      "status": "queued",
      "started_at": 1699075592,
      "expires_at": 1699076192,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": null,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "tools": [
        {
          "type": "function",
          "function": {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
              "type": "object",
              "properties": {
                "location": {
                  "type": "string",
                  "description": "The city and state, e.g. San Francisco, CA"
                },
                "unit": {
                  "type": "string",
                  "enum": ["celsius", "fahrenheit"]
                }
              },
              "required": ["location"]
            }
          }
        }
      ],
      "metadata": {},
      "usage": null,
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

Cancel a run

Beta


----------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

#### Path parameters

[](#runs-cancelrun-run_id)

run\_id

string

Required

The ID of the run to cancel.

[](#runs-cancelrun-thread_id)

thread\_id

string

Required

The ID of the thread to which this run belongs.

#### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -X POST
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.runs.cancel(
      thread_id="thread_abc123",
      run_id="run_abc123"
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.runs.cancel(
        "thread_abc123",
        "run_abc123"
      );
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699076126,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "cancelling",
      "started_at": 1699076126,
      "expires_at": 1699076726,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": null,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": "You summarize books.",
      "tools": [
        {
          "type": "file_search"
        }
      ],
      "tool_resources": {
        "file_search": {
          "vector_store_ids": ["vs_123"]
        }
      },
      "metadata": {},
      "usage": null,
      "temperature": 1.0,
      "top_p": 1.0,
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

The run object

Beta


------------------------

Represents an execution run on a [thread](/docs/api-reference/threads).

[](#runs/object-assistant_id)

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run.

[](#runs/object-cancelled_at)

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

[](#runs/object-completed_at)

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

[](#runs/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

[](#runs/object-expires_at)

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

[](#runs/object-failed_at)

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

[](#runs/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#runs/object-incomplete_details)

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

[](#runs/object-instructions)

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants) used for this run.

[](#runs/object-last_error)

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

[](#runs/object-max_completion_tokens)

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

[](#runs/object-max_prompt_tokens)

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

[](#runs/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#runs/object-model)

model

string

The model that the [assistant](/docs/api-reference/assistants) used for this run.

[](#runs/object-object)

object

string

The object type, which is always `thread.run`.

[](#runs/object-parallel_tool_calls)

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

[](#runs/object-required_action)

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

[](#runs/object-response_format)

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#runs/object-started_at)

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

[](#runs/object-status)

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.

[](#runs/object-temperature)

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

[](#runs/object-thread_id)

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run.

[](#runs/object-tool_choice)

tool\_choice

string or object

Controls which (if any) tool is called by the model. `none` means the model will not call any tools and instead generates a message. `auto` is the default value and means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user. Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

[](#runs/object-tools)

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.

Show possible types

[](#runs/object-top_p)

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

[](#runs/object-truncation_strategy)

truncation\_strategy

object or null

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

[](#runs/object-usage)

usage

object or null

Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).

Show properties

OBJECT The run object
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1698107661,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699073476,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699073498,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
      "metadata": {},
      "incomplete_details": null,
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

Run steps

Beta


-------------------

Represents the steps (model and tool calls) taken during the run.

Related guide: [Assistants](/docs/assistants/overview)

List run steps

Beta


------------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

#### Path parameters

[](#run-steps-listrunsteps-run_id)

run\_id

string

Required

The ID of the run the run steps belong to.

[](#run-steps-listrunsteps-thread_id)

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

#### Query parameters

[](#run-steps-listrunsteps-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#run-steps-listrunsteps-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#run-steps-listrunsteps-include)

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

[](#run-steps-listrunsteps-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#run-steps-listrunsteps-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [run step](/docs/api-reference/run-steps/step-object) objects.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    run_steps = client.beta.threads.runs.steps.list(
        thread_id="thread_abc123",
        run_id="run_abc123"
    )
    
    print(run_steps)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const runStep = await openai.beta.threads.runs.steps.list(
        "thread_abc123",
        "run_abc123"
      );
      console.log(runStep);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "step_abc123",
          "object": "thread.run.step",
          "created_at": 1699063291,
          "run_id": "run_abc123",
          "assistant_id": "asst_abc123",
          "thread_id": "thread_abc123",
          "type": "message_creation",
          "status": "completed",
          "cancelled_at": null,
          "completed_at": 1699063291,
          "expired_at": null,
          "failed_at": null,
          "last_error": null,
          "step_details": {
            "type": "message_creation",
            "message_creation": {
              "message_id": "msg_abc123"
            }
          },
          "usage": {
            "prompt_tokens": 123,
            "completion_tokens": 456,
            "total_tokens": 579
          }
        }
      ],
      "first_id": "step_abc123",
      "last_id": "step_abc456",
      "has_more": false
    }

Retrieve run step

Beta


---------------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

#### Path parameters

[](#run-steps-getrunstep-run_id)

run\_id

string

Required

The ID of the run to which the run step belongs.

[](#run-steps-getrunstep-step_id)

step\_id

string

Required

The ID of the run step to retrieve.

[](#run-steps-getrunstep-thread_id)

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

#### Query parameters

[](#run-steps-getrunstep-include)

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

#### Returns

The [run step](/docs/api-reference/run-steps/step-object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    run_step = client.beta.threads.runs.steps.retrieve(
        thread_id="thread_abc123",
        run_id="run_abc123",
        step_id="step_abc123"
    )
    
    print(run_step)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const runStep = await openai.beta.threads.runs.steps.retrieve(
        "thread_abc123",
        "run_abc123",
        "step_abc123"
      );
      console.log(runStep);
    }
    
    main();

Response
    {
      "id": "step_abc123",
      "object": "thread.run.step",
      "created_at": 1699063291,
      "run_id": "run_abc123",
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "type": "message_creation",
      "status": "completed",
      "cancelled_at": null,
      "completed_at": 1699063291,
      "expired_at": null,
      "failed_at": null,
      "last_error": null,
      "step_details": {
        "type": "message_creation",
        "message_creation": {
          "message_id": "msg_abc123"
        }
      },
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      }
    }

The run step object

Beta


-----------------------------

Represents a step in execution of a run.

[](#run-steps/step-object-assistant_id)

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) associated with the run step.

[](#run-steps/step-object-cancelled_at)

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

[](#run-steps/step-object-completed_at)

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

[](#run-steps/step-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

[](#run-steps/step-object-expired_at)

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

[](#run-steps/step-object-failed_at)

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

[](#run-steps/step-object-id)

id

string

The identifier of the run step, which can be referenced in API endpoints.

[](#run-steps/step-object-last_error)

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

[](#run-steps/step-object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#run-steps/step-object-object)

object

string

The object type, which is always `thread.run.step`.

[](#run-steps/step-object-run_id)

run\_id

string

The ID of the [run](/docs/api-reference/runs) that this run step is a part of.

[](#run-steps/step-object-status)

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

[](#run-steps/step-object-step_details)

step\_details

object

The details of the run step.

Show possible types

[](#run-steps/step-object-thread_id)

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was run.

[](#run-steps/step-object-type)

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

[](#run-steps/step-object-usage)

usage

object or null

Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.

Show properties

OBJECT The run step object
    {
      "id": "step_abc123",
      "object": "thread.run.step",
      "created_at": 1699063291,
      "run_id": "run_abc123",
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "type": "message_creation",
      "status": "completed",
      "cancelled_at": null,
      "completed_at": 1699063291,
      "expired_at": null,
      "failed_at": null,
      "last_error": null,
      "step_details": {
        "type": "message_creation",
        "message_creation": {
          "message_id": "msg_abc123"
        }
      },
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      }
    }

Streaming

Beta


-------------------

Stream the result of executing a Run or resuming a Run after submitting tool outputs. You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun), [Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs) endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream. Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the [Assistants API quickstart](/docs/assistants/overview) to learn more.

The message delta object

Beta


----------------------------------

Represents a message delta i.e. any changed fields on a message during streaming.

[](#assistants-streaming/message-delta-object-delta)

delta

object

The delta containing the fields that have changed on the Message.

Show properties

[](#assistants-streaming/message-delta-object-id)

id

string

The identifier of the message, which can be referenced in API endpoints.

[](#assistants-streaming/message-delta-object-object)

object

string

The object type, which is always `thread.message.delta`.

OBJECT The message delta object
    {
      "id": "msg_123",
      "object": "thread.message.delta",
      "delta": {
        "content": [
          {
            "index": 0,
            "type": "text",
            "text": { "value": "Hello", "annotations": [] }
          }
        ]
      }
    }

The run step delta object

Beta


-----------------------------------

Represents a run step delta i.e. any changed fields on a run step during streaming.

[](#assistants-streaming/run-step-delta-object-delta)

delta

object

The delta containing the fields that have changed on the run step.

Show properties

[](#assistants-streaming/run-step-delta-object-id)

id

string

The identifier of the run step, which can be referenced in API endpoints.

[](#assistants-streaming/run-step-delta-object-object)

object

string

The object type, which is always `thread.run.step.delta`.

OBJECT The run step delta object
    {
      "id": "step_123",
      "object": "thread.run.step.delta",
      "delta": {
        "step_details": {
          "type": "tool_calls",
          "tool_calls": [
            {
              "index": 0,
              "id": "call_123",
              "type": "code_interpreter",
              "code_interpreter": { "input": "", "outputs": [] }
            }
          ]
        }
      }
    }

Assistant stream events

Beta


---------------------------------

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

    event: thread.created
    data: {"id": "thread_123", "object": "thread", ...}

We emit events whenever a new object is created, transitions to a new state, or is being streamed in parts (deltas). For example, we emit `thread.run.created` when a new run is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses to create a message during a run, we emit a `thread.message.created event`, a `thread.message.in_progress` event, many `thread.message.delta` events, and finally a `thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to integrate the Assistants API with streaming.

[](#assistants-streaming/events-done)

done

`data` is `[DONE]`

Occurs when a stream ends.

[](#assistants-streaming/events-error)

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

[](#assistants-streaming/events-thread-created)

thread.created

`data` is a [thread](/docs/api-reference/threads/object)

Occurs when a new [thread](/docs/api-reference/threads/object) is created.

[](#assistants-streaming/events-thread-message-completed)

thread.message.completed

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is completed.

[](#assistants-streaming/events-thread-message-created)

thread.message.created

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is created.

[](#assistants-streaming/events-thread-message-delta)

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages/object) are being streamed.

[](#assistants-streaming/events-thread-message-in_progress)

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) moves to an `in_progress` state.

[](#assistants-streaming/events-thread-message-incomplete)

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) ends before it is completed.

[](#assistants-streaming/events-thread-run-cancelled)

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is cancelled.

[](#assistants-streaming/events-thread-run-cancelling)

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `cancelling` status.

[](#assistants-streaming/events-thread-run-completed)

thread.run.completed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is completed.

[](#assistants-streaming/events-thread-run-created)

thread.run.created

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a new [run](/docs/api-reference/runs/object) is created.

[](#assistants-streaming/events-thread-run-expired)

thread.run.expired

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) expires.

[](#assistants-streaming/events-thread-run-failed)

thread.run.failed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) fails.

[](#assistants-streaming/events-thread-run-in_progress)

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to an `in_progress` status.

[](#assistants-streaming/events-thread-run-incomplete)

thread.run.incomplete

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) ends with status `incomplete`.

[](#assistants-streaming/events-thread-run-queued)

thread.run.queued

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `queued` status.

[](#assistants-streaming/events-thread-run-requires_action)

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `requires_action` status.

[](#assistants-streaming/events-thread-run-step-cancelled)

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is cancelled.

[](#assistants-streaming/events-thread-run-step-completed)

thread.run.step.completed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is completed.

[](#assistants-streaming/events-thread-run-step-created)

thread.run.step.created

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is created.

[](#assistants-streaming/events-thread-run-step-delta)

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object) are being streamed.

[](#assistants-streaming/events-thread-run-step-expired)

thread.run.step.expired

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) expires.

[](#assistants-streaming/events-thread-run-step-failed)

thread.run.step.failed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) fails.

[](#assistants-streaming/events-thread-run-step-in_progress)

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) moves to an `in_progress` state.

Administration


------------------

Programmatically manage your organization. The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes. To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints. For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)

Admin API Keys


------------------

Admin API keys enable Organization Owners to programmatically manage various aspects of their organization, including users, projects, and API keys. These keys provide administrative capabilities, such as creating, updating, and deleting users; managing projects; and overseeing API key lifecycles.

Key Features of Admin API Keys:

*   User Management: Invite new users, update roles, and remove users from the organization.
    
*   Project Management: Create, update, archive projects, and manage user assignments within projects.
    
*   API Key Oversight: List, retrieve, and delete API keys associated with projects.
    

Only Organization Owners have the authority to create and utilize Admin API keys. To manage these keys, Organization Owners can navigate to the Admin Keys section of their API Platform dashboard.

For direct access to the Admin Keys management page, Organization Owners can use the following link:

[https://platform.openai.com/settings/organization/admin-keys](https://platform.openai.com/settings/organization/admin-keys)

It's crucial to handle Admin API keys with care due to their elevated permissions. Adhering to best practices, such as regular key rotation and assigning appropriate permissions, enhances security and ensures proper governance within the organization.

List all organization and project API keys.


-----------------------------------------------

getÂ https://api.openai.com/v1/organization/admin\_api\_keys

List organization API keys

#### Query parameters

[](#admin-api-keys-list-after)

after

string or null

Optional

[](#admin-api-keys-list-limit)

limit

integer

Optional

Defaults to 20

[](#admin-api-keys-list-order)

order

string

Optional

Defaults to asc

#### Returns

A list of admin and project API key objects.

Example request

curl
    curl https://api.openai.com/v1/organization/admin_api_keys?after=key_abc&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "organization.admin_api_key",
          "id": "key_abc",
          "name": "Main Admin Key",
          "redacted_value": "sk-admin...def",
          "created_at": 1711471533,
          "last_used_at": 1711471534,
          "owner": {
            "type": "service_account",
            "object": "organization.service_account",
            "id": "sa_456",
            "name": "My Service Account",
            "created_at": 1711471533,
            "role": "member"
          }
        }
      ],
      "first_id": "key_abc",
      "last_id": "key_abc",
      "has_more": false
    }

Create admin API key


------------------------

postÂ https://api.openai.com/v1/organization/admin\_api\_keys

Create an organization admin API key

#### Request body

[](#admin-api-keys-create-name)

name

string

Required

#### Returns

The created [AdminApiKey](/docs/api-reference/admin-api-keys/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/admin_api_keys \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "name": "New Admin Key"
      }'

Response
    {
      "object": "organization.admin_api_key",
      "id": "key_xyz",
      "name": "New Admin Key",
      "redacted_value": "sk-admin...xyz",
      "created_at": 1711471533,
      "last_used_at": 1711471534,
      "owner": {
        "type": "user",
        "object": "organization.user",
        "id": "user_123",
        "name": "John Doe",
        "created_at": 1711471533,
        "role": "owner"
      },
      "value": "sk-admin-1234abcd"
    }

Retrieve admin API key


--------------------------

getÂ https://api.openai.com/v1/organization/admin\_api\_keys/{key\_id}

Retrieve a single organization API key

#### Path parameters

[](#admin-api-keys-listget-key_id)

key\_id

string

Required

#### Returns

The requested [AdminApiKey](/docs/api-reference/admin-api-keys/object) object.

Example request

curl
    curl https://api.openai.com/v1/organization/admin_api_keys/key_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "organization.admin_api_key",
      "id": "key_abc",
      "name": "Main Admin Key",
      "redacted_value": "sk-admin...xyz",
      "created_at": 1711471533,
      "last_used_at": 1711471534,
      "owner": {
        "type": "user",
        "object": "organization.user",
        "id": "user_123",
        "name": "John Doe",
        "created_at": 1711471533,
        "role": "owner"
      }
    }

Delete admin API key


------------------------

deleteÂ https://api.openai.com/v1/organization/admin\_api\_keys/{key\_id}

Delete an organization admin API key

#### Path parameters

[](#admin-api-keys-delete-key_id)

key\_id

string

Required

#### Returns

A confirmation object indicating the key was deleted.

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/admin_api_keys/key_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "id": "key_abc",
      "object": "organization.admin_api_key.deleted",
      "deleted": true
    }

The admin API key object


----------------------------

Represents an individual Admin API key in an org.

[](#admin-api-keys/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) of when the API key was created

[](#admin-api-keys/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#admin-api-keys/object-last_used_at)

last\_used\_at

integer or null

The Unix timestamp (in seconds) of when the API key was last used

[](#admin-api-keys/object-name)

name

string

The name of the API key

[](#admin-api-keys/object-object)

object

string

The object type, which is always `organization.admin_api_key`

[](#admin-api-keys/object-owner)

owner

object

Show properties

[](#admin-api-keys/object-redacted_value)

redacted\_value

string

The redacted value of the API key

[](#admin-api-keys/object-value)

value

string

The value of the API key. Only shown on create.

OBJECT The admin API key object
    {
      "object": "organization.admin_api_key",
      "id": "key_abc",
      "name": "Main Admin Key",
      "redacted_value": "sk-admin...xyz",
      "created_at": 1711471533,
      "last_used_at": 1711471534,
      "owner": {
        "type": "user",
        "object": "organization.user",
        "id": "user_123",
        "name": "John Doe",
        "created_at": 1711471533,
        "role": "owner"
      }
    }

Invites


-----------

Invite and manage invitations for an organization.

List invites


----------------

getÂ https://api.openai.com/v1/organization/invites

Returns a list of invites in the organization.

#### Query parameters

[](#invite-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#invite-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [Invite](/docs/api-reference/invite/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "organization.invite",
          "id": "invite-abc",
          "email": "user@example.com",
          "role": "owner",
          "status": "accepted",
          "invited_at": 1711471533,
          "expires_at": 1711471533,
          "accepted_at": 1711471533
        }
      ],
      "first_id": "invite-abc",
      "last_id": "invite-abc",
      "has_more": false
    }

Create invite


-----------------

postÂ https://api.openai.com/v1/organization/invites

Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.

#### Request body

[](#invite-create-email)

email

string

Required

Send an email to this address

[](#invite-create-role)

role

string

Required

`owner` or `reader`

[](#invite-create-projects)

projects

array

Optional

An array of projects to which membership is granted at the same time the org invite is accepted. If omitted, the user will be invited to the default project for compatibility with legacy behavior.

Show properties

#### Returns

The created [Invite](/docs/api-reference/invite/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/invites \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "email": "anotheruser@example.com",
          "role": "reader",
          "projects": [
            {
              "id": "project-xyz",
              "role": "member"
            },
            {
              "id": "project-abc",
              "role": "owner"
            }
          ]
      }'

Response
    {
      "object": "organization.invite",
      "id": "invite-def",
      "email": "anotheruser@example.com",
      "role": "reader",
      "status": "pending",
      "invited_at": 1711471533,
      "expires_at": 1711471533,
      "accepted_at": null,
      "projects": [
        {
          "id": "project-xyz",
          "role": "member"
        },
        {
          "id": "project-abc",
          "role": "owner"
        }
      ]
    }

Retrieve invite


-------------------

getÂ https://api.openai.com/v1/organization/invites/{invite\_id}

Retrieves an invite.

#### Path parameters

[](#invite-retrieve-invite_id)

invite\_id

string

Required

The ID of the invite to retrieve.

#### Returns

The [Invite](/docs/api-reference/invite/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/invites/invite-abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.invite",
        "id": "invite-abc",
        "email": "user@example.com",
        "role": "owner",
        "status": "accepted",
        "invited_at": 1711471533,
        "expires_at": 1711471533,
        "accepted_at": 1711471533
    }

Delete invite


-----------------

deleteÂ https://api.openai.com/v1/organization/invites/{invite\_id}

Delete an invite. If the invite has already been accepted, it cannot be deleted.

#### Path parameters

[](#invite-delete-invite_id)

invite\_id

string

Required

The ID of the invite to delete.

#### Returns

Confirmation that the invite has been deleted

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.invite.deleted",
        "id": "invite-abc",
        "deleted": true
    }

The invite object


---------------------

Represents an individual `invite` to the organization.

[](#invite/object-accepted_at)

accepted\_at

integer

The Unix timestamp (in seconds) of when the invite was accepted.

[](#invite/object-email)

email

string

The email address of the individual to whom the invite was sent

[](#invite/object-expires_at)

expires\_at

integer

The Unix timestamp (in seconds) of when the invite expires.

[](#invite/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#invite/object-invited_at)

invited\_at

integer

The Unix timestamp (in seconds) of when the invite was sent.

[](#invite/object-object)

object

string

The object type, which is always `organization.invite`

[](#invite/object-projects)

projects

array

The projects that were granted membership upon acceptance of the invite.

Show properties

[](#invite/object-role)

role

string

`owner` or `reader`

[](#invite/object-status)

status

string

`accepted`,`expired`, or `pending`

OBJECT The invite object
    {
      "object": "organization.invite",
      "id": "invite-abc",
      "email": "user@example.com",
      "role": "owner",
      "status": "accepted",
      "invited_at": 1711471533,
      "expires_at": 1711471533,
      "accepted_at": 1711471533,
      "projects": [
        {
          "id": "project-xyz",
          "role": "member"
        }
      ]
    }

Users


---------

Manage users and their role in an organization.

List users


--------------

getÂ https://api.openai.com/v1/organization/users

Lists all of the users in the organization.

#### Query parameters

[](#users-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#users-list-emails)

emails

array

Optional

Filter by the email address of users.

[](#users-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [User](/docs/api-reference/users/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "object": "organization.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
        ],
        "first_id": "user-abc",
        "last_id": "user-xyz",
        "has_more": false
    }

Modify user


---------------

postÂ https://api.openai.com/v1/organization/users/{user\_id}

Modifies a user's role in the organization.

#### Path parameters

[](#users-modify-user_id)

user\_id

string

Required

The ID of the user.

#### Request body

[](#users-modify-role)

role

string

Required

`owner` or `reader`

#### Returns

The updated [User](/docs/api-reference/users/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "role": "owner"
      }'

Response
    {
        "object": "organization.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Retrieve user


-----------------

getÂ https://api.openai.com/v1/organization/users/{user\_id}

Retrieves a user by their identifier.

#### Path parameters

[](#users-retrieve-user_id)

user\_id

string

Required

The ID of the user.

#### Returns

The [User](/docs/api-reference/users/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Delete user


---------------

deleteÂ https://api.openai.com/v1/organization/users/{user\_id}

Deletes a user from the organization.

#### Path parameters

[](#users-delete-user_id)

user\_id

string

Required

The ID of the user.

#### Returns

Confirmation of the deleted user

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.user.deleted",
        "id": "user_abc",
        "deleted": true
    }

The user object


-------------------

Represents an individual `user` within an organization.

[](#users/object-added_at)

added\_at

integer

The Unix timestamp (in seconds) of when the user was added.

[](#users/object-email)

email

string

The email address of the user

[](#users/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#users/object-name)

name

string

The name of the user

[](#users/object-object)

object

string

The object type, which is always `organization.user`

[](#users/object-role)

role

string

`owner` or `reader`

OBJECT The user object
    {
        "object": "organization.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Projects


------------

Manage the projects within an orgnanization includes creation, updating, and archiving or projects. The Default project cannot be archived.

List projects


-----------------

getÂ https://api.openai.com/v1/organization/projects

Returns a list of projects.

#### Query parameters

[](#projects-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#projects-list-include_archived)

include\_archived

boolean

Optional

Defaults to false

If `true` returns all projects including those that have been `archived`. Archived projects are not included by default.

[](#projects-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [Project](/docs/api-reference/projects/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "id": "proj_abc",
                "object": "organization.project",
                "name": "Project example",
                "created_at": 1711471533,
                "archived_at": null,
                "status": "active"
            }
        ],
        "first_id": "proj-abc",
        "last_id": "proj-xyz",
        "has_more": false
    }

Create project


------------------

postÂ https://api.openai.com/v1/organization/projects

Create a new project in the organization. Projects can be created and archived, but cannot be deleted.

#### Request body

[](#projects-create-name)

name

string

Required

The friendly name of the project, this name appears in reports.

#### Returns

The created [Project](/docs/api-reference/projects/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "name": "Project ABC"
      }'

Response
    {
        "id": "proj_abc",
        "object": "organization.project",
        "name": "Project ABC",
        "created_at": 1711471533,
        "archived_at": null,
        "status": "active"
    }

Retrieve project


--------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}

Retrieves a project.

#### Path parameters

[](#projects-retrieve-project_id)

project\_id

string

Required

The ID of the project.

#### Returns

The [Project](/docs/api-reference/projects/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "id": "proj_abc",
        "object": "organization.project",
        "name": "Project example",
        "created_at": 1711471533,
        "archived_at": null,
        "status": "active"
    }

Modify project


------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}

Modifies a project in the organization.

#### Path parameters

[](#projects-modify-project_id)

project\_id

string

Required

The ID of the project.

#### Request body

[](#projects-modify-name)

name

string

Required

The updated name of the project, this name appears in reports.

#### Returns

The updated [Project](/docs/api-reference/projects/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "name": "Project DEF"
      }'

Archive project


-------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/archive

Archives a project in the organization. Archived projects cannot be used or updated.

#### Path parameters

[](#projects-archive-project_id)

project\_id

string

Required

The ID of the project.

#### Returns

The archived [Project](/docs/api-reference/projects/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "id": "proj_abc",
        "object": "organization.project",
        "name": "Project DEF",
        "created_at": 1711471533,
        "archived_at": 1711471533,
        "status": "archived"
    }

The project object


----------------------

Represents an individual project.

[](#projects/object-archived_at)

archived\_at

integer or null

The Unix timestamp (in seconds) of when the project was archived or `null`.

[](#projects/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) of when the project was created.

[](#projects/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#projects/object-name)

name

string

The name of the project. This appears in reporting.

[](#projects/object-object)

object

string

The object type, which is always `organization.project`

[](#projects/object-status)

status

string

`active` or `archived`

OBJECT The project object
    {
        "id": "proj_abc",
        "object": "organization.project",
        "name": "Project example",
        "created_at": 1711471533,
        "archived_at": null,
        "status": "active"
    }

Project users


-----------------

Manage users within a project, including adding, updating roles, and removing users.

List project users


----------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/users

Returns a list of users in the project.

#### Path parameters

[](#project-users-list-project_id)

project\_id

string

Required

The ID of the project.

#### Query parameters

[](#project-users-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#project-users-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [ProjectUser](/docs/api-reference/project-users/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "object": "organization.project.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
        ],
        "first_id": "user-abc",
        "last_id": "user-xyz",
        "has_more": false
    }

Create project user


-----------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/users

Adds a user to the project. Users must already be members of the organization to be added to a project.

#### Path parameters

[](#project-users-creeate-project_id)

project\_id

string

Required

The ID of the project.

#### Request body

[](#project-users-creeate-role)

role

string

Required

`owner` or `member`

[](#project-users-creeate-user_id)

user\_id

string

Required

The ID of the user.

#### Returns

The created [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "user_id": "user_abc",
          "role": "member"
      }'

Response
    {
        "object": "organization.project.user",
        "id": "user_abc",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Retrieve project user


-------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Retrieves a user in the project.

#### Path parameters

[](#project-users-retrieve-project_id)

project\_id

string

Required

The ID of the project.

[](#project-users-retrieve-user_id)

user\_id

string

Required

The ID of the user.

#### Returns

The [ProjectUser](/docs/api-reference/project-users/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Modify project user


-----------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Modifies a user's role in the project.

#### Path parameters

[](#project-users-modify-project_id)

project\_id

string

Required

The ID of the project.

[](#project-users-modify-user_id)

user\_id

string

Required

The ID of the user.

#### Request body

[](#project-users-modify-role)

role

string

Required

`owner` or `member`

#### Returns

The updated [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "role": "owner"
      }'

Response
    {
        "object": "organization.project.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Delete project user


-----------------------

deleteÂ https://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Deletes a user from the project.

#### Path parameters

[](#project-users-delete-project_id)

project\_id

string

Required

The ID of the project.

[](#project-users-delete-user_id)

user\_id

string

Required

The ID of the user.

#### Returns

Confirmation that project has been deleted or an error in case of an archived project, which has no users

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.user.deleted",
        "id": "user_abc",
        "deleted": true
    }

The project user object


---------------------------

Represents an individual user in a project.

[](#project-users/object-added_at)

added\_at

integer

The Unix timestamp (in seconds) of when the project was added.

[](#project-users/object-email)

email

string

The email address of the user

[](#project-users/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#project-users/object-name)

name

string

The name of the user

[](#project-users/object-object)

object

string

The object type, which is always `organization.project.user`

[](#project-users/object-role)

role

string

`owner` or `member`

OBJECT The project user object
    {
        "object": "organization.project.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Project service accounts


----------------------------

Manage service accounts within a project. A service account is a bot user that is not associated with a user. If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts do not have this limitation. However, service accounts can also be deleted from a project.

List project service accounts


---------------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Returns a list of service accounts in the project.

#### Path parameters

[](#project-service-accounts-list-project_id)

project\_id

string

Required

The ID of the project.

#### Query parameters

[](#project-service-accounts-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#project-service-accounts-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "object": "organization.project.service_account",
                "id": "svc_acct_abc",
                "name": "Service Account",
                "role": "owner",
                "created_at": 1711471533
            }
        ],
        "first_id": "svc_acct_abc",
        "last_id": "svc_acct_xyz",
        "has_more": false
    }

Create project service account


----------------------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Creates a new service account in the project. This also returns an unredacted API key for the service account.

#### Path parameters

[](#project-service-accounts-create-project_id)

project\_id

string

Required

The ID of the project.

#### Request body

[](#project-service-accounts-create-name)

name

string

Required

The name of the service account being created.

#### Returns

The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "name": "Production App"
      }'

Response
    {
        "object": "organization.project.service_account",
        "id": "svc_acct_abc",
        "name": "Production App",
        "role": "member",
        "created_at": 1711471533,
        "api_key": {
            "object": "organization.project.service_account.api_key",
            "value": "sk-abcdefghijklmnop123",
            "name": "Secret Key",
            "created_at": 1711471533,
            "id": "key_abc"
        }
    }

Retrieve project service account


------------------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Retrieves a service account in the project.

#### Path parameters

[](#project-service-accounts-retrieve-project_id)

project\_id

string

Required

The ID of the project.

[](#project-service-accounts-retrieve-service_account_id)

service\_account\_id

string

Required

The ID of the service account.

#### Returns

The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.service_account",
        "id": "svc_acct_abc",
        "name": "Service Account",
        "role": "owner",
        "created_at": 1711471533
    }

Delete project service account


----------------------------------

deleteÂ https://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Deletes a service account from the project.

#### Path parameters

[](#project-service-accounts-delete-project_id)

project\_id

string

Required

The ID of the project.

[](#project-service-accounts-delete-service_account_id)

service\_account\_id

string

Required

The ID of the service account.

#### Returns

Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.service_account.deleted",
        "id": "svc_acct_abc",
        "deleted": true
    }

The project service account object


--------------------------------------

Represents an individual service account in a project.

[](#project-service-accounts/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) of when the service account was created

[](#project-service-accounts/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#project-service-accounts/object-name)

name

string

The name of the service account

[](#project-service-accounts/object-object)

object

string

The object type, which is always `organization.project.service_account`

[](#project-service-accounts/object-role)

role

string

`owner` or `member`

OBJECT The project service account object
    {
        "object": "organization.project.service_account",
        "id": "svc_acct_abc",
        "name": "Service Account",
        "role": "owner",
        "created_at": 1711471533
    }

Project API keys


--------------------

Manage API keys for a given project. Supports listing and deleting keys for users. This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.

List project API keys


-------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/api\_keys

Returns a list of API keys in the project.

#### Path parameters

[](#project-api-keys-list-project_id)

project\_id

string

Required

The ID of the project.

#### Query parameters

[](#project-api-keys-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#project-api-keys-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "object": "organization.project.api_key",
                "redacted_value": "sk-abc...def",
                "name": "My API Key",
                "created_at": 1711471533,
                "last_used_at": 1711471534,
                "id": "key_abc",
                "owner": {
                    "type": "user",
                    "user": {
                        "object": "organization.project.user",
                        "id": "user_abc",
                        "name": "First Last",
                        "email": "user@example.com",
                        "role": "owner",
                        "added_at": 1711471533
                    }
                }
            }
        ],
        "first_id": "key_abc",
        "last_id": "key_xyz",
        "has_more": false
    }

Retrieve project API key


----------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Retrieves an API key in the project.

#### Path parameters

[](#project-api-keys-retrieve-key_id)

key\_id

string

Required

The ID of the API key.

[](#project-api-keys-retrieve-project_id)

project\_id

string

Required

The ID of the project.

#### Returns

The [ProjectApiKey](/docs/api-reference/project-api-keys/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.api_key",
        "redacted_value": "sk-abc...def",
        "name": "My API Key",
        "created_at": 1711471533,
        "last_used_at": 1711471534,
        "id": "key_abc",
        "owner": {
            "type": "user",
            "user": {
                "object": "organization.project.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
        }
    }

Delete project API key


--------------------------

deleteÂ https://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Deletes an API key from the project.

#### Path parameters

[](#project-api-keys-delete-key_id)

key\_id

string

Required

The ID of the API key.

[](#project-api-keys-delete-project_id)

project\_id

string

Required

The ID of the project.

#### Returns

Confirmation of the key's deletion or an error if the key belonged to a service account

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.api_key.deleted",
        "id": "key_abc",
        "deleted": true
    }

The project API key object


------------------------------

Represents an individual API key in a project.

[](#project-api-keys/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) of when the API key was created

[](#project-api-keys/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#project-api-keys/object-last_used_at)

last\_used\_at

integer

The Unix timestamp (in seconds) of when the API key was last used.

[](#project-api-keys/object-name)

name

string

The name of the API key

[](#project-api-keys/object-object)

object

string

The object type, which is always `organization.project.api_key`

[](#project-api-keys/object-owner)

owner

object

Show properties

[](#project-api-keys/object-redacted_value)

redacted\_value

string

The redacted value of the API key

OBJECT The project API key object
    {
        "object": "organization.project.api_key",
        "redacted_value": "sk-abc...def",
        "name": "My API Key",
        "created_at": 1711471533,
        "last_used_at": 1711471534,
        "id": "key_abc",
        "owner": {
            "type": "user",
            "user": {
                "object": "organization.project.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "created_at": 1711471533
            }
        }
    }

Project rate limits


-----------------------

Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.

List project rate limits


----------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits

Returns the rate limits per model for a project.

#### Path parameters

[](#project-rate-limits-list-project_id)

project\_id

string

Required

The ID of the project.

#### Query parameters

[](#project-rate-limits-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#project-rate-limits-list-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#project-rate-limits-list-limit)

limit

integer

Optional

Defaults to 100

A limit on the number of objects to be returned. The default is 100.

#### Returns

A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
              "object": "project.rate_limit",
              "id": "rl-ada",
              "model": "ada",
              "max_requests_per_1_minute": 600,
              "max_tokens_per_1_minute": 150000,
              "max_images_per_1_minute": 10
            }
        ],
        "first_id": "rl-ada",
        "last_id": "rl-ada",
        "has_more": false
    }

Modify project rate limit


-----------------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits/{rate\_limit\_id}

Updates a project rate limit.

#### Path parameters

[](#project-rate-limits-update-project_id)

project\_id

string

Required

The ID of the project.

[](#project-rate-limits-update-rate_limit_id)

rate\_limit\_id

string

Required

The ID of the rate limit.

#### Request body

[](#project-rate-limits-update-batch_1_day_max_input_tokens)

batch\_1\_day\_max\_input\_tokens

integer

Optional

The maximum batch input tokens per day. Only relevant for certain models.

[](#project-rate-limits-update-max_audio_megabytes_per_1_minute)

max\_audio\_megabytes\_per\_1\_minute

integer

Optional

The maximum audio megabytes per minute. Only relevant for certain models.

[](#project-rate-limits-update-max_images_per_1_minute)

max\_images\_per\_1\_minute

integer

Optional

The maximum images per minute. Only relevant for certain models.

[](#project-rate-limits-update-max_requests_per_1_day)

max\_requests\_per\_1\_day

integer

Optional

The maximum requests per day. Only relevant for certain models.

[](#project-rate-limits-update-max_requests_per_1_minute)

max\_requests\_per\_1\_minute

integer

Optional

The maximum requests per minute.

[](#project-rate-limits-update-max_tokens_per_1_minute)

max\_tokens\_per\_1\_minute

integer

Optional

The maximum tokens per minute.

#### Returns

The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "max_requests_per_1_minute": 500
      }'

Response
    {
        "object": "project.rate_limit",
        "id": "rl-ada",
        "model": "ada",
        "max_requests_per_1_minute": 600,
        "max_tokens_per_1_minute": 150000,
        "max_images_per_1_minute": 10
      }

The project rate limit object


---------------------------------

Represents a project rate limit config.

[](#project-rate-limits/object-batch_1_day_max_input_tokens)

batch\_1\_day\_max\_input\_tokens

integer

The maximum batch input tokens per day. Only present for relevant models.

[](#project-rate-limits/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#project-rate-limits/object-max_audio_megabytes_per_1_minute)

max\_audio\_megabytes\_per\_1\_minute

integer

The maximum audio megabytes per minute. Only present for relevant models.

[](#project-rate-limits/object-max_images_per_1_minute)

max\_images\_per\_1\_minute

integer

The maximum images per minute. Only present for relevant models.

[](#project-rate-limits/object-max_requests_per_1_day)

max\_requests\_per\_1\_day

integer

The maximum requests per day. Only present for relevant models.

[](#project-rate-limits/object-max_requests_per_1_minute)

max\_requests\_per\_1\_minute

integer

The maximum requests per minute.

[](#project-rate-limits/object-max_tokens_per_1_minute)

max\_tokens\_per\_1\_minute

integer

The maximum tokens per minute.

[](#project-rate-limits/object-model)

model

string

The model this rate limit applies to.

[](#project-rate-limits/object-object)

object

string

The object type, which is always `project.rate_limit`

OBJECT The project rate limit object
    {
        "object": "project.rate_limit",
        "id": "rl_ada",
        "model": "ada",
        "max_requests_per_1_minute": 600,
        "max_tokens_per_1_minute": 150000,
        "max_images_per_1_minute": 10
    }

Audit logs


--------------

Logs of user actions and configuration changes within this organization. To log events, you must activate logging in the [Organization Settings](/settings/organization/general). Once activated, for security reasons, logging cannot be deactivated.

List audit logs


-------------------

getÂ https://api.openai.com/v1/organization/audit\_logs

List user actions and configuration changes within this organization.

#### Query parameters

[](#audit-logs-list-actor_emails)

actor\_emails\[\]

array

Optional

Return only events performed by users with these emails.

[](#audit-logs-list-actor_ids)

actor\_ids\[\]

array

Optional

Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.

[](#audit-logs-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#audit-logs-list-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#audit-logs-list-effective_at)

effective\_at

object

Optional

Return only events whose `effective_at` (Unix seconds) is in this range.

Show properties

[](#audit-logs-list-event_types)

event\_types\[\]

array

Optional

Return only events with a `type` in one of these values. For example, `project.created`. For all options, see the documentation for the [audit log object](/docs/api-reference/audit-logs/object).

[](#audit-logs-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#audit-logs-list-project_ids)

project\_ids\[\]

array

Optional

Return only events for these projects.

[](#audit-logs-list-resource_ids)

resource\_ids\[\]

array

Optional

Return only events performed on these targets. For example, a project ID updated.

#### Returns

A list of paginated [Audit Log](/docs/api-reference/audit-logs/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/audit_logs \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "id": "audit_log-xxx_yyyymmdd",
                "type": "project.archived",
                "effective_at": 1722461446,
                "actor": {
                    "type": "api_key",
                    "api_key": {
                        "type": "user",
                        "user": {
                            "id": "user-xxx",
                            "email": "user@example.com"
                        }
                    }
                },
                "project.archived": {
                    "id": "proj_abc"
                },
            },
            {
                "id": "audit_log-yyy__20240101",
                "type": "api_key.updated",
                "effective_at": 1720804190,
                "actor": {
                    "type": "session",
                    "session": {
                        "user": {
                            "id": "user-xxx",
                            "email": "user@example.com"
                        },
                        "ip_address": "127.0.0.1",
                        "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                        "ja3": "a497151ce4338a12c4418c44d375173e",
                        "ja4": "q13d0313h3_55b375c5d22e_c7319ce65786",
                        "ip_address_details": {
                          "country": "US",
                          "city": "San Francisco",
                          "region": "California",
                          "region_code": "CA",
                          "asn": "1234",
                          "latitude": "37.77490",
                          "longitude": "-122.41940"
                        }
                    }
                },
                "api_key.updated": {
                    "id": "key_xxxx",
                    "data": {
                        "scopes": ["resource_2.operation_2"]
                    }
                },
            }
        ],
        "first_id": "audit_log-xxx__20240101",
        "last_id": "audit_log_yyy__20240101",
        "has_more": true
    }

The audit log object


------------------------

A log of a user action or configuration change within this organization.

[](#audit-logs/object-actor)

actor

object

The actor who performed the audit logged action.

Show properties

[](#audit-logs/object-api_key-created)

api\_key.created

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-api_key-deleted)

api\_key.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-api_key-updated)

api\_key.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-certificate-created)

certificate.created

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-certificate-deleted)

certificate.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-certificate-updated)

certificate.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-certificates-activated)

certificates.activated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-certificates-deactivated)

certificates.deactivated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-checkpoint_permission-created)

checkpoint\_permission.created

object

The project and fine-tuned model checkpoint that the checkpoint permission was created for.

Show properties

[](#audit-logs/object-checkpoint_permission-deleted)

checkpoint\_permission.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-effective_at)

effective\_at

integer

The Unix timestamp (in seconds) of the event.

[](#audit-logs/object-id)

id

string

The ID of this log.

[](#audit-logs/object-invite-accepted)

invite.accepted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-invite-deleted)

invite.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-invite-sent)

invite.sent

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-login-failed)

login.failed

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-logout-failed)

logout.failed

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-organization-updated)

organization.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-project)

project

object

The project that the action was scoped to. Absent for actions not scoped to projects.

Show properties

[](#audit-logs/object-project-archived)

project.archived

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-project-created)

project.created

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-project-updated)

project.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-rate_limit-deleted)

rate\_limit.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-rate_limit-updated)

rate\_limit.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-service_account-created)

service\_account.created

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-service_account-deleted)

service\_account.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-service_account-updated)

service\_account.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-type)

type

string

The event type.

[](#audit-logs/object-user-added)

user.added

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-user-deleted)

user.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-user-updated)

user.updated

object

The details for events with this `type`.

Show properties

OBJECT The audit log object
    {
        "id": "req_xxx_20240101",
        "type": "api_key.created",
        "effective_at": 1720804090,
        "actor": {
            "type": "session",
            "session": {
                "user": {
                    "id": "user-xxx",
                    "email": "user@example.com"
                },
                "ip_address": "127.0.0.1",
                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
        },
        "api_key.created": {
            "id": "key_xxxx",
            "data": {
                "scopes": ["resource.operation"]
            }
        }
    }

Usage


---------

The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.

Completions


---------------

getÂ https://api.openai.com/v1/organization/usage/completions

Get completions usage details for the organization.

#### Query parameters

[](#usage-completions-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-completions-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-completions-batch)

batch

boolean

Optional

If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.

[](#usage-completions-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-completions-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-completions-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any combination of them.

[](#usage-completions-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-completions-models)

models

array

Optional

Return only usage for these models.

[](#usage-completions-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-completions-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-completions-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.completions.result",
                        "input_tokens": 1000,
                        "output_tokens": 500,
                        "input_cached_tokens": 800,
                        "input_audio_tokens": 0,
                        "output_audio_tokens": 0,
                        "num_model_requests": 5,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null,
                        "batch": null
                    }
                ]
            }
        ],
        "has_more": true,
        "next_page": "page_AAAAAGdGxdEiJdKOAAAAAGcqsYA="
    }

Completions usage object


----------------------------

The aggregated completions usage details of the specific time bucket.

[](#usage/completions_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/completions_object-batch)

batch

boolean or null

When `group_by=batch`, this field tells whether the grouped usage result is batch or not.

[](#usage/completions_object-input_audio_tokens)

input\_audio\_tokens

integer

The aggregated number of audio input tokens used, including cached tokens.

[](#usage/completions_object-input_cached_tokens)

input\_cached\_tokens

integer

The aggregated number of text input tokens that has been cached from previous requests. For customers subscribe to scale tier, this includes scale tier tokens.

[](#usage/completions_object-input_tokens)

input\_tokens

integer

The aggregated number of text input tokens used, including cached tokens. For customers subscribe to scale tier, this includes scale tier tokens.

[](#usage/completions_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/completions_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/completions_object-object)

object

string

[](#usage/completions_object-output_audio_tokens)

output\_audio\_tokens

integer

The aggregated number of audio output tokens used.

[](#usage/completions_object-output_tokens)

output\_tokens

integer

The aggregated number of text output tokens used. For customers subscribe to scale tier, this includes scale tier tokens.

[](#usage/completions_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/completions_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Completions usage object
    {
        "object": "organization.usage.completions.result",
        "input_tokens": 5000,
        "output_tokens": 1000,
        "input_cached_tokens": 4000,
        "input_audio_tokens": 300,
        "output_audio_tokens": 200,
        "num_model_requests": 5,
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "gpt-4o-mini-2024-07-18",
        "batch": false
    }

Embeddings


--------------

getÂ https://api.openai.com/v1/organization/usage/embeddings

Get embeddings usage details for the organization.

#### Query parameters

[](#usage-embeddings-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-embeddings-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-embeddings-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-embeddings-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-embeddings-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

[](#usage-embeddings-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-embeddings-models)

models

array

Optional

Return only usage for these models.

[](#usage-embeddings-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-embeddings-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-embeddings-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.embeddings.result",
                        "input_tokens": 16,
                        "num_model_requests": 2,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Embeddings usage object


---------------------------

The aggregated embeddings usage details of the specific time bucket.

[](#usage/embeddings_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/embeddings_object-input_tokens)

input\_tokens

integer

The aggregated number of input tokens used.

[](#usage/embeddings_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/embeddings_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/embeddings_object-object)

object

string

[](#usage/embeddings_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/embeddings_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Embeddings usage object
    {
        "object": "organization.usage.embeddings.result",
        "input_tokens": 20,
        "num_model_requests": 2,
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "text-embedding-ada-002-v2"
    }

Moderations


---------------

getÂ https://api.openai.com/v1/organization/usage/moderations

Get moderations usage details for the organization.

#### Query parameters

[](#usage-moderations-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-moderations-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-moderations-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-moderations-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-moderations-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

[](#usage-moderations-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-moderations-models)

models

array

Optional

Return only usage for these models.

[](#usage-moderations-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-moderations-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-moderations-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.moderations.result",
                        "input_tokens": 16,
                        "num_model_requests": 2,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Moderations usage object


----------------------------

The aggregated moderations usage details of the specific time bucket.

[](#usage/moderations_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/moderations_object-input_tokens)

input\_tokens

integer

The aggregated number of input tokens used.

[](#usage/moderations_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/moderations_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/moderations_object-object)

object

string

[](#usage/moderations_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/moderations_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Moderations usage object
    {
        "object": "organization.usage.moderations.result",
        "input_tokens": 20,
        "num_model_requests": 2,
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "text-moderation"
    }

Images


----------

getÂ https://api.openai.com/v1/organization/usage/images

Get images usage details for the organization.

#### Query parameters

[](#usage-images-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-images-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-images-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-images-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-images-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source` or any combination of them.

[](#usage-images-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-images-models)

models

array

Optional

Return only usage for these models.

[](#usage-images-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-images-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-images-sizes)

sizes

array

Optional

Return only usages for these image sizes. Possible values are `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination of them.

[](#usage-images-sources)

sources

array

Optional

Return only usages for these sources. Possible values are `image.generation`, `image.edit`, `image.variation` or any combination of them.

[](#usage-images-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.images.result",
                        "images": 2,
                        "num_model_requests": 2,
                        "size": null,
                        "source": null,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Images usage object


-----------------------

The aggregated images usage details of the specific time bucket.

[](#usage/images_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/images_object-images)

images

integer

The number of images processed.

[](#usage/images_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/images_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/images_object-object)

object

string

[](#usage/images_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/images_object-size)

size

string or null

When `group_by=size`, this field provides the image size of the grouped usage result.

[](#usage/images_object-source)

source

string or null

When `group_by=source`, this field provides the source of the grouped usage result, possible values are `image.generation`, `image.edit`, `image.variation`.

[](#usage/images_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Images usage object
    {
        "object": "organization.usage.images.result",
        "images": 2,
        "num_model_requests": 2,
        "size": "1024x1024",
        "source": "image.generation",
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "dall-e-3"
    }

Audio speeches


------------------

getÂ https://api.openai.com/v1/organization/usage/audio\_speeches

Get audio speeches usage details for the organization.

#### Query parameters

[](#usage-audio_speeches-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-audio_speeches-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-audio_speeches-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-audio_speeches-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-audio_speeches-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

[](#usage-audio_speeches-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-audio_speeches-models)

models

array

Optional

Return only usage for these models.

[](#usage-audio_speeches-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-audio_speeches-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-audio_speeches-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.audio_speeches.result",
                        "characters": 45,
                        "num_model_requests": 1,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Audio speeches usage object


-------------------------------

The aggregated audio speeches usage details of the specific time bucket.

[](#usage/audio_speeches_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/audio_speeches_object-characters)

characters

integer

The number of characters processed.

[](#usage/audio_speeches_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/audio_speeches_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/audio_speeches_object-object)

object

string

[](#usage/audio_speeches_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/audio_speeches_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Audio speeches usage object
    {
        "object": "organization.usage.audio_speeches.result",
        "characters": 45,
        "num_model_requests": 1,
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "tts-1"
    }

Audio transcriptions


------------------------

getÂ https://api.openai.com/v1/organization/usage/audio\_transcriptions

Get audio transcriptions usage details for the organization.

#### Query parameters

[](#usage-audio_transcriptions-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-audio_transcriptions-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-audio_transcriptions-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-audio_transcriptions-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-audio_transcriptions-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

[](#usage-audio_transcriptions-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-audio_transcriptions-models)

models

array

Optional

Return only usage for these models.

[](#usage-audio_transcriptions-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-audio_transcriptions-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-audio_transcriptions-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.audio_transcriptions.result",
                        "seconds": 20,
                        "num_model_requests": 1,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Audio transcriptions usage object


-------------------------------------

The aggregated audio transcriptions usage details of the specific time bucket.

[](#usage/audio_transcriptions_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/audio_transcriptions_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/audio_transcriptions_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/audio_transcriptions_object-object)

object

string

[](#usage/audio_transcriptions_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/audio_transcriptions_object-seconds)

seconds

integer

The number of seconds processed.

[](#usage/audio_transcriptions_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Audio transcriptions usage object
    {
        "object": "organization.usage.audio_transcriptions.result",
        "seconds": 10,
        "num_model_requests": 1,
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "tts-1"
    }

Vector stores


-----------------

getÂ https://api.openai.com/v1/organization/usage/vector\_stores

Get vector stores usage details for the organization.

#### Query parameters

[](#usage-vector_stores-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-vector_stores-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-vector_stores-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-vector_stores-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

[](#usage-vector_stores-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-vector_stores-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-vector_stores-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

#### Returns

A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.vector_stores.result",
                        "usage_bytes": 1024,
                        "project_id": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Vector stores usage object


------------------------------

The aggregated vector stores usage details of the specific time bucket.

[](#usage/vector_stores_object-object)

object

string

[](#usage/vector_stores_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/vector_stores_object-usage_bytes)

usage\_bytes

integer

The vector stores usage in bytes.

OBJECT Vector stores usage object
    {
        "object": "organization.usage.vector_stores.result",
        "usage_bytes": 1024,
        "project_id": "proj_abc"
    }

Code interpreter sessions


-----------------------------

getÂ https://api.openai.com/v1/organization/usage/code\_interpreter\_sessions

Get code interpreter sessions usage details for the organization.

#### Query parameters

[](#usage-code_interpreter_sessions-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-code_interpreter_sessions-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-code_interpreter_sessions-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-code_interpreter_sessions-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

[](#usage-code_interpreter_sessions-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-code_interpreter_sessions-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-code_interpreter_sessions-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

#### Returns

A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.code_interpreter_sessions.result",
                        "num_sessions": 1,
                        "project_id": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Code interpreter sessions usage object


------------------------------------------

The aggregated code interpreter sessions usage details of the specific time bucket.

[](#usage/code_interpreter_sessions_object-num_sessions)

num\_sessions

integer

The number of code interpreter sessions.

[](#usage/code_interpreter_sessions_object-object)

object

string

[](#usage/code_interpreter_sessions_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Code interpreter sessions usage object
    {
        "object": "organization.usage.code_interpreter_sessions.result",
        "num_sessions": 1,
        "project_id": "proj_abc"
    }

Costs


---------

getÂ https://api.openai.com/v1/organization/costs

Get costs details for the organization.

#### Query parameters

[](#usage-costs-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-costs-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently only `1d` is supported, default to `1d`.

[](#usage-costs-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-costs-group_by)

group\_by

array

Optional

Group the costs by the specified fields. Support fields include `project_id`, `line_item` and any combination of them.

[](#usage-costs-limit)

limit

integer

Optional

Defaults to 7

A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.

[](#usage-costs-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-costs-project_ids)

project\_ids

array

Optional

Return only costs for these projects.

#### Returns

A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.costs.result",
                        "amount": {
                            "value": 0.06,
                            "currency": "usd"
                        },
                        "line_item": null,
                        "project_id": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Costs object


----------------

The aggregated costs details of the specific time bucket.

[](#usage/costs_object-amount)

amount

object

The monetary value in its associated currency.

Show properties

[](#usage/costs_object-line_item)

line\_item

string or null

When `group_by=line_item`, this field provides the line item of the grouped costs result.

[](#usage/costs_object-object)

object

string

[](#usage/costs_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped costs result.

OBJECT Costs object
    {
        "object": "organization.costs.result",
        "amount": {
          "value": 0.06,
          "currency": "usd"
        },
        "line_item": "Image models",
        "project_id": "proj_abc"
    }

Certificates

Beta


----------------------

Manage Mutual TLS certificates across your organization and projects.

[Learn more about Mutual TLS.](https://help.openai.com/en/articles/10876024-openai-mutual-tls-beta-program)

Upload certificate


----------------------

postÂ https://api.openai.com/v1/organization/certificates

Upload a certificate to the organization. This does **not** automatically activate the certificate.

Organizations can upload up to 50 certificates.

#### Request body

[](#certificates-uploadcertificate-content)

content

string

Required

The certificate content in PEM format

[](#certificates-uploadcertificate-name)

name

string

Optional

An optional name for the certificate

#### Returns

A single [Certificate](/docs/api-reference/certificates/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/certificates \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "name": "My Example Certificate",
      "certificate": "-----BEGIN CERTIFICATE-----\\nMIIDeT...\\n-----END CERTIFICATE-----"
    }'

Response
    {
      "object": "certificate",
      "id": "cert_abc",
      "name": "My Example Certificate",
      "created_at": 1234567,
      "certificate_details": {
        "valid_at": 12345667,
        "expires_at": 12345678
      }
    }

Get certificate


-------------------

getÂ https://api.openai.com/v1/organization/certificates/{certificate\_id}

Get a certificate that has been uploaded to the organization.

You can get a certificate regardless of whether it is active or not.

#### Path parameters

[](#certificates-getcertificate-cert_id)

cert\_id

string

Required

Unique ID of the certificate to retrieve.

#### Query parameters

[](#certificates-getcertificate-include)

include

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `content` to fetch the PEM content of the certificate.

#### Returns

A single [Certificate](/docs/api-reference/certificates/object) object.

Example request

curl
    curl "https://api.openai.com/v1/organization/certificates/cert_abc?include[]=content" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY"

Response
    {
      "object": "certificate",
      "id": "cert_abc",
      "name": "My Example Certificate",
      "created_at": 1234567,
      "certificate_details": {
        "valid_at": 1234567,
        "expires_at": 12345678,
        "content": "-----BEGIN CERTIFICATE-----MIIDeT...-----END CERTIFICATE-----"
      }
    }

Modify certificate


----------------------

postÂ https://api.openai.com/v1/organization/certificates/{certificate\_id}

Modify a certificate. Note that only the name can be modified.

#### Request body

[](#certificates-modifycertificate-name)

name

string

Required

The updated name for the certificate

#### Returns

The updated [Certificate](/docs/api-reference/certificates/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/certificates/cert_abc \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "name": "Renamed Certificate"
    }'

Response
    {
      "object": "certificate",
      "id": "cert_abc",
      "name": "Renamed Certificate",
      "created_at": 1234567,
      "certificate_details": {
        "valid_at": 12345667,
        "expires_at": 12345678
      }
    }

Delete certificate


----------------------

deleteÂ https://api.openai.com/v1/organization/certificates/{certificate\_id}

Delete a certificate from the organization.

The certificate must be inactive for the organization and all projects.

#### Returns

A confirmation object indicating the certificate was deleted.

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/certificates/cert_abc \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY"

Response
    {
      "object": "certificate.deleted",
      "id": "cert_abc"
    }

List organization certificates


----------------------------------

getÂ https://api.openai.com/v1/organization/certificates

List uploaded certificates for this organization.

#### Query parameters

[](#certificates-listorganizationcertificates-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#certificates-listorganizationcertificates-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#certificates-listorganizationcertificates-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/certificates \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "organization.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
      "first_id": "cert_abc",
      "last_id": "cert_abc",
      "has_more": false
    }

List project certificates


-----------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/certificates

List certificates for this project.

#### Query parameters

[](#certificates-listprojectcertificates-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#certificates-listprojectcertificates-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#certificates-listprojectcertificates-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/certificates \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "organization.project.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
      "first_id": "cert_abc",
      "last_id": "cert_abc",
      "has_more": false
    }

Activate certificates for organization


------------------------------------------

postÂ https://api.openai.com/v1/organization/certificates/activate

Activate certificates at the organization level.

You can atomically and idempotently activate up to 10 certificates at a time.

#### Request body

[](#certificates-activateorganizationcertificates-certificate_ids)

certificate\_ids

array

Required

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects that were activated.

Example request

curl
    curl https://api.openai.com/v1/organization/certificates/activate \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "data": ["cert_abc", "cert_def"]
    }'

Response
    {
      "object": "organization.certificate.activation",
      "data": [
        {
          "object": "organization.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
        {
          "object": "organization.certificate",
          "id": "cert_def",
          "name": "My Example Certificate 2",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
    }

Deactivate certificates for organization


--------------------------------------------

postÂ https://api.openai.com/v1/organization/certificates/deactivate

Deactivate certificates at the organization level.

You can atomically and idempotently deactivate up to 10 certificates at a time.

#### Request body

[](#certificates-deactivateorganizationcertificates-certificate_ids)

certificate\_ids

array

Required

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects that were deactivated.

Example request

curl
    curl https://api.openai.com/v1/organization/certificates/deactivate \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "data": ["cert_abc", "cert_def"]
    }'

Response
    {
      "object": "organization.certificate.deactivation",
      "data": [
        {
          "object": "organization.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": false,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
        {
          "object": "organization.certificate",
          "id": "cert_def",
          "name": "My Example Certificate 2",
          "active": false,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
    }

Activate certificates for project


-------------------------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/certificates/activate

Activate certificates at the project level.

You can atomically and idempotently activate up to 10 certificates at a time.

#### Request body

[](#certificates-activateprojectcertificates-certificate_ids)

certificate\_ids

array

Required

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects that were activated.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/certificates/activate \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "data": ["cert_abc", "cert_def"]
    }'

Response
    {
      "object": "organization.project.certificate.activation",
      "data": [
        {
          "object": "organization.project.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
        {
          "object": "organization.project.certificate",
          "id": "cert_def",
          "name": "My Example Certificate 2",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
    }

Deactivate certificates for project


---------------------------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/certificates/deactivate

Deactivate certificates at the project level.

You can atomically and idempotently deactivate up to 10 certificates at a time.

#### Request body

[](#certificates-deactivateprojectcertificates-certificate_ids)

certificate\_ids

array

Required

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects that were deactivated.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/certificates/deactivate \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "data": ["cert_abc", "cert_def"]
    }'

Response
    {
      "object": "organization.project.certificate.deactivation",
      "data": [
        {
          "object": "organization.project.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": false,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
        {
          "object": "organization.project.certificate",
          "id": "cert_def",
          "name": "My Example Certificate 2",
          "active": false,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
    }

The certificate object


--------------------------

Represents an individual `certificate` uploaded to the organization.

[](#certificates/object-active)

active

boolean

Whether the certificate is currently active at the specified scope. Not returned when getting details for a specific certificate.

[](#certificates/object-certificate_details)

certificate\_details

object

Show properties

[](#certificates/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) of when the certificate was uploaded.

[](#certificates/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#certificates/object-name)

name

string

The name of the certificate.

[](#certificates/object-object)

object

string

The object type.

*   If creating, updating, or getting a specific certificate, the object type is `certificate`.
*   If listing, activating, or deactivating certificates for the organization, the object type is `organization.certificate`.
*   If listing, activating, or deactivating certificates for a project, the object type is `organization.project.certificate`.

OBJECT The certificate object
    {
      "object": "certificate",
      "id": "cert_abc",
      "name": "My Certificate",
      "created_at": 1234567,
      "certificate_details": {
        "valid_at": 1234567,
        "expires_at": 12345678,
        "content": "-----BEGIN CERTIFICATE----- MIIGAjCCA...6znFlOW+ -----END CERTIFICATE-----"
      }
    }

Completions

Legacy


-----------------------

Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.

Create completion

Legacy


-----------------------------

postÂ https://api.openai.com/v1/completions

Creates a completion for the provided prompt and parameters.

#### Request body

[](#completions-create-model)

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

[](#completions-create-prompt)

prompt

string or array

Required

The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.

[](#completions-create-best_of)

best\_of

integer or null

Optional

Defaults to 1

Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return â `best_of` must be greater than `n`.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

[](#completions-create-echo)

echo

boolean or null

Optional

Defaults to false

Echo back the prompt in addition to the completion

[](#completions-create-frequency_penalty)

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

[](#completions-create-logit_bias)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.

[](#completions-create-logprobs)

logprobs

integer or null

Optional

Defaults to null

Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

The maximum value for `logprobs` is 5.

[](#completions-create-max_tokens)

max\_tokens

integer or null

Optional

Defaults to 16

The maximum number of [tokens](/tokenizer) that can be generated in the completion.

The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

[](#completions-create-n)

n

integer or null

Optional

Defaults to 1

How many completions to generate for each prompt.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

[](#completions-create-presence_penalty)

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

[](#completions-create-seed)

seed

integer or null

Optional

If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

[](#completions-create-stop)

stop

string / array / null

Optional

Defaults to null

Not supported with latest reasoning models `o3` and `o4-mini`.

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

[](#completions-create-stream)

stream

boolean or null

Optional

Defaults to false

Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

[](#completions-create-stream_options)

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

[](#completions-create-suffix)

suffix

string or null

Optional

Defaults to null

The suffix that comes after a completion of inserted text.

This parameter is only supported for `gpt-3.5-turbo-instruct`.

[](#completions-create-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

[](#completions-create-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

[](#completions-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.

No streamingNo streamingStreamingStreaming

Example request

gpt-3.5-turbo-instruct

node.js
    curl https://api.openai.com/v1/completions \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "model": "gpt-3.5-turbo-instruct",
        "prompt": "Say this is a test",
        "max_tokens": 7,
        "temperature": 0
      }'
    from openai import OpenAI
    client = OpenAI()
    
    client.completions.create(
      model="gpt-3.5-turbo-instruct",
      prompt="Say this is a test",
      max_tokens=7,
      temperature=0
    )
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const completion = await openai.completions.create({
        model: "gpt-3.5-turbo-instruct",
        prompt: "Say this is a test.",
        max_tokens: 7,
        temperature: 0,
      });
    
      console.log(completion);
    }
    main();

Response
    {
      "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
      "object": "text_completion",
      "created": 1589478378,
      "model": "gpt-3.5-turbo-instruct",
      "system_fingerprint": "fp_44709d6fcb",
      "choices": [
        {
          "text": "\n\nThis is indeed a test",
          "index": 0,
          "logprobs": null,
          "finish_reason": "length"
        }
      ],
      "usage": {
        "prompt_tokens": 5,
        "completion_tokens": 7,
        "total_tokens": 12
      }
    }

The completion object

Legacy


---------------------------------

Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).

[](#completions/object-choices)

choices

array

The list of completion choices the model generated for the input prompt.

Show properties

[](#completions/object-created)

created

integer

The Unix timestamp (in seconds) of when the completion was created.

[](#completions/object-id)

id

string

A unique identifier for the completion.

[](#completions/object-model)

model

string

The model used for completion.

[](#completions/object-object)

object

string

The object type, which is always "text\_completion"

[](#completions/object-system_fingerprint)

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

[](#completions/object-usage)

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The completion object
    {
      "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
      "object": "text_completion",
      "created": 1589478378,
      "model": "gpt-4-turbo",
      "choices": [
        {
          "text": "\n\nThis is indeed a test",
          "index": 0,
          "logprobs": null,
          "finish_reason": "length"
        }
      ],
      "usage": {
        "prompt_tokens": 5,
        "completion_tokens": 7,
        "total_tokens": 12
      }
    }

Introduction
------------

This API reference describes the RESTful, streaming, and realtime APIs you can use to interact with the OpenAI platform. REST APIs are usable via HTTP in any environment that supports HTTP requests. Language-specific SDKs are listed [on the libraries page](/docs/libraries).

Authentication
--------------

The OpenAI API uses API keys for authentication. Create, manage, and learn more about API keys in your [organization settings](/settings/organization/api-keys).

**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). API keys should be securely loaded from an environment variable or key management service on the server.

API keys should be provided via [HTTP Bearer authentication](https://swagger.io/docs/specification/v3_0/authentication/bearer-authentication/).

    Authorization: Bearer OPENAI_API_KEY

If you belong to multiple organizations or access projects through a legacy user API key, pass a header to specify which organization and project to use for an API request:
    curl https://api.openai.com/v1/models \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Organization: YOUR_ORG_ID" \
      -H "OpenAI-Project: $PROJECT_ID"

Usage from these API requests counts as usage for the specified organization and project.Organization IDs can be found on your [organization settings](/settings/organization/general) page. Project IDs can be found on your [general settings](/settings) page by selecting the specific project.

Debugging requests
------------------

In addition to [error codes](/docs/guides/error-codes) returned from API responses, you can inspect HTTP response headers containing the unique ID of a particular API request or information about rate limiting applied to your requests. Below is an incomplete list of HTTP headers returned with API responses:

**API meta information**

*   `openai-organization`: The [organization](/docs/guides/production-best-practices#setting-up-your-organization) associated with the request
*   `openai-processing-ms`: Time taken processing your API request
*   `openai-version`: REST API version used for this request (currently `2020-10-01`)
*   `x-request-id`: Unique identifier for this API request (used in troubleshooting)

**[Rate limiting information](/docs/guides/rate-limits)**

*   `x-ratelimit-limit-requests`
*   `x-ratelimit-limit-tokens`
*   `x-ratelimit-remaining-requests`
*   `x-ratelimit-remaining-tokens`
*   `x-ratelimit-reset-requests`
*   `x-ratelimit-reset-tokens`

**OpenAI recommends logging request IDs in production deployments** for more efficient troubleshooting with our [support team](https://help.openai.com/en/), should the need arise. Our [official SDKs](/docs/libraries) provide a property on top-level response objects containing the value of the `x-request-id` header.

Backward compatibility
----------------------

OpenAI is committed to providing stability to API users by avoiding breaking changes in major API versions whenever reasonably possible. This includes:

*   The REST API (currently `v1`)
*   Our first-party [SDKs](/docs/libraries) (released SDKs adhere to [semantic versioning](https://semver.org/))
*   [Model](/docs/models) families (like `gpt-4o` or `o4-mini`)

**Model prompting behavior between snapshots is subject to change**. Model outputs are by their nature variable, so expect changes in prompting and model behavior between snapshots. For example, if you moved from `gpt-4o-2024-05-13` to `gpt-4o-2024-08-06`, the same `system` or `user` messages could function differently between versions. The best way to ensure consistent prompting behavior and model output is to use pinned model versions, and to implement [evals](/docs/guides/evals) for your applications.

**Backwards-compatible API changes**:

*   Adding new resources (URLs) to the REST API and SDKs
*   Adding new optional API parameters
*   Adding new properties to JSON response objects or event data
*   Changing the order of properties in a JSON response object
*   Changing the length or format of opaque strings, like resource identifiers and UUIDs
*   Adding new event types (in either streaming or the Realtime API)

See the [changelog](/docs/changelog) for a list of backwards-compatible changes and rare breaking changes.

Responses


-------------

OpenAI's most advanced interface for generating model responses. Supports text and image inputs, and text outputs. Create stateful interactions with the model, using the output of previous responses as input. Extend the model's capabilities with built-in tools for file search, web search, computer use, and more. Allow the model access to external systems and data using function calling.

Related guides:

*   [Quickstart](/docs/quickstart?api-mode=responses)
*   [Text inputs and outputs](/docs/guides/text?api-mode=responses)
*   [Image inputs](/docs/guides/images?api-mode=responses)
*   [Structured Outputs](/docs/guides/structured-outputs?api-mode=responses)
*   [Function calling](/docs/guides/function-calling?api-mode=responses)
*   [Conversation state](/docs/guides/conversation-state?api-mode=responses)
*   [Extend the models with tools](/docs/guides/tools?api-mode=responses)

Create a model response


---------------------------

postÂ https://api.openai.com/v1/responses

Creates a model response. Provide [text](/docs/guides/text) or [image](/docs/guides/images) inputs to generate [text](/docs/guides/text) or [JSON](/docs/guides/structured-outputs) outputs. Have the model call your own [custom code](/docs/guides/function-calling) or use built-in [tools](/docs/guides/tools) like [web search](/docs/guides/tools-web-search) or [file search](/docs/guides/tools-file-search) to use your own data as input for the model's response.

#### Request body

[](#responses-create-input)

input

string or array

Required

Text, image, or file inputs to the model, used to generate a response.

Learn more:

*   [Text inputs and outputs](/docs/guides/text)
*   [Image inputs](/docs/guides/images)
*   [File inputs](/docs/guides/pdf-files)
*   [Conversation state](/docs/guides/conversation-state)
*   [Function calling](/docs/guides/function-calling)

Show possible types

[](#responses-create-model)

model

string

Required

Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the [model guide](/docs/models) to browse and compare available models.

[](#responses-create-include)

include

array or null

Optional

Specify additional output data to include in the model response. Currently supported values are:

*   `file_search_call.results`: Include the search results of the file search tool call.
*   `message.input_image.image_url`: Include image urls from the input message.
*   `computer_call_output.output.image_url`: Include image urls from the computer call output.
*   `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).

[](#responses-create-instructions)

instructions

string or null

Optional

Inserts a system (or developer) message as the first item in the model's context.

When using along with `previous_response_id`, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

[](#responses-create-max_output_tokens)

max\_output\_tokens

integer or null

Optional

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

[](#responses-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#responses-create-parallel_tool_calls)

parallel\_tool\_calls

boolean or null

Optional

Defaults to true

Whether to allow the model to run tool calls in parallel.

[](#responses-create-previous_response_id)

previous\_response\_id

string or null

Optional

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about [conversation state](/docs/guides/conversation-state).

[](#responses-create-reasoning)

reasoning

object or null

Optional

**o-series models only**

Configuration options for [reasoning models](https://platform.openai.com/docs/guides/reasoning).

Show properties

[](#responses-create-service_tier)

service\_tier

string or null

Optional

Defaults to auto

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

*   If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
*   If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
*   When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

[](#responses-create-store)

store

boolean or null

Optional

Defaults to true

Whether to store the generated model response for later retrieval via API.

[](#responses-create-stream)

stream

boolean or null

Optional

Defaults to false

If set to true, the model response data will be streamed to the client as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format). See the [Streaming section below](/docs/api-reference/responses-streaming) for more information.

[](#responses-create-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both.

[](#responses-create-text)

text

object

Optional

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

*   [Text inputs and outputs](/docs/guides/text)
*   [Structured Outputs](/docs/guides/structured-outputs)

Show properties

[](#responses-create-tool_choice)

tool\_choice

string or object

Optional

How the model should select which tool (or tools) to use when generating a response. See the `tools` parameter to see how to specify which tools the model can call.

Show possible types

[](#responses-create-tools)

tools

array

Optional

An array of tools the model may call while generating a response. You can specify which tool to use by setting the `tool_choice` parameter.

The two categories of tools you can provide the model are:

*   **Built-in tools**: Tools that are provided by OpenAI that extend the model's capabilities, like [web search](/docs/guides/tools-web-search) or [file search](/docs/guides/tools-file-search). Learn more about [built-in tools](/docs/guides/tools).
*   **Function calls (custom tools)**: Functions that are defined by you, enabling the model to call your own code. Learn more about [function calling](/docs/guides/function-calling).

Show possible types

[](#responses-create-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

[](#responses-create-truncation)

truncation

string or null

Optional

Defaults to disabled

The truncation strategy to use for the model response.

*   `auto`: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.
*   `disabled` (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.

[](#responses-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

Returns a [Response](/docs/api-reference/responses/object) object.

Text inputText inputImage inputImage inputWeb searchWeb searchFile searchFile searchStreamingStreamingFunctionsFunctionsReasoningReasoning

Example request

curl
    curl https://api.openai.com/v1/responses \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "model": "gpt-4.1",
        "input": "Tell me a three sentence bedtime story about a unicorn."
      }'
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    const response = await openai.responses.create({
        model: "gpt-4.1",
        input: "Tell me a three sentence bedtime story about a unicorn."
    });
    
    console.log(response);
    from openai import OpenAI
    
    client = OpenAI()
    
    response = client.responses.create(
      model="gpt-4.1",
      input="Tell me a three sentence bedtime story about a unicorn."
    )
    
    print(response)
    using System;
    using OpenAI.Responses;
    
    OpenAIResponseClient client = new(
        model: "gpt-4.1",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    OpenAIResponse response = client.CreateResponse("Tell me a three sentence bedtime story about a unicorn.");
    
    Console.WriteLine(response.GetOutputText());

Response
    {
      "id": "resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b",
      "object": "response",
      "created_at": 1741476542,
      "status": "completed",
      "error": null,
      "incomplete_details": null,
      "instructions": null,
      "max_output_tokens": null,
      "model": "gpt-4.1-2025-04-14",
      "output": [
        {
          "type": "message",
          "id": "msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b",
          "status": "completed",
          "role": "assistant",
          "content": [
            {
              "type": "output_text",
              "text": "In a peaceful grove beneath a silver moon, a unicorn named Lumina discovered a hidden pool that reflected the stars. As she dipped her horn into the water, the pool began to shimmer, revealing a pathway to a magical realm of endless night skies. Filled with wonder, Lumina whispered a wish for all who dream to find their own hidden magic, and as she glanced back, her hoofprints sparkled like stardust.",
              "annotations": []
            }
          ]
        }
      ],
      "parallel_tool_calls": true,
      "previous_response_id": null,
      "reasoning": {
        "effort": null,
        "summary": null
      },
      "store": true,
      "temperature": 1.0,
      "text": {
        "format": {
          "type": "text"
        }
      },
      "tool_choice": "auto",
      "tools": [],
      "top_p": 1.0,
      "truncation": "disabled",
      "usage": {
        "input_tokens": 36,
        "input_tokens_details": {
          "cached_tokens": 0
        },
        "output_tokens": 87,
        "output_tokens_details": {
          "reasoning_tokens": 0
        },
        "total_tokens": 123
      },
      "user": null,
      "metadata": {}
    }

Get a model response


------------------------

getÂ https://api.openai.com/v1/responses/{response\_id}

Retrieves a model response with the given ID.

#### Path parameters

[](#responses-get-response_id)

response\_id

string

Required

The ID of the response to retrieve.

#### Query parameters

[](#responses-get-include)

include

array

Optional

Additional fields to include in the response. See the `include` parameter for Response creation above for more information.

#### Returns

The [Response](/docs/api-reference/responses/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/responses/resp_123 \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer $OPENAI_API_KEY"
    import OpenAI from "openai";
    const client = new OpenAI();
    
    const response = await client.responses.retrieve("resp_123");
    console.log(response);
    from openai import OpenAI
    client = OpenAI()
    
    response = client.responses.retrieve("resp_123")
    print(response)

Response
    {
      "id": "resp_67cb71b351908190a308f3859487620d06981a8637e6bc44",
      "object": "response",
      "created_at": 1741386163,
      "status": "completed",
      "error": null,
      "incomplete_details": null,
      "instructions": null,
      "max_output_tokens": null,
      "model": "gpt-4o-2024-08-06",
      "output": [
        {
          "type": "message",
          "id": "msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44",
          "status": "completed",
          "role": "assistant",
          "content": [
            {
              "type": "output_text",
              "text": "Silent circuits hum,  \nThoughts emerge in data streamsâ  \nDigital dawn breaks.",
              "annotations": []
            }
          ]
        }
      ],
      "parallel_tool_calls": true,
      "previous_response_id": null,
      "reasoning": {
        "effort": null,
        "summary": null
      },
      "store": true,
      "temperature": 1.0,
      "text": {
        "format": {
          "type": "text"
        }
      },
      "tool_choice": "auto",
      "tools": [],
      "top_p": 1.0,
      "truncation": "disabled",
      "usage": {
        "input_tokens": 32,
        "input_tokens_details": {
          "cached_tokens": 0
        },
        "output_tokens": 18,
        "output_tokens_details": {
          "reasoning_tokens": 0
        },
        "total_tokens": 50
      },
      "user": null,
      "metadata": {}
    }

Delete a model response


---------------------------

deleteÂ https://api.openai.com/v1/responses/{response\_id}

Deletes a model response with the given ID.

#### Path parameters

[](#responses-delete-response_id)

response\_id

string

Required

The ID of the response to delete.

#### Returns

A success message.

Example request

curl
    curl -X DELETE https://api.openai.com/v1/responses/resp_123 \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer $OPENAI_API_KEY"
    import OpenAI from "openai";
    const client = new OpenAI();
    
    const response = await client.responses.del("resp_123");
    console.log(response);
    from openai import OpenAI
    client = OpenAI()
    
    response = client.responses.del("resp_123")
    print(response)

Response
    {
      "id": "resp_6786a1bec27481909a17d673315b29f6",
      "object": "response",
      "deleted": true
    }

List input items


--------------------

getÂ https://api.openai.com/v1/responses/{response\_id}/input\_items

Returns a list of input items for a given response.

#### Path parameters

[](#responses-input-items-response_id)

response\_id

string

Required

The ID of the response to retrieve input items for.

#### Query parameters

[](#responses-input-items-after)

after

string

Optional

An item ID to list items after, used in pagination.

[](#responses-input-items-before)

before

string

Optional

An item ID to list items before, used in pagination.

[](#responses-input-items-include)

include

array

Optional

Additional fields to include in the response. See the `include` parameter for Response creation above for more information.

[](#responses-input-items-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#responses-input-items-order)

order

string

Optional

The order to return the input items in. Default is `asc`.

*   `asc`: Return the input items in ascending order.
*   `desc`: Return the input items in descending order.

#### Returns

A list of input item objects.

Example request

curl
    curl https://api.openai.com/v1/responses/resp_abc123/input_items \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    import OpenAI from "openai";
    const client = new OpenAI();
    
    const response = await client.responses.inputItems.list("resp_123");
    console.log(response.data);
    from openai import OpenAI
    client = OpenAI()
    
    response = client.responses.input_items.list("resp_123")
    print(response.data)

Response
    {
      "object": "list",
      "data": [
        {
          "id": "msg_abc123",
          "type": "message",
          "role": "user",
          "content": [
            {
              "type": "input_text",
              "text": "Tell me a three sentence bedtime story about a unicorn."
            }
          ]
        }
      ],
      "first_id": "msg_abc123",
      "last_id": "msg_abc123",
      "has_more": false
    }

The response object


-----------------------

[](#responses/object-created_at)

created\_at

number

Unix timestamp (in seconds) of when this Response was created.

[](#responses/object-error)

error

object or null

An error object returned when the model fails to generate a Response.

Show properties

[](#responses/object-id)

id

string

Unique identifier for this Response.

[](#responses/object-incomplete_details)

incomplete\_details

object or null

Details about why the response is incomplete.

Show properties

[](#responses/object-instructions)

instructions

string or null

Inserts a system (or developer) message as the first item in the model's context.

When using along with `previous_response_id`, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

[](#responses/object-max_output_tokens)

max\_output\_tokens

integer or null

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

[](#responses/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#responses/object-model)

model

string

Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the [model guide](/docs/models) to browse and compare available models.

[](#responses/object-object)

object

string

The object type of this resource - always set to `response`.

[](#responses/object-output)

output

array

An array of content items generated by the model.

*   The length and order of items in the `output` array is dependent on the model's response.
*   Rather than accessing the first item in the `output` array and assuming it's an `assistant` message with the content generated by the model, you might consider using the `output_text` property where supported in SDKs.

Show possible types

[](#responses/object-output_text)

output\_text

string or null

SDK Only

SDK-only convenience property that contains the aggregated text output from all `output_text` items in the `output` array, if any are present. Supported in the Python and JavaScript SDKs.

[](#responses/object-parallel_tool_calls)

parallel\_tool\_calls

boolean

Whether to allow the model to run tool calls in parallel.

[](#responses/object-previous_response_id)

previous\_response\_id

string or null

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about [conversation state](/docs/guides/conversation-state).

[](#responses/object-reasoning)

reasoning

object or null

**o-series models only**

Configuration options for [reasoning models](https://platform.openai.com/docs/guides/reasoning).

Show properties

[](#responses/object-service_tier)

service\_tier

string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

*   If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
*   If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
*   When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

[](#responses/object-status)

status

string

The status of the response generation. One of `completed`, `failed`, `in_progress`, or `incomplete`.

[](#responses/object-temperature)

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both.

[](#responses/object-text)

text

object

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

*   [Text inputs and outputs](/docs/guides/text)
*   [Structured Outputs](/docs/guides/structured-outputs)

Show properties

[](#responses/object-tool_choice)

tool\_choice

string or object

How the model should select which tool (or tools) to use when generating a response. See the `tools` parameter to see how to specify which tools the model can call.

Show possible types

[](#responses/object-tools)

tools

array

An array of tools the model may call while generating a response. You can specify which tool to use by setting the `tool_choice` parameter.

The two categories of tools you can provide the model are:

*   **Built-in tools**: Tools that are provided by OpenAI that extend the model's capabilities, like [web search](/docs/guides/tools-web-search) or [file search](/docs/guides/tools-file-search). Learn more about [built-in tools](/docs/guides/tools).
*   **Function calls (custom tools)**: Functions that are defined by you, enabling the model to call your own code. Learn more about [function calling](/docs/guides/function-calling).

Show possible types

[](#responses/object-top_p)

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

[](#responses/object-truncation)

truncation

string or null

The truncation strategy to use for the model response.

*   `auto`: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.
*   `disabled` (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.

[](#responses/object-usage)

usage

object

Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.

Show properties

[](#responses/object-user)

user

string

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

OBJECT The response object
    {
      "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
      "object": "response",
      "created_at": 1741476777,
      "status": "completed",
      "error": null,
      "incomplete_details": null,
      "instructions": null,
      "max_output_tokens": null,
      "model": "gpt-4o-2024-08-06",
      "output": [
        {
          "type": "message",
          "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
          "status": "completed",
          "role": "assistant",
          "content": [
            {
              "type": "output_text",
              "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
              "annotations": []
            }
          ]
        }
      ],
      "parallel_tool_calls": true,
      "previous_response_id": null,
      "reasoning": {
        "effort": null,
        "summary": null
      },
      "store": true,
      "temperature": 1,
      "text": {
        "format": {
          "type": "text"
        }
      },
      "tool_choice": "auto",
      "tools": [],
      "top_p": 1,
      "truncation": "disabled",
      "usage": {
        "input_tokens": 328,
        "input_tokens_details": {
          "cached_tokens": 0
        },
        "output_tokens": 52,
        "output_tokens_details": {
          "reasoning_tokens": 0
        },
        "total_tokens": 380
      },
      "user": null,
      "metadata": {}
    }

The input item list


-----------------------

A list of Response items.

[](#responses/list-data)

data

array

A list of items used to generate this response.

Show possible types

[](#responses/list-first_id)

first\_id

string

The ID of the first item in the list.

[](#responses/list-has_more)

has\_more

boolean

Whether there are more items available.

[](#responses/list-last_id)

last\_id

string

The ID of the last item in the list.

[](#responses/list-object)

object

string

The type of object returned, must be `list`.

OBJECT The input item list
    {
      "object": "list",
      "data": [
        {
          "id": "msg_abc123",
          "type": "message",
          "role": "user",
          "content": [
            {
              "type": "input_text",
              "text": "Tell me a three sentence bedtime story about a unicorn."
            }
          ]
        }
      ],
      "first_id": "msg_abc123",
      "last_id": "msg_abc123",
      "has_more": false
    }

Streaming


-------------

When you [create a Response](/docs/api-reference/responses/create) with `stream` set to `true`, the server will emit server-sent events to the client as the Response is generated. This section contains the events that are emitted by the server.

[Learn more about streaming responses](/docs/guides/streaming-responses?api-mode=responses).

response.created


--------------------

An event that is emitted when a response is created.

[](#responses-streaming/response/created-response)

response

object

The response that was created.

Show properties

[](#responses-streaming/response/created-type)

type

string

The type of the event. Always `response.created`.

OBJECT response.created
    {
      "type": "response.created",
      "response": {
        "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
        "object": "response",
        "created_at": 1741487325,
        "status": "in_progress",
        "error": null,
        "incomplete_details": null,
        "instructions": null,
        "max_output_tokens": null,
        "model": "gpt-4o-2024-08-06",
        "output": [],
        "parallel_tool_calls": true,
        "previous_response_id": null,
        "reasoning": {
          "effort": null,
          "summary": null
        },
        "store": true,
        "temperature": 1,
        "text": {
          "format": {
            "type": "text"
          }
        },
        "tool_choice": "auto",
        "tools": [],
        "top_p": 1,
        "truncation": "disabled",
        "usage": null,
        "user": null,
        "metadata": {}
      }
    }

response.in\_progress


-------------------------

Emitted when the response is in progress.

[](#responses-streaming/response/in_progress-response)

response

object

The response that is in progress.

Show properties

[](#responses-streaming/response/in_progress-type)

type

string

The type of the event. Always `response.in_progress`.

OBJECT response.in\_progress
    {
      "type": "response.in_progress",
      "response": {
        "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
        "object": "response",
        "created_at": 1741487325,
        "status": "in_progress",
        "error": null,
        "incomplete_details": null,
        "instructions": null,
        "max_output_tokens": null,
        "model": "gpt-4o-2024-08-06",
        "output": [],
        "parallel_tool_calls": true,
        "previous_response_id": null,
        "reasoning": {
          "effort": null,
          "summary": null
        },
        "store": true,
        "temperature": 1,
        "text": {
          "format": {
            "type": "text"
          }
        },
        "tool_choice": "auto",
        "tools": [],
        "top_p": 1,
        "truncation": "disabled",
        "usage": null,
        "user": null,
        "metadata": {}
      }
    }

response.completed


----------------------

Emitted when the model response is complete.

[](#responses-streaming/response/completed-response)

response

object

Properties of the completed response.

Show properties

[](#responses-streaming/response/completed-type)

type

string

The type of the event. Always `response.completed`.

OBJECT response.completed
    {
      "type": "response.completed",
      "response": {
        "id": "resp_123",
        "object": "response",
        "created_at": 1740855869,
        "status": "completed",
        "error": null,
        "incomplete_details": null,
        "input": [],
        "instructions": null,
        "max_output_tokens": null,
        "model": "gpt-4o-mini-2024-07-18",
        "output": [
          {
            "id": "msg_123",
            "type": "message",
            "role": "assistant",
            "content": [
              {
                "type": "output_text",
                "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
                "annotations": []
              }
            ]
          }
        ],
        "previous_response_id": null,
        "reasoning_effort": null,
        "store": false,
        "temperature": 1,
        "text": {
          "format": {
            "type": "text"
          }
        },
        "tool_choice": "auto",
        "tools": [],
        "top_p": 1,
        "truncation": "disabled",
        "usage": {
          "input_tokens": 0,
          "output_tokens": 0,
          "output_tokens_details": {
            "reasoning_tokens": 0
          },
          "total_tokens": 0
        },
        "user": null,
        "metadata": {}
      }
    }

response.failed


-------------------

An event that is emitted when a response fails.

[](#responses-streaming/response/failed-response)

response

object

The response that failed.

Show properties

[](#responses-streaming/response/failed-type)

type

string

The type of the event. Always `response.failed`.

OBJECT response.failed
    {
      "type": "response.failed",
      "response": {
        "id": "resp_123",
        "object": "response",
        "created_at": 1740855869,
        "status": "failed",
        "error": {
          "code": "server_error",
          "message": "The model failed to generate a response."
        },
        "incomplete_details": null,
        "instructions": null,
        "max_output_tokens": null,
        "model": "gpt-4o-mini-2024-07-18",
        "output": [],
        "previous_response_id": null,
        "reasoning_effort": null,
        "store": false,
        "temperature": 1,
        "text": {
          "format": {
            "type": "text"
          }
        },
        "tool_choice": "auto",
        "tools": [],
        "top_p": 1,
        "truncation": "disabled",
        "usage": null,
        "user": null,
        "metadata": {}
      }
    }

response.incomplete


-----------------------

An event that is emitted when a response finishes as incomplete.

[](#responses-streaming/response/incomplete-response)

response

object

The response that was incomplete.

Show properties

[](#responses-streaming/response/incomplete-type)

type

string

The type of the event. Always `response.incomplete`.

OBJECT response.incomplete
    {
      "type": "response.incomplete",
      "response": {
        "id": "resp_123",
        "object": "response",
        "created_at": 1740855869,
        "status": "incomplete",
        "error": null, 
        "incomplete_details": {
          "reason": "max_tokens"
        },
        "instructions": null,
        "max_output_tokens": null,
        "model": "gpt-4o-mini-2024-07-18",
        "output": [],
        "previous_response_id": null,
        "reasoning_effort": null,
        "store": false,
        "temperature": 1,
        "text": {
          "format": {
            "type": "text"
          }
        },
        "tool_choice": "auto",
        "tools": [],
        "top_p": 1,
        "truncation": "disabled",
        "usage": null,
        "user": null,
        "metadata": {}
      }
    }

response.output\_item.added


-------------------------------

Emitted when a new output item is added.

[](#responses-streaming/response/output_item/added-item)

item

object

The output item that was added.

Show possible types

[](#responses-streaming/response/output_item/added-output_index)

output\_index

integer

The index of the output item that was added.

[](#responses-streaming/response/output_item/added-type)

type

string

The type of the event. Always `response.output_item.added`.

OBJECT response.output\_item.added
    {
      "type": "response.output_item.added",
      "output_index": 0,
      "item": {
        "id": "msg_123",
        "status": "in_progress",
        "type": "message",
        "role": "assistant",
        "content": []
      }
    }

response.output\_item.done


------------------------------

Emitted when an output item is marked done.

[](#responses-streaming/response/output_item/done-item)

item

object

The output item that was marked done.

Show possible types

[](#responses-streaming/response/output_item/done-output_index)

output\_index

integer

The index of the output item that was marked done.

[](#responses-streaming/response/output_item/done-type)

type

string

The type of the event. Always `response.output_item.done`.

OBJECT response.output\_item.done
    {
      "type": "response.output_item.done",
      "output_index": 0,
      "item": {
        "id": "msg_123",
        "status": "completed",
        "type": "message",
        "role": "assistant",
        "content": [
          {
            "type": "output_text",
            "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
            "annotations": []
          }
        ]
      }
    }

response.content\_part.added


--------------------------------

Emitted when a new content part is added.

[](#responses-streaming/response/content_part/added-content_index)

content\_index

integer

The index of the content part that was added.

[](#responses-streaming/response/content_part/added-item_id)

item\_id

string

The ID of the output item that the content part was added to.

[](#responses-streaming/response/content_part/added-output_index)

output\_index

integer

The index of the output item that the content part was added to.

[](#responses-streaming/response/content_part/added-part)

part

object

The content part that was added.

Show possible types

[](#responses-streaming/response/content_part/added-type)

type

string

The type of the event. Always `response.content_part.added`.

OBJECT response.content\_part.added
    {
      "type": "response.content_part.added",
      "item_id": "msg_123",
      "output_index": 0,
      "content_index": 0,
      "part": {
        "type": "output_text",
        "text": "",
        "annotations": []
      }
    }

response.content\_part.done


-------------------------------

Emitted when a content part is done.

[](#responses-streaming/response/content_part/done-content_index)

content\_index

integer

The index of the content part that is done.

[](#responses-streaming/response/content_part/done-item_id)

item\_id

string

The ID of the output item that the content part was added to.

[](#responses-streaming/response/content_part/done-output_index)

output\_index

integer

The index of the output item that the content part was added to.

[](#responses-streaming/response/content_part/done-part)

part

object

The content part that is done.

Show possible types

[](#responses-streaming/response/content_part/done-type)

type

string

The type of the event. Always `response.content_part.done`.

OBJECT response.content\_part.done
    {
      "type": "response.content_part.done",
      "item_id": "msg_123",
      "output_index": 0,
      "content_index": 0,
      "part": {
        "type": "output_text",
        "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
        "annotations": []
      }
    }

response.output\_text.delta


-------------------------------

Emitted when there is an additional text delta.

[](#responses-streaming/response/output_text/delta-content_index)

content\_index

integer

The index of the content part that the text delta was added to.

[](#responses-streaming/response/output_text/delta-delta)

delta

string

The text delta that was added.

[](#responses-streaming/response/output_text/delta-item_id)

item\_id

string

The ID of the output item that the text delta was added to.

[](#responses-streaming/response/output_text/delta-output_index)

output\_index

integer

The index of the output item that the text delta was added to.

[](#responses-streaming/response/output_text/delta-type)

type

string

The type of the event. Always `response.output_text.delta`.

OBJECT response.output\_text.delta
    {
      "type": "response.output_text.delta",
      "item_id": "msg_123",
      "output_index": 0,
      "content_index": 0,
      "delta": "In"
    }

response.output\_text.annotation.added


------------------------------------------

Emitted when a text annotation is added.

[](#responses-streaming/response/output_text/annotation/added-annotation)

annotation

object

Show possible types

[](#responses-streaming/response/output_text/annotation/added-annotation_index)

annotation\_index

integer

The index of the annotation that was added.

[](#responses-streaming/response/output_text/annotation/added-content_index)

content\_index

integer

The index of the content part that the text annotation was added to.

[](#responses-streaming/response/output_text/annotation/added-item_id)

item\_id

string

The ID of the output item that the text annotation was added to.

[](#responses-streaming/response/output_text/annotation/added-output_index)

output\_index

integer

The index of the output item that the text annotation was added to.

[](#responses-streaming/response/output_text/annotation/added-type)

type

string

The type of the event. Always `response.output_text.annotation.added`.

OBJECT response.output\_text.annotation.added
    {
      "type": "response.output_text.annotation.added",
      "item_id": "msg_abc123",
      "output_index": 1,
      "content_index": 0,
      "annotation_index": 0,
      "annotation": {
        "type": "file_citation",
        "index": 390,
        "file_id": "file-4wDz5b167pAf72nx1h9eiN",
        "filename": "dragons.pdf"
      }
    }

response.output\_text.done


------------------------------

Emitted when text content is finalized.

[](#responses-streaming/response/output_text/done-content_index)

content\_index

integer

The index of the content part that the text content is finalized.

[](#responses-streaming/response/output_text/done-item_id)

item\_id

string

The ID of the output item that the text content is finalized.

[](#responses-streaming/response/output_text/done-output_index)

output\_index

integer

The index of the output item that the text content is finalized.

[](#responses-streaming/response/output_text/done-text)

text

string

The text content that is finalized.

[](#responses-streaming/response/output_text/done-type)

type

string

The type of the event. Always `response.output_text.done`.

OBJECT response.output\_text.done
    {
      "type": "response.output_text.done",
      "item_id": "msg_123",
      "output_index": 0,
      "content_index": 0,
      "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic."
    }

response.refusal.delta


--------------------------

Emitted when there is a partial refusal text.

[](#responses-streaming/response/refusal/delta-content_index)

content\_index

integer

The index of the content part that the refusal text is added to.

[](#responses-streaming/response/refusal/delta-delta)

delta

string

The refusal text that is added.

[](#responses-streaming/response/refusal/delta-item_id)

item\_id

string

The ID of the output item that the refusal text is added to.

[](#responses-streaming/response/refusal/delta-output_index)

output\_index

integer

The index of the output item that the refusal text is added to.

[](#responses-streaming/response/refusal/delta-type)

type

string

The type of the event. Always `response.refusal.delta`.

OBJECT response.refusal.delta
    {
      "type": "response.refusal.delta",
      "item_id": "msg_123",
      "output_index": 0,
      "content_index": 0,
      "delta": "refusal text so far"
    }

response.refusal.done


-------------------------

Emitted when refusal text is finalized.

[](#responses-streaming/response/refusal/done-content_index)

content\_index

integer

The index of the content part that the refusal text is finalized.

[](#responses-streaming/response/refusal/done-item_id)

item\_id

string

The ID of the output item that the refusal text is finalized.

[](#responses-streaming/response/refusal/done-output_index)

output\_index

integer

The index of the output item that the refusal text is finalized.

[](#responses-streaming/response/refusal/done-refusal)

refusal

string

The refusal text that is finalized.

[](#responses-streaming/response/refusal/done-type)

type

string

The type of the event. Always `response.refusal.done`.

OBJECT response.refusal.done
    {
      "type": "response.refusal.done",
      "item_id": "item-abc",
      "output_index": 1,
      "content_index": 2,
      "refusal": "final refusal text"
    }

response.function\_call\_arguments.delta


--------------------------------------------

Emitted when there is a partial function-call arguments delta.

[](#responses-streaming/response/function_call_arguments/delta-delta)

delta

string

The function-call arguments delta that is added.

[](#responses-streaming/response/function_call_arguments/delta-item_id)

item\_id

string

The ID of the output item that the function-call arguments delta is added to.

[](#responses-streaming/response/function_call_arguments/delta-output_index)

output\_index

integer

The index of the output item that the function-call arguments delta is added to.

[](#responses-streaming/response/function_call_arguments/delta-type)

type

string

The type of the event. Always `response.function_call_arguments.delta`.

OBJECT response.function\_call\_arguments.delta
    {
      "type": "response.function_call_arguments.delta",
      "item_id": "item-abc",
      "output_index": 0,
      "delta": "{ \"arg\":"
    }

response.function\_call\_arguments.done


-------------------------------------------

Emitted when function-call arguments are finalized.

[](#responses-streaming/response/function_call_arguments/done-arguments)

arguments

string

The function-call arguments.

[](#responses-streaming/response/function_call_arguments/done-item_id)

item\_id

string

The ID of the item.

[](#responses-streaming/response/function_call_arguments/done-output_index)

output\_index

integer

The index of the output item.

[](#responses-streaming/response/function_call_arguments/done-type)

type

string

OBJECT response.function\_call\_arguments.done
    {
      "type": "response.function_call_arguments.done",
      "item_id": "item-abc",
      "output_index": 1,
      "arguments": "{ \"arg\": 123 }"
    }

response.file\_search\_call.in\_progress


--------------------------------------------

Emitted when a file search call is initiated.

[](#responses-streaming/response/file_search_call/in_progress-item_id)

item\_id

string

The ID of the output item that the file search call is initiated.

[](#responses-streaming/response/file_search_call/in_progress-output_index)

output\_index

integer

The index of the output item that the file search call is initiated.

[](#responses-streaming/response/file_search_call/in_progress-type)

type

string

The type of the event. Always `response.file_search_call.in_progress`.

OBJECT response.file\_search\_call.in\_progress
    {
      "type": "response.file_search_call.in_progress",
      "output_index": 0,
      "item_id": "fs_123",
    }

response.file\_search\_call.searching


-----------------------------------------

Emitted when a file search is currently searching.

[](#responses-streaming/response/file_search_call/searching-item_id)

item\_id

string

The ID of the output item that the file search call is initiated.

[](#responses-streaming/response/file_search_call/searching-output_index)

output\_index

integer

The index of the output item that the file search call is searching.

[](#responses-streaming/response/file_search_call/searching-type)

type

string

The type of the event. Always `response.file_search_call.searching`.

OBJECT response.file\_search\_call.searching
    {
      "type": "response.file_search_call.searching",
      "output_index": 0,
      "item_id": "fs_123",
    }

response.file\_search\_call.completed


-----------------------------------------

Emitted when a file search call is completed (results found).

[](#responses-streaming/response/file_search_call/completed-item_id)

item\_id

string

The ID of the output item that the file search call is initiated.

[](#responses-streaming/response/file_search_call/completed-output_index)

output\_index

integer

The index of the output item that the file search call is initiated.

[](#responses-streaming/response/file_search_call/completed-type)

type

string

The type of the event. Always `response.file_search_call.completed`.

OBJECT response.file\_search\_call.completed
    {
      "type": "response.file_search_call.completed",
      "output_index": 0,
      "item_id": "fs_123",
    }

response.web\_search\_call.in\_progress


-------------------------------------------

Emitted when a web search call is initiated.

[](#responses-streaming/response/web_search_call/in_progress-item_id)

item\_id

string

Unique ID for the output item associated with the web search call.

[](#responses-streaming/response/web_search_call/in_progress-output_index)

output\_index

integer

The index of the output item that the web search call is associated with.

[](#responses-streaming/response/web_search_call/in_progress-type)

type

string

The type of the event. Always `response.web_search_call.in_progress`.

OBJECT response.web\_search\_call.in\_progress
    {
      "type": "response.web_search_call.in_progress",
      "output_index": 0,
      "item_id": "ws_123",
    }

response.web\_search\_call.searching


----------------------------------------

Emitted when a web search call is executing.

[](#responses-streaming/response/web_search_call/searching-item_id)

item\_id

string

Unique ID for the output item associated with the web search call.

[](#responses-streaming/response/web_search_call/searching-output_index)

output\_index

integer

The index of the output item that the web search call is associated with.

[](#responses-streaming/response/web_search_call/searching-type)

type

string

The type of the event. Always `response.web_search_call.searching`.

OBJECT response.web\_search\_call.searching
    {
      "type": "response.web_search_call.searching",
      "output_index": 0,
      "item_id": "ws_123",
    }

response.web\_search\_call.completed


----------------------------------------

Emitted when a web search call is completed.

[](#responses-streaming/response/web_search_call/completed-item_id)

item\_id

string

Unique ID for the output item associated with the web search call.

[](#responses-streaming/response/web_search_call/completed-output_index)

output\_index

integer

The index of the output item that the web search call is associated with.

[](#responses-streaming/response/web_search_call/completed-type)

type

string

The type of the event. Always `response.web_search_call.completed`.

OBJECT response.web\_search\_call.completed
    {
      "type": "response.web_search_call.completed",
      "output_index": 0,
      "item_id": "ws_123",
    }

response.reasoning\_summary\_part.added


-------------------------------------------

Emitted when a new reasoning summary part is added.

[](#responses-streaming/response/reasoning_summary_part/added-item_id)

item\_id

string

The ID of the item this summary part is associated with.

[](#responses-streaming/response/reasoning_summary_part/added-output_index)

output\_index

integer

The index of the output item this summary part is associated with.

[](#responses-streaming/response/reasoning_summary_part/added-part)

part

object

The summary part that was added.

Show properties

[](#responses-streaming/response/reasoning_summary_part/added-summary_index)

summary\_index

integer

The index of the summary part within the reasoning summary.

[](#responses-streaming/response/reasoning_summary_part/added-type)

type

string

The type of the event. Always `response.reasoning_summary_part.added`.

OBJECT response.reasoning\_summary\_part.added
    {
      "type": "response.reasoning_summary_part.added",
      "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
      "output_index": 0,
      "summary_index": 0,
      "part": {
        "type": "summary_text",
        "text": ""
      }
    }

response.reasoning\_summary\_part.done


------------------------------------------

Emitted when a reasoning summary part is completed.

[](#responses-streaming/response/reasoning_summary_part/done-item_id)

item\_id

string

The ID of the item this summary part is associated with.

[](#responses-streaming/response/reasoning_summary_part/done-output_index)

output\_index

integer

The index of the output item this summary part is associated with.

[](#responses-streaming/response/reasoning_summary_part/done-part)

part

object

The completed summary part.

Show properties

[](#responses-streaming/response/reasoning_summary_part/done-summary_index)

summary\_index

integer

The index of the summary part within the reasoning summary.

[](#responses-streaming/response/reasoning_summary_part/done-type)

type

string

The type of the event. Always `response.reasoning_summary_part.done`.

OBJECT response.reasoning\_summary\_part.done
    {
      "type": "response.reasoning_summary_part.done",
      "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
      "output_index": 0,
      "summary_index": 0,
      "part": {
        "type": "summary_text",
        "text": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!"
      }
    }

response.reasoning\_summary\_text.delta


-------------------------------------------

Emitted when a delta is added to a reasoning summary text.

[](#responses-streaming/response/reasoning_summary_text/delta-delta)

delta

string

The text delta that was added to the summary.

[](#responses-streaming/response/reasoning_summary_text/delta-item_id)

item\_id

string

The ID of the item this summary text delta is associated with.

[](#responses-streaming/response/reasoning_summary_text/delta-output_index)

output\_index

integer

The index of the output item this summary text delta is associated with.

[](#responses-streaming/response/reasoning_summary_text/delta-summary_index)

summary\_index

integer

The index of the summary part within the reasoning summary.

[](#responses-streaming/response/reasoning_summary_text/delta-type)

type

string

The type of the event. Always `response.reasoning_summary_text.delta`.

OBJECT response.reasoning\_summary\_text.delta
    {
      "type": "response.reasoning_summary_text.delta",
      "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
      "output_index": 0,
      "summary_index": 0,
      "delta": "**Respond"
    }

response.reasoning\_summary\_text.done


------------------------------------------

Emitted when a reasoning summary text is completed.

[](#responses-streaming/response/reasoning_summary_text/done-item_id)

item\_id

string

The ID of the item this summary text is associated with.

[](#responses-streaming/response/reasoning_summary_text/done-output_index)

output\_index

integer

The index of the output item this summary text is associated with.

[](#responses-streaming/response/reasoning_summary_text/done-summary_index)

summary\_index

integer

The index of the summary part within the reasoning summary.

[](#responses-streaming/response/reasoning_summary_text/done-text)

text

string

The full text of the completed reasoning summary.

[](#responses-streaming/response/reasoning_summary_text/done-type)

type

string

The type of the event. Always `response.reasoning_summary_text.done`.

OBJECT response.reasoning\_summary\_text.done
    {
      "type": "response.reasoning_summary_text.done",
      "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
      "output_index": 0,
      "summary_index": 0,
      "text": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!"
    }

error


---------

Emitted when an error occurs.

[](#responses-streaming/error-code)

code

string or null

The error code.

[](#responses-streaming/error-message)

message

string

The error message.

[](#responses-streaming/error-param)

param

string or null

The error parameter.

[](#responses-streaming/error-type)

type

string

The type of the event. Always `error`.

OBJECT error
    {
      "type": "error",
      "code": "ERR_SOMETHING",
      "message": "Something went wrong",
      "param": null
    }

Chat Completions


--------------------

The Chat Completions API endpoint will generate a model response from a list of messages comprising a conversation.

Related guides:

*   [Quickstart](/docs/quickstart?api-mode=chat)
*   [Text inputs and outputs](/docs/guides/text?api-mode=chat)
*   [Image inputs](/docs/guides/images?api-mode=chat)
*   [Audio inputs and outputs](/docs/guides/audio?api-mode=chat)
*   [Structured Outputs](/docs/guides/structured-outputs?api-mode=chat)
*   [Function calling](/docs/guides/function-calling?api-mode=chat)
*   [Conversation state](/docs/guides/conversation-state?api-mode=chat)

**Starting a new project?** We recommend trying [Responses](/docs/api-reference/responses) to take advantage of the latest OpenAI platform features. Compare [Chat Completions with Responses](/docs/guides/responses-vs-chat-completions?api-mode=responses).

Create chat completion


--------------------------

postÂ https://api.openai.com/v1/chat/completions

**Starting a new project?** We recommend trying [Responses](/docs/api-reference/responses) to take advantage of the latest OpenAI platform features. Compare [Chat Completions with Responses](/docs/guides/responses-vs-chat-completions?api-mode=responses).

* * *

Creates a model response for the given chat conversation. Learn more in the [text generation](/docs/guides/text-generation), [vision](/docs/guides/vision), and [audio](/docs/guides/audio) guides.

Parameter support can differ depending on the model used to generate the response, particularly for newer reasoning models. Parameters that are only supported for reasoning models are noted below. For the current state of unsupported parameters in reasoning models, [refer to the reasoning guide](/docs/guides/reasoning).

#### Request body

[](#chat-create-messages)

messages

array

Required

A list of messages comprising the conversation so far. Depending on the [model](/docs/models) you use, different message types (modalities) are supported, like [text](/docs/guides/text-generation), [images](/docs/guides/vision), and [audio](/docs/guides/audio).

Show possible types

[](#chat-create-model)

model

string

Required

Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the [model guide](/docs/models) to browse and compare available models.

[](#chat-create-audio)

audio

object or null

Optional

Parameters for audio output. Required when audio output is requested with `modalities: ["audio"]`. [Learn more](/docs/guides/audio).

Show properties

[](#chat-create-frequency_penalty)

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[](#chat-create-function_call)

function\_call

Deprecated

string or object

Optional

Deprecated in favor of `tool_choice`.

Controls which (if any) function is called by the model.

`none` means the model will not call a function and instead generates a message.

`auto` means the model can pick between generating a message or calling a function.

Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

`none` is the default when no functions are present. `auto` is the default if functions are present.

Show possible types

[](#chat-create-functions)

functions

Deprecated

array

Optional

Deprecated in favor of `tools`.

A list of functions the model may generate JSON inputs for.

Show properties

[](#chat-create-logit_bias)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

[](#chat-create-logprobs)

logprobs

boolean or null

Optional

Defaults to false

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.

[](#chat-create-max_completion_tokens)

max\_completion\_tokens

integer or null

Optional

An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

[](#chat-create-max_tokens)

max\_tokens

Deprecated

integer or null

Optional

The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.

This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o-series models](/docs/guides/reasoning).

[](#chat-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#chat-create-modalities)

modalities

array or null

Optional

Output types that you would like the model to generate. Most models are capable of generating text, which is the default:

`["text"]`

The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To request that this model generate both text and audio responses, you can use:

`["text", "audio"]`

[](#chat-create-n)

n

integer or null

Optional

Defaults to 1

How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.

[](#chat-create-parallel_tool_calls)

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

[](#chat-create-prediction)

prediction

object

Optional

Configuration for a [Predicted Output](/docs/guides/predicted-outputs), which can greatly improve response times when large parts of the model response are known ahead of time. This is most common when you are regenerating a file with only minor changes to most of the content.

Show possible types

[](#chat-create-presence_penalty)

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[](#chat-create-reasoning_effort)

reasoning\_effort

string or null

Optional

Defaults to medium

**o-series models only**

Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `low`, `medium`, and `high`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

[](#chat-create-response_format)

response\_format

object

Optional

An object specifying the format that the model must output.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables the older JSON mode, which ensures the message the model generates is valid JSON. Using `json_schema` is preferred for models that support it.

Show possible types

[](#chat-create-seed)

seed

integer or null

Optional

This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result. Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

[](#chat-create-service_tier)

service\_tier

string or null

Optional

Defaults to auto

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

*   If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
*   If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
*   When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

[](#chat-create-stop)

stop

string / array / null

Optional

Defaults to null

Not supported with latest reasoning models `o3` and `o4-mini`.

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

[](#chat-create-store)

store

boolean or null

Optional

Defaults to false

Whether or not to store the output of this chat completion request for use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products.

[](#chat-create-stream)

stream

boolean or null

Optional

Defaults to false

If set to true, the model response data will be streamed to the client as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format). See the [Streaming section below](/docs/api-reference/chat/streaming) for more information, along with the [streaming responses](/docs/guides/streaming-responses) guide for more information on how to handle the streaming events.

[](#chat-create-stream_options)

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

[](#chat-create-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both.

[](#chat-create-tool_choice)

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model. `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools. Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

`none` is the default when no tools are present. `auto` is the default if tools are present.

Show possible types

[](#chat-create-tools)

tools

array

Optional

A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.

Show properties

[](#chat-create-top_logprobs)

top\_logprobs

integer or null

Optional

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.

[](#chat-create-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

[](#chat-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

[](#chat-create-web_search_options)

web\_search\_options

object

Optional

This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](/docs/guides/tools-web-search?api-mode=chat).

Show properties

#### Returns

Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.

DefaultDefaultImage inputImage inputStreamingStreamingFunctionsFunctionsLogprobsLogprobs

Example request

gpt-4.1

node.js
    curl https://api.openai.com/v1/chat/completions \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "model": "gpt-4.1",
        "messages": [
          {
            "role": "developer",
            "content": "You are a helpful assistant."
          },
          {
            "role": "user",
            "content": "Hello!"
          }
        ]
      }'
    from openai import OpenAI
    client = OpenAI()
    
    completion = client.chat.completions.create(
      model="gpt-4.1",
      messages=[
        {"role": "developer", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
      ]
    )
    
    print(completion.choices[0].message)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const completion = await openai.chat.completions.create({
        messages: [{ role: "developer", content: "You are a helpful assistant." }],
        model: "gpt-4.1",
        store: true,
      });
    
      console.log(completion.choices[0]);
    }
    
    main();
    using System;
    using System.Collections.Generic;
    
    using OpenAI.Chat;
    
    ChatClient client = new(
        model: "gpt-4.1",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    List<ChatMessage> messages =
    [
        new SystemChatMessage("You are a helpful assistant."),
        new UserChatMessage("Hello!")
    ];
    
    ChatCompletion completion = client.CompleteChat(messages);
    
    Console.WriteLine(completion.Content[0].Text);

Response
    {
      "id": "chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT",
      "object": "chat.completion",
      "created": 1741569952,
      "model": "gpt-4.1-2025-04-14",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "Hello! How can I assist you today?",
            "refusal": null,
            "annotations": []
          },
          "logprobs": null,
          "finish_reason": "stop"
        }
      ],
      "usage": {
        "prompt_tokens": 19,
        "completion_tokens": 10,
        "total_tokens": 29,
        "prompt_tokens_details": {
          "cached_tokens": 0,
          "audio_tokens": 0
        },
        "completion_tokens_details": {
          "reasoning_tokens": 0,
          "audio_tokens": 0,
          "accepted_prediction_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "service_tier": "default"
    }

Get chat completion


-----------------------

getÂ https://api.openai.com/v1/chat/completions/{completion\_id}

Get a stored chat completion. Only Chat Completions that have been created with the `store` parameter set to `true` will be returned.

#### Path parameters

[](#chat-get-completion_id)

completion\_id

string

Required

The ID of the chat completion to retrieve.

#### Returns

The [ChatCompletion](/docs/api-reference/chat/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/chat/completions/chatcmpl-abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"
    from openai import OpenAI
    client = OpenAI()
    
    completions = client.chat.completions.list()
    first_id = completions[0].id
    first_completion = client.chat.completions.retrieve(completion_id=first_id)
    print(first_completion)

Response
    {
      "object": "chat.completion",
      "id": "chatcmpl-abc123",
      "model": "gpt-4o-2024-08-06",
      "created": 1738960610,
      "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
      "tool_choice": null,
      "usage": {
        "total_tokens": 31,
        "completion_tokens": 18,
        "prompt_tokens": 13
      },
      "seed": 4944116822809979520,
      "top_p": 1.0,
      "temperature": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "system_fingerprint": "fp_50cad350e4",
      "input_user": null,
      "service_tier": "default",
      "tools": null,
      "metadata": {},
      "choices": [
        {
          "index": 0,
          "message": {
            "content": "Mind of circuits hum,  \nLearning patterns in silenceâ  \nFuture's quiet spark.",
            "role": "assistant",
            "tool_calls": null,
            "function_call": null
          },
          "finish_reason": "stop",
          "logprobs": null
        }
      ],
      "response_format": null
    }

Get chat messages


---------------------

getÂ https://api.openai.com/v1/chat/completions/{completion\_id}/messages

Get the messages in a stored chat completion. Only Chat Completions that have been created with the `store` parameter set to `true` will be returned.

#### Path parameters

[](#chat-getmessages-completion_id)

completion\_id

string

Required

The ID of the chat completion to retrieve messages from.

#### Query parameters

[](#chat-getmessages-after)

after

string

Optional

Identifier for the last message from the previous pagination request.

[](#chat-getmessages-limit)

limit

integer

Optional

Defaults to 20

Number of messages to retrieve.

[](#chat-getmessages-order)

order

string

Optional

Defaults to asc

Sort order for messages by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.

#### Returns

A list of [messages](/docs/api-reference/chat/message-list) for the specified chat completion.

Example request

curl
    curl https://api.openai.com/v1/chat/completions/chat_abc123/messages \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"
    from openai import OpenAI
    client = OpenAI()
    
    completions = client.chat.completions.list()
    first_id = completions[0].id
    first_completion = client.chat.completions.retrieve(completion_id=first_id)
    messages = client.chat.completions.messages.list(completion_id=first_id)
    print(messages)

Response
    {
      "object": "list",
      "data": [
        {
          "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
          "role": "user",
          "content": "write a haiku about ai",
          "name": null,
          "content_parts": null
        }
      ],
      "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
      "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
      "has_more": false
    }

List Chat Completions


-------------------------

getÂ https://api.openai.com/v1/chat/completions

List stored Chat Completions. Only Chat Completions that have been stored with the `store` parameter set to `true` will be returned.

#### Query parameters

[](#chat-list-after)

after

string

Optional

Identifier for the last chat completion from the previous pagination request.

[](#chat-list-limit)

limit

integer

Optional

Defaults to 20

Number of Chat Completions to retrieve.

[](#chat-list-metadata)

metadata

map

Optional

A list of metadata keys to filter the Chat Completions by. Example:

`metadata[key1]=value1&metadata[key2]=value2`

[](#chat-list-model)

model

string

Optional

The model used to generate the Chat Completions.

[](#chat-list-order)

order

string

Optional

Defaults to asc

Sort order for Chat Completions by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.

#### Returns

A list of [Chat Completions](/docs/api-reference/chat/list-object) matching the specified filters.

Example request

curl
    curl https://api.openai.com/v1/chat/completions \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"
    from openai import OpenAI
    client = OpenAI()
    
    completions = client.chat.completions.list()
    print(completions)

Response
    {
      "object": "list",
      "data": [
        {
          "object": "chat.completion",
          "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
          "model": "gpt-4.1-2025-04-14",
          "created": 1738960610,
          "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
          "tool_choice": null,
          "usage": {
            "total_tokens": 31,
            "completion_tokens": 18,
            "prompt_tokens": 13
          },
          "seed": 4944116822809979520,
          "top_p": 1.0,
          "temperature": 1.0,
          "presence_penalty": 0.0,
          "frequency_penalty": 0.0,
          "system_fingerprint": "fp_50cad350e4",
          "input_user": null,
          "service_tier": "default",
          "tools": null,
          "metadata": {},
          "choices": [
            {
              "index": 0,
              "message": {
                "content": "Mind of circuits hum,  \nLearning patterns in silenceâ  \nFuture's quiet spark.",
                "role": "assistant",
                "tool_calls": null,
                "function_call": null
              },
              "finish_reason": "stop",
              "logprobs": null
            }
          ],
          "response_format": null
        }
      ],
      "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "has_more": false
    }

Update chat completion


--------------------------

postÂ https://api.openai.com/v1/chat/completions/{completion\_id}

Modify a stored chat completion. Only Chat Completions that have been created with the `store` parameter set to `true` can be modified. Currently, the only supported modification is to update the `metadata` field.

#### Path parameters

[](#chat-update-completion_id)

completion\_id

string

Required

The ID of the chat completion to update.

#### Request body

[](#chat-update-metadata)

metadata

map

Required

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

#### Returns

The [ChatCompletion](/docs/api-reference/chat/object) object matching the specified ID.

Example request

curl
    curl -X POST https://api.openai.com/v1/chat/completions/chat_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{"metadata": {"foo": "bar"}}'
    from openai import OpenAI
    client = OpenAI()
    
    completions = client.chat.completions.list()
    first_id = completions[0].id
    updated_completion = client.chat.completions.update(completion_id=first_id, request_body={"metadata": {"foo": "bar"}})
    print(updated_completion)

Response
    {
      "object": "chat.completion",
      "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "model": "gpt-4o-2024-08-06",
      "created": 1738960610,
      "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
      "tool_choice": null,
      "usage": {
        "total_tokens": 31,
        "completion_tokens": 18,
        "prompt_tokens": 13
      },
      "seed": 4944116822809979520,
      "top_p": 1.0,
      "temperature": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "system_fingerprint": "fp_50cad350e4",
      "input_user": null,
      "service_tier": "default",
      "tools": null,
      "metadata": {
        "foo": "bar"
      },
      "choices": [
        {
          "index": 0,
          "message": {
            "content": "Mind of circuits hum,  \nLearning patterns in silenceâ  \nFuture's quiet spark.",
            "role": "assistant",
            "tool_calls": null,
            "function_call": null
          },
          "finish_reason": "stop",
          "logprobs": null
        }
      ],
      "response_format": null
    }

Delete chat completion


--------------------------

deleteÂ https://api.openai.com/v1/chat/completions/{completion\_id}

Delete a stored chat completion. Only Chat Completions that have been created with the `store` parameter set to `true` can be deleted.

#### Path parameters

[](#chat-delete-completion_id)

completion\_id

string

Required

The ID of the chat completion to delete.

#### Returns

A deletion confirmation object.

Example request

curl
    curl -X DELETE https://api.openai.com/v1/chat/completions/chat_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"
    from openai import OpenAI
    client = OpenAI()
    
    completions = client.chat.completions.list()
    first_id = completions[0].id
    delete_response = client.chat.completions.delete(completion_id=first_id)
    print(delete_response)

Response
    {
      "object": "chat.completion.deleted",
      "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "deleted": true
    }

The chat completion object


------------------------------

Represents a chat completion response returned by model, based on the provided input.

[](#chat/object-choices)

choices

array

A list of chat completion choices. Can be more than one if `n` is greater than 1.

Show properties

[](#chat/object-created)

created

integer

The Unix timestamp (in seconds) of when the chat completion was created.

[](#chat/object-id)

id

string

A unique identifier for the chat completion.

[](#chat/object-model)

model

string

The model used for the chat completion.

[](#chat/object-object)

object

string

The object type, which is always `chat.completion`.

[](#chat/object-service_tier)

service\_tier

string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

*   If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
*   If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
*   When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

[](#chat/object-system_fingerprint)

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

[](#chat/object-usage)

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The chat completion object
    {
      "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
      "object": "chat.completion",
      "created": 1741570283,
      "model": "gpt-4o-2024-08-06",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.",
            "refusal": null,
            "annotations": []
          },
          "logprobs": null,
          "finish_reason": "stop"
        }
      ],
      "usage": {
        "prompt_tokens": 1117,
        "completion_tokens": 46,
        "total_tokens": 1163,
        "prompt_tokens_details": {
          "cached_tokens": 0,
          "audio_tokens": 0
        },
        "completion_tokens_details": {
          "reasoning_tokens": 0,
          "audio_tokens": 0,
          "accepted_prediction_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "service_tier": "default",
      "system_fingerprint": "fp_fc9f1d7035"
    }

The chat completion list object


-----------------------------------

An object representing a list of Chat Completions.

[](#chat/list-object-data)

data

array

An array of chat completion objects.

Show properties

[](#chat/list-object-first_id)

first\_id

string

The identifier of the first chat completion in the data array.

[](#chat/list-object-has_more)

has\_more

boolean

Indicates whether there are more Chat Completions available.

[](#chat/list-object-last_id)

last\_id

string

The identifier of the last chat completion in the data array.

[](#chat/list-object-object)

object

string

The type of this object. It is always set to "list".

OBJECT The chat completion list object
    {
      "object": "list",
      "data": [
        {
          "object": "chat.completion",
          "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
          "model": "gpt-4o-2024-08-06",
          "created": 1738960610,
          "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
          "tool_choice": null,
          "usage": {
            "total_tokens": 31,
            "completion_tokens": 18,
            "prompt_tokens": 13
          },
          "seed": 4944116822809979520,
          "top_p": 1.0,
          "temperature": 1.0,
          "presence_penalty": 0.0,
          "frequency_penalty": 0.0,
          "system_fingerprint": "fp_50cad350e4",
          "input_user": null,
          "service_tier": "default",
          "tools": null,
          "metadata": {},
          "choices": [
            {
              "index": 0,
              "message": {
                "content": "Mind of circuits hum,  \nLearning patterns in silenceâ  \nFuture's quiet spark.",
                "role": "assistant",
                "tool_calls": null,
                "function_call": null
              },
              "finish_reason": "stop",
              "logprobs": null
            }
          ],
          "response_format": null
        }
      ],
      "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "has_more": false
    }

The chat completion message list object


-------------------------------------------

An object representing a list of chat completion messages.

[](#chat/message-list-data)

data

array

An array of chat completion message objects.

Show properties

[](#chat/message-list-first_id)

first\_id

string

The identifier of the first chat message in the data array.

[](#chat/message-list-has_more)

has\_more

boolean

Indicates whether there are more chat messages available.

[](#chat/message-list-last_id)

last\_id

string

The identifier of the last chat message in the data array.

[](#chat/message-list-object)

object

string

The type of this object. It is always set to "list".

OBJECT The chat completion message list object
    {
      "object": "list",
      "data": [
        {
          "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
          "role": "user",
          "content": "write a haiku about ai",
          "name": null,
          "content_parts": null
        }
      ],
      "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
      "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
      "has_more": false
    }

Streaming


-------------

Stream Chat Completions in real time. Receive chunks of completions returned from the model using server-sent events. [Learn more](/docs/guides/streaming-responses?api-mode=chat).

The chat completion chunk object


------------------------------------

Represents a streamed chunk of a chat completion response returned by the model, based on the provided input. [Learn more](/docs/guides/streaming-responses).

[](#chat-streaming/streaming-choices)

choices

array

A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the last chunk if you set `stream_options: {"include_usage": true}`.

Show properties

[](#chat-streaming/streaming-created)

created

integer

The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.

[](#chat-streaming/streaming-id)

id

string

A unique identifier for the chat completion. Each chunk has the same ID.

[](#chat-streaming/streaming-model)

model

string

The model to generate the completion.

[](#chat-streaming/streaming-object)

object

string

The object type, which is always `chat.completion.chunk`.

[](#chat-streaming/streaming-service_tier)

service\_tier

string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

*   If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
*   If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
*   If set to 'flex', the request will be processed with the Flex Processing service tier. [Learn more](/docs/guides/flex-processing).
*   When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

[](#chat-streaming/streaming-system_fingerprint)

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

[](#chat-streaming/streaming-usage)

usage

object or null

Usage statistics for the completion request.

Show properties

OBJECT The chat completion chunk object
    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}
    
    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}
    
    ....
    
    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}

Realtime

Beta


------------------

Communicate with a GPT-4o class model in real time using WebRTC or WebSockets. Supports text and audio inputs and ouputs, along with audio transcriptions. [Learn more about the Realtime API](/docs/guides/realtime).

Session tokens


------------------

REST API endpoint to generate ephemeral session tokens for use in client-side applications.

Create session


------------------

postÂ https://api.openai.com/v1/realtime/sessions

Create an ephemeral API token for use in client-side applications with the Realtime API. Can be configured with the same session parameters as the `session.update` client event.

It responds with a session object, plus a `client_secret` key which contains a usable ephemeral API token that can be used to authenticate browser clients for the Realtime API.

#### Request body

[](#realtime-sessions-create-input_audio_format)

input\_audio\_format

string

Optional

Defaults to pcm16

The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel (mono), and little-endian byte order.

[](#realtime-sessions-create-input_audio_noise_reduction)

input\_audio\_noise\_reduction

object

Optional

Defaults to null

Configuration for input audio noise reduction. This can be set to `null` to turn off. Noise reduction filters audio added to the input audio buffer before it is sent to VAD and the model. Filtering the audio can improve VAD and turn detection accuracy (reducing false positives) and model performance by improving perception of the input audio.

Show properties

[](#realtime-sessions-create-input_audio_transcription)

input\_audio\_transcription

object

Optional

Configuration for input audio transcription, defaults to off and can be set to `null` to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs asynchronously through [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription) and should be treated as guidance of input audio content rather than precisely what the model heard. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.

Show properties

[](#realtime-sessions-create-instructions)

instructions

string

Optional

The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. "be extremely succinct", "act friendly", "here are examples of good responses") and on audio behavior (e.g. "talk quickly", "inject emotion into your voice", "laugh frequently"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.

Note that the server sets default instructions which will be used if this field is not set and are visible in the `session.created` event at the start of the session.

[](#realtime-sessions-create-max_response_output_tokens)

max\_response\_output\_tokens

integer or "inf"

Optional

Maximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or `inf` for the maximum available tokens for a given model. Defaults to `inf`.

[](#realtime-sessions-create-modalities)

modalities

Optional

The set of modalities the model can respond with. To disable audio, set this to \["text"\].

[](#realtime-sessions-create-model)

model

string

Optional

The Realtime model used for this session.

[](#realtime-sessions-create-output_audio_format)

output\_audio\_format

string

Optional

Defaults to pcm16

The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For `pcm16`, output audio is sampled at a rate of 24kHz.

[](#realtime-sessions-create-temperature)

temperature

number

Optional

Defaults to 0.8

Sampling temperature for the model, limited to \[0.6, 1.2\]. For audio models a temperature of 0.8 is highly recommended for best performance.

[](#realtime-sessions-create-tool_choice)

tool\_choice

string

Optional

Defaults to auto

How the model chooses tools. Options are `auto`, `none`, `required`, or specify a function.

[](#realtime-sessions-create-tools)

tools

array

Optional

Tools (functions) available to the model.

Show properties

[](#realtime-sessions-create-turn_detection)

turn\_detection

object

Optional

Configuration for turn detection, ether Server VAD or Semantic VAD. This can be set to `null` to turn off, in which case the client must manually trigger model response. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech. Semantic VAD is more advanced and uses a turn detection model (in conjuction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with "uhhm", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency.

Show properties

[](#realtime-sessions-create-voice)

voice

string

Optional

The voice the model uses to respond. Voice cannot be changed during the session once the model has responded with audio at least once. Current voice options are `alloy`, `ash`, `ballad`, `coral`, `echo`, `fable`, `onyx`, `nova`, `sage`, `shimmer`, and `verse`.

#### Returns

The created Realtime session object, plus an ephemeral key

Example request

curl
    curl -X POST https://api.openai.com/v1/realtime/sessions \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "gpt-4o-realtime-preview",
        "modalities": ["audio", "text"],
        "instructions": "You are a friendly assistant."
      }'

Response
    {
      "id": "sess_001",
      "object": "realtime.session",
      "model": "gpt-4o-realtime-preview",
      "modalities": ["audio", "text"],
      "instructions": "You are a friendly assistant.",
      "voice": "alloy",
      "input_audio_format": "pcm16",
      "output_audio_format": "pcm16",
      "input_audio_transcription": {
          "model": "whisper-1"
      },
      "turn_detection": null,
      "tools": [],
      "tool_choice": "none",
      "temperature": 0.7,
      "max_response_output_tokens": 200,
      "client_secret": {
        "value": "ek_abc123", 
        "expires_at": 1234567890
      }
    }

Create transcription session


--------------------------------

postÂ https://api.openai.com/v1/realtime/transcription\_sessions

Create an ephemeral API token for use in client-side applications with the Realtime API specifically for realtime transcriptions. Can be configured with the same session parameters as the `transcription_session.update` client event.

It responds with a session object, plus a `client_secret` key which contains a usable ephemeral API token that can be used to authenticate browser clients for the Realtime API.

#### Request body

[](#realtime-sessions-create-transcription-include)

include

array

Optional

The set of items to include in the transcription. Current available items are:

null.

[](#realtime-sessions-create-transcription-input_audio_format)

input\_audio\_format

string

Optional

Defaults to pcm16

The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel (mono), and little-endian byte order.

[](#realtime-sessions-create-transcription-input_audio_noise_reduction)

input\_audio\_noise\_reduction

object

Optional

Defaults to null

Configuration for input audio noise reduction. This can be set to `null` to turn off. Noise reduction filters audio added to the input audio buffer before it is sent to VAD and the model. Filtering the audio can improve VAD and turn detection accuracy (reducing false positives) and model performance by improving perception of the input audio.

Show properties

[](#realtime-sessions-create-transcription-input_audio_transcription)

input\_audio\_transcription

object

Optional

Configuration for input audio transcription. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.

Show properties

[](#realtime-sessions-create-transcription-modalities)

modalities

Optional

The set of modalities the model can respond with. To disable audio, set this to \["text"\].

[](#realtime-sessions-create-transcription-turn_detection)

turn\_detection

object

Optional

Configuration for turn detection, ether Server VAD or Semantic VAD. This can be set to `null` to turn off, in which case the client must manually trigger model response. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech. Semantic VAD is more advanced and uses a turn detection model (in conjuction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with "uhhm", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency.

Show properties

#### Returns

The created [Realtime transcription session object](/docs/api-reference/realtime-sessions/transcription_session_object), plus an ephemeral key

Example request

curl
    curl -X POST https://api.openai.com/v1/realtime/transcription_sessions \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{}'

Response
    {
      "id": "sess_BBwZc7cFV3XizEyKGDCGL",
      "object": "realtime.transcription_session",
      "modalities": ["audio", "text"],
      "turn_detection": {
        "type": "server_vad",
        "threshold": 0.5,
        "prefix_padding_ms": 300,
        "silence_duration_ms": 200
      },
      "input_audio_format": "pcm16",
      "input_audio_transcription": {
        "model": "gpt-4o-transcribe",
        "language": null,
        "prompt": ""
      },
      "client_secret": null
    }

The session object


----------------------

A new Realtime session configuration, with an ephermeral key. Default TTL for keys is one minute.

[](#realtime-sessions/session_object-client_secret)

client\_secret

object

Ephemeral key returned by the API.

Show properties

[](#realtime-sessions/session_object-input_audio_format)

input\_audio\_format

string

The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.

[](#realtime-sessions/session_object-input_audio_transcription)

input\_audio\_transcription

object

Configuration for input audio transcription, defaults to off and can be set to `null` to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs asynchronously through Whisper and should be treated as rough guidance rather than the representation understood by the model.

Show properties

[](#realtime-sessions/session_object-instructions)

instructions

string

The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. "be extremely succinct", "act friendly", "here are examples of good responses") and on audio behavior (e.g. "talk quickly", "inject emotion into your voice", "laugh frequently"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.

Note that the server sets default instructions which will be used if this field is not set and are visible in the `session.created` event at the start of the session.

[](#realtime-sessions/session_object-max_response_output_tokens)

max\_response\_output\_tokens

integer or "inf"

Maximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or `inf` for the maximum available tokens for a given model. Defaults to `inf`.

[](#realtime-sessions/session_object-modalities)

modalities

The set of modalities the model can respond with. To disable audio, set this to \["text"\].

[](#realtime-sessions/session_object-output_audio_format)

output\_audio\_format

string

The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.

[](#realtime-sessions/session_object-temperature)

temperature

number

Sampling temperature for the model, limited to \[0.6, 1.2\]. Defaults to 0.8.

[](#realtime-sessions/session_object-tool_choice)

tool\_choice

string

How the model chooses tools. Options are `auto`, `none`, `required`, or specify a function.

[](#realtime-sessions/session_object-tools)

tools

array

Tools (functions) available to the model.

Show properties

[](#realtime-sessions/session_object-turn_detection)

turn\_detection

object

Configuration for turn detection. Can be set to `null` to turn off. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.

Show properties

[](#realtime-sessions/session_object-voice)

voice

string

The voice the model uses to respond. Voice cannot be changed during the session once the model has responded with audio at least once. Current voice options are `alloy`, `ash`, `ballad`, `coral`, `echo` `sage`, `shimmer` and `verse`.

OBJECT The session object
    {
      "id": "sess_001",
      "object": "realtime.session",
      "model": "gpt-4o-realtime-preview",
      "modalities": ["audio", "text"],
      "instructions": "You are a friendly assistant.",
      "voice": "alloy",
      "input_audio_format": "pcm16",
      "output_audio_format": "pcm16",
      "input_audio_transcription": {
          "model": "whisper-1"
      },
      "turn_detection": null,
      "tools": [],
      "tool_choice": "none",
      "temperature": 0.7,
      "max_response_output_tokens": 200,
      "client_secret": {
        "value": "ek_abc123", 
        "expires_at": 1234567890
      }
    }

The transcription session object


------------------------------------

A new Realtime transcription session configuration.

When a session is created on the server via REST API, the session object also contains an ephemeral key. Default TTL for keys is one minute. This property is not present when a session is updated via the WebSocket API.

[](#realtime-sessions/transcription_session_object-client_secret)

client\_secret

object

Ephemeral key returned by the API. Only present when the session is created on the server via REST API.

Show properties

[](#realtime-sessions/transcription_session_object-input_audio_format)

input\_audio\_format

string

The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.

[](#realtime-sessions/transcription_session_object-input_audio_transcription)

input\_audio\_transcription

object

Configuration of the transcription model.

Show properties

[](#realtime-sessions/transcription_session_object-modalities)

modalities

The set of modalities the model can respond with. To disable audio, set this to \["text"\].

[](#realtime-sessions/transcription_session_object-turn_detection)

turn\_detection

object

Configuration for turn detection. Can be set to `null` to turn off. Server VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.

Show properties

OBJECT The transcription session object
    {
      "id": "sess_BBwZc7cFV3XizEyKGDCGL",
      "object": "realtime.transcription_session",
      "expires_at": 1742188264,
      "modalities": ["audio", "text"],
      "turn_detection": {
        "type": "server_vad",
        "threshold": 0.5,
        "prefix_padding_ms": 300,
        "silence_duration_ms": 200
      },
      "input_audio_format": "pcm16",
      "input_audio_transcription": {
        "model": "gpt-4o-transcribe",
        "language": null,
        "prompt": ""
      },
      "client_secret": null
    }

Client events


-----------------

These are events that the OpenAI Realtime WebSocket server will accept from the client.

session.update


------------------

Send this event to update the sessionâs default configuration. The client may send this event at any time to update any field, except for `voice`. However, note that once a session has been initialized with a particular `model`, it canât be changed to another model using `session.update`.

When the server receives a `session.update`, it will respond with a `session.updated` event showing the full, effective configuration. Only the fields that are present are updated. To clear a field like `instructions`, pass an empty string.

[](#realtime-client-events/session/update-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/session/update-session)

session

object

Realtime session object configuration.

Show properties

[](#realtime-client-events/session/update-type)

type

string

The event type, must be `session.update`.

OBJECT session.update
    {
        "event_id": "event_123",
        "type": "session.update",
        "session": {
            "modalities": ["text", "audio"],
            "instructions": "You are a helpful assistant.",
            "voice": "sage",
            "input_audio_format": "pcm16",
            "output_audio_format": "pcm16",
            "input_audio_transcription": {
                "model": "whisper-1"
            },
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500,
                "create_response": true
            },
            "tools": [
                {
                    "type": "function",
                    "name": "get_weather",
                    "description": "Get the current weather...",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "location": { "type": "string" }
                        },
                        "required": ["location"]
                    }
                }
            ],
            "tool_choice": "auto",
            "temperature": 0.8,
            "max_response_output_tokens": "inf"
        }
    }

input\_audio\_buffer.append


-------------------------------

Send this event to append audio bytes to the input audio buffer. The audio buffer is temporary storage you can write to and later commit. In Server VAD mode, the audio buffer is used to detect speech and the server will decide when to commit. When Server VAD is disabled, you must commit the audio buffer manually.

The client may choose how much audio to place in each event up to a maximum of 15 MiB, for example streaming smaller chunks from the client may allow the VAD to be more responsive. Unlike made other client events, the server will not send a confirmation response to this event.

[](#realtime-client-events/input_audio_buffer/append-audio)

audio

string

Base64-encoded audio bytes. This must be in the format specified by the `input_audio_format` field in the session configuration.

[](#realtime-client-events/input_audio_buffer/append-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/input_audio_buffer/append-type)

type

string

The event type, must be `input_audio_buffer.append`.

OBJECT input\_audio\_buffer.append
    {
        "event_id": "event_456",
        "type": "input_audio_buffer.append",
        "audio": "Base64EncodedAudioData"
    }

input\_audio\_buffer.commit


-------------------------------

Send this event to commit the user input audio buffer, which will create a new user message item in the conversation. This event will produce an error if the input audio buffer is empty. When in Server VAD mode, the client does not need to send this event, the server will commit the audio buffer automatically.

Committing the input audio buffer will trigger input audio transcription (if enabled in session configuration), but it will not create a response from the model. The server will respond with an `input_audio_buffer.committed` event.

[](#realtime-client-events/input_audio_buffer/commit-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/input_audio_buffer/commit-type)

type

string

The event type, must be `input_audio_buffer.commit`.

OBJECT input\_audio\_buffer.commit
    {
        "event_id": "event_789",
        "type": "input_audio_buffer.commit"
    }

input\_audio\_buffer.clear


------------------------------

Send this event to clear the audio bytes in the buffer. The server will respond with an `input_audio_buffer.cleared` event.

[](#realtime-client-events/input_audio_buffer/clear-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/input_audio_buffer/clear-type)

type

string

The event type, must be `input_audio_buffer.clear`.

OBJECT input\_audio\_buffer.clear
    {
        "event_id": "event_012",
        "type": "input_audio_buffer.clear"
    }

conversation.item.create


----------------------------

Add a new Item to the Conversation's context, including messages, function calls, and function call responses. This event can be used both to populate a "history" of the conversation and to add new items mid-stream, but has the current limitation that it cannot populate assistant audio messages.

If successful, the server will respond with a `conversation.item.created` event, otherwise an `error` event will be sent.

[](#realtime-client-events/conversation/item/create-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/conversation/item/create-item)

item

object

The item to add to the conversation.

Show properties

[](#realtime-client-events/conversation/item/create-previous_item_id)

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted. If not set, the new item will be appended to the end of the conversation. If set to `root`, the new item will be added to the beginning of the conversation. If set to an existing ID, it allows an item to be inserted mid-conversation. If the ID cannot be found, an error will be returned and the item will not be added.

[](#realtime-client-events/conversation/item/create-type)

type

string

The event type, must be `conversation.item.create`.

OBJECT conversation.item.create
    {
        "event_id": "event_345",
        "type": "conversation.item.create",
        "previous_item_id": null,
        "item": {
            "id": "msg_001",
            "type": "message",
            "role": "user",
            "content": [
                {
                    "type": "input_text",
                    "text": "Hello, how are you?"
                }
            ]
        }
    }

conversation.item.retrieve


------------------------------

Send this event when you want to retrieve the server's representation of a specific item in the conversation history. This is useful, for example, to inspect user audio after noise cancellation and VAD. The server will respond with a `conversation.item.retrieved` event, unless the item does not exist in the conversation history, in which case the server will respond with an error.

[](#realtime-client-events/conversation/item/retrieve-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/conversation/item/retrieve-item_id)

item\_id

string

The ID of the item to retrieve.

[](#realtime-client-events/conversation/item/retrieve-type)

type

string

The event type, must be `conversation.item.retrieve`.

OBJECT conversation.item.retrieve
    {
        "event_id": "event_901",
        "type": "conversation.item.retrieve",
        "item_id": "msg_003"
    }

conversation.item.truncate


------------------------------

Send this event to truncate a previous assistant messageâs audio. The server will produce audio faster than realtime, so this event is useful when the user interrupts to truncate audio that has already been sent to the client but not yet played. This will synchronize the server's understanding of the audio with the client's playback.

Truncating audio will delete the server-side text transcript to ensure there is not text in the context that hasn't been heard by the user.

If successful, the server will respond with a `conversation.item.truncated` event.

[](#realtime-client-events/conversation/item/truncate-audio_end_ms)

audio\_end\_ms

integer

Inclusive duration up to which audio is truncated, in milliseconds. If the audio\_end\_ms is greater than the actual audio duration, the server will respond with an error.

[](#realtime-client-events/conversation/item/truncate-content_index)

content\_index

integer

The index of the content part to truncate. Set this to 0.

[](#realtime-client-events/conversation/item/truncate-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/conversation/item/truncate-item_id)

item\_id

string

The ID of the assistant message item to truncate. Only assistant message items can be truncated.

[](#realtime-client-events/conversation/item/truncate-type)

type

string

The event type, must be `conversation.item.truncate`.

OBJECT conversation.item.truncate
    {
        "event_id": "event_678",
        "type": "conversation.item.truncate",
        "item_id": "msg_002",
        "content_index": 0,
        "audio_end_ms": 1500
    }

conversation.item.delete


----------------------------

Send this event when you want to remove any item from the conversation history. The server will respond with a `conversation.item.deleted` event, unless the item does not exist in the conversation history, in which case the server will respond with an error.

[](#realtime-client-events/conversation/item/delete-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/conversation/item/delete-item_id)

item\_id

string

The ID of the item to delete.

[](#realtime-client-events/conversation/item/delete-type)

type

string

The event type, must be `conversation.item.delete`.

OBJECT conversation.item.delete
    {
        "event_id": "event_901",
        "type": "conversation.item.delete",
        "item_id": "msg_003"
    }

response.create


-------------------

This event instructs the server to create a Response, which means triggering model inference. When in Server VAD mode, the server will create Responses automatically.

A Response will include at least one Item, and may have two, in which case the second will be a function call. These Items will be appended to the conversation history.

The server will respond with a `response.created` event, events for Items and content created, and finally a `response.done` event to indicate the Response is complete.

The `response.create` event includes inference configuration like `instructions`, and `temperature`. These fields will override the Session's configuration for this Response only.

[](#realtime-client-events/response/create-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/response/create-response)

response

object

Create a new Realtime response with these parameters

Show properties

[](#realtime-client-events/response/create-type)

type

string

The event type, must be `response.create`.

OBJECT response.create
    {
        "event_id": "event_234",
        "type": "response.create",
        "response": {
            "modalities": ["text", "audio"],
            "instructions": "Please assist the user.",
            "voice": "sage",
            "output_audio_format": "pcm16",
            "tools": [
                {
                    "type": "function",
                    "name": "calculate_sum",
                    "description": "Calculates the sum of two numbers.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "a": { "type": "number" },
                            "b": { "type": "number" }
                        },
                        "required": ["a", "b"]
                    }
                }
            ],
            "tool_choice": "auto",
            "temperature": 0.8,
            "max_output_tokens": 1024
        }
    }

response.cancel


-------------------

Send this event to cancel an in-progress response. The server will respond with a `response.cancelled` event or an error if there is no response to cancel.

[](#realtime-client-events/response/cancel-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/response/cancel-response_id)

response\_id

string

A specific response ID to cancel - if not provided, will cancel an in-progress response in the default conversation.

[](#realtime-client-events/response/cancel-type)

type

string

The event type, must be `response.cancel`.

OBJECT response.cancel
    {
        "event_id": "event_567",
        "type": "response.cancel"
    }

transcription\_session.update


---------------------------------

Send this event to update a transcription session.

[](#realtime-client-events/transcription_session/update-event_id)

event\_id

string

Optional client-generated ID used to identify this event.

[](#realtime-client-events/transcription_session/update-session)

session

object

Realtime transcription session object configuration.

Show properties

[](#realtime-client-events/transcription_session/update-type)

type

string

The event type, must be `transcription_session.update`.

OBJECT transcription\_session.update
    {
      "type": "transcription_session.update",
      "session": {
        "input_audio_format": "pcm16",
        "input_audio_transcription": {
          "model": "gpt-4o-transcribe",
          "prompt": "",
          "language": ""
        },
        "turn_detection": {
          "type": "server_vad",
          "threshold": 0.5,
          "prefix_padding_ms": 300,
          "silence_duration_ms": 500,
          "create_response": true,
        },
        "input_audio_noise_reduction": {
          "type": "near_field"
        },
        "include": [
          "item.input_audio_transcription.logprobs",
        ]
      }
    }

output\_audio\_buffer.clear


-------------------------------

**WebRTC Only:** Emit to cut off the current audio response. This will trigger the server to stop generating audio and emit a `output_audio_buffer.cleared` event. This event should be preceded by a `response.cancel` client event to stop the generation of the current response. [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).

[](#realtime-client-events/output_audio_buffer/clear-event_id)

event\_id

string

The unique ID of the client event used for error handling.

[](#realtime-client-events/output_audio_buffer/clear-type)

type

string

The event type, must be `output_audio_buffer.clear`.

OBJECT output\_audio\_buffer.clear
    {
        "event_id": "optional_client_event_id",
        "type": "output_audio_buffer.clear"
    }

Server events


-----------------

These are events emitted from the OpenAI Realtime WebSocket server to the client.

error


---------

Returned when an error occurs, which could be a client problem or a server problem. Most errors are recoverable and the session will stay open, we recommend to implementors to monitor and log error messages by default.

[](#realtime-server-events/error-error)

error

object

Details of the error.

Show properties

[](#realtime-server-events/error-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/error-type)

type

string

The event type, must be `error`.

OBJECT error
    {
        "event_id": "event_890",
        "type": "error",
        "error": {
            "type": "invalid_request_error",
            "code": "invalid_event",
            "message": "The 'type' field is missing.",
            "param": null,
            "event_id": "event_567"
        }
    }

session.created


-------------------

Returned when a Session is created. Emitted automatically when a new connection is established as the first server event. This event will contain the default Session configuration.

[](#realtime-server-events/session/created-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/session/created-session)

session

object

Realtime session object configuration.

Show properties

[](#realtime-server-events/session/created-type)

type

string

The event type, must be `session.created`.

OBJECT session.created
    {
        "event_id": "event_1234",
        "type": "session.created",
        "session": {
            "id": "sess_001",
            "object": "realtime.session",
            "model": "gpt-4o-realtime-preview",
            "modalities": ["text", "audio"],
            "instructions": "...model instructions here...",
            "voice": "sage",
            "input_audio_format": "pcm16",
            "output_audio_format": "pcm16",
            "input_audio_transcription": null,
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 200
            },
            "tools": [],
            "tool_choice": "auto",
            "temperature": 0.8,
            "max_response_output_tokens": "inf"
        }
    }

session.updated


-------------------

Returned when a session is updated with a `session.update` event, unless there is an error.

[](#realtime-server-events/session/updated-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/session/updated-session)

session

object

Realtime session object configuration.

Show properties

[](#realtime-server-events/session/updated-type)

type

string

The event type, must be `session.updated`.

OBJECT session.updated
    {
        "event_id": "event_5678",
        "type": "session.updated",
        "session": {
            "id": "sess_001",
            "object": "realtime.session",
            "model": "gpt-4o-realtime-preview",
            "modalities": ["text"],
            "instructions": "New instructions",
            "voice": "sage",
            "input_audio_format": "pcm16",
            "output_audio_format": "pcm16",
            "input_audio_transcription": {
                "model": "whisper-1"
            },
            "turn_detection": null,
            "tools": [],
            "tool_choice": "none",
            "temperature": 0.7,
            "max_response_output_tokens": 200
        }
    }

conversation.created


------------------------

Returned when a conversation is created. Emitted right after session creation.

[](#realtime-server-events/conversation/created-conversation)

conversation

object

The conversation resource.

Show properties

[](#realtime-server-events/conversation/created-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/created-type)

type

string

The event type, must be `conversation.created`.

OBJECT conversation.created
    {
        "event_id": "event_9101",
        "type": "conversation.created",
        "conversation": {
            "id": "conv_001",
            "object": "realtime.conversation"
        }
    }

conversation.item.created


-----------------------------

Returned when a conversation item is created. There are several scenarios that produce this event:

*   The server is generating a Response, which if successful will produce either one or two Items, which will be of type `message` (role `assistant`) or type `function_call`.
*   The input audio buffer has been committed, either by the client or the server (in `server_vad` mode). The server will take the content of the input audio buffer and add it to a new user message Item.
*   The client has sent a `conversation.item.create` event to add a new Item to the Conversation.

[](#realtime-server-events/conversation/item/created-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/created-item)

item

object

The item to add to the conversation.

Show properties

[](#realtime-server-events/conversation/item/created-previous_item_id)

previous\_item\_id

string

The ID of the preceding item in the Conversation context, allows the client to understand the order of the conversation.

[](#realtime-server-events/conversation/item/created-type)

type

string

The event type, must be `conversation.item.created`.

OBJECT conversation.item.created
    {
        "event_id": "event_1920",
        "type": "conversation.item.created",
        "previous_item_id": "msg_002",
        "item": {
            "id": "msg_003",
            "object": "realtime.item",
            "type": "message",
            "status": "completed",
            "role": "user",
            "content": []
        }
    }

conversation.item.retrieved


-------------------------------

Returned when a conversation item is retrieved with `conversation.item.retrieve`.

[](#realtime-server-events/conversation/item/retrieved-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/retrieved-item)

item

object

The item to add to the conversation.

Show properties

[](#realtime-server-events/conversation/item/retrieved-type)

type

string

The event type, must be `conversation.item.retrieved`.

OBJECT conversation.item.retrieved
    {
        "event_id": "event_1920",
        "type": "conversation.item.created",
        "previous_item_id": "msg_002",
        "item": {
            "id": "msg_003",
            "object": "realtime.item",
            "type": "message",
            "status": "completed",
            "role": "user",
            "content": [
                {
                    "type": "input_audio",
                    "transcript": "hello how are you",
                    "audio": "base64encodedaudio=="
                }
            ]
        }
    }

conversation.item.input\_audio\_transcription.completed


-----------------------------------------------------------

This event is the output of audio transcription for user audio written to the user audio buffer. Transcription begins when the input audio buffer is committed by the client or server (in `server_vad` mode). Transcription runs asynchronously with Response creation, so this event may come before or after the Response events.

Realtime API models accept audio natively, and thus input transcription is a separate process run on a separate ASR (Automatic Speech Recognition) model, currently always `whisper-1`. Thus the transcript may diverge somewhat from the model's interpretation, and should be treated as a rough guide.

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-content_index)

content\_index

integer

The index of the content part containing the audio.

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-item_id)

item\_id

string

The ID of the user message item containing the audio.

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-logprobs)

logprobs

array or null

The log probabilities of the transcription.

Show properties

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-transcript)

transcript

string

The transcribed text.

[](#realtime-server-events/conversation/item/input_audio_transcription/completed-type)

type

string

The event type, must be `conversation.item.input_audio_transcription.completed`.

OBJECT conversation.item.input\_audio\_transcription.completed
    {
        "event_id": "event_2122",
        "type": "conversation.item.input_audio_transcription.completed",
        "item_id": "msg_003",
        "content_index": 0,
        "transcript": "Hello, how are you?"
    }

conversation.item.input\_audio\_transcription.delta


-------------------------------------------------------

Returned when the text value of an input audio transcription content part is updated.

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-delta)

delta

string

The text delta.

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-logprobs)

logprobs

array or null

The log probabilities of the transcription.

Show properties

[](#realtime-server-events/conversation/item/input_audio_transcription/delta-type)

type

string

The event type, must be `conversation.item.input_audio_transcription.delta`.

OBJECT conversation.item.input\_audio\_transcription.delta
    {
      "type": "conversation.item.input_audio_transcription.delta",
      "event_id": "event_001",
      "item_id": "item_001",
      "content_index": 0,
      "delta": "Hello"
    }

conversation.item.input\_audio\_transcription.failed


--------------------------------------------------------

Returned when input audio transcription is configured, and a transcription request for a user message failed. These events are separate from other `error` events so that the client can identify the related Item.

[](#realtime-server-events/conversation/item/input_audio_transcription/failed-content_index)

content\_index

integer

The index of the content part containing the audio.

[](#realtime-server-events/conversation/item/input_audio_transcription/failed-error)

error

object

Details of the transcription error.

Show properties

[](#realtime-server-events/conversation/item/input_audio_transcription/failed-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/input_audio_transcription/failed-item_id)

item\_id

string

The ID of the user message item.

[](#realtime-server-events/conversation/item/input_audio_transcription/failed-type)

type

string

The event type, must be `conversation.item.input_audio_transcription.failed`.

OBJECT conversation.item.input\_audio\_transcription.failed
    {
        "event_id": "event_2324",
        "type": "conversation.item.input_audio_transcription.failed",
        "item_id": "msg_003",
        "content_index": 0,
        "error": {
            "type": "transcription_error",
            "code": "audio_unintelligible",
            "message": "The audio could not be transcribed.",
            "param": null
        }
    }

conversation.item.truncated


-------------------------------

Returned when an earlier assistant audio message item is truncated by the client with a `conversation.item.truncate` event. This event is used to synchronize the server's understanding of the audio with the client's playback.

This action will truncate the audio and remove the server-side text transcript to ensure there is no text in the context that hasn't been heard by the user.

[](#realtime-server-events/conversation/item/truncated-audio_end_ms)

audio\_end\_ms

integer

The duration up to which the audio was truncated, in milliseconds.

[](#realtime-server-events/conversation/item/truncated-content_index)

content\_index

integer

The index of the content part that was truncated.

[](#realtime-server-events/conversation/item/truncated-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/truncated-item_id)

item\_id

string

The ID of the assistant message item that was truncated.

[](#realtime-server-events/conversation/item/truncated-type)

type

string

The event type, must be `conversation.item.truncated`.

OBJECT conversation.item.truncated
    {
        "event_id": "event_2526",
        "type": "conversation.item.truncated",
        "item_id": "msg_004",
        "content_index": 0,
        "audio_end_ms": 1500
    }

conversation.item.deleted


-----------------------------

Returned when an item in the conversation is deleted by the client with a `conversation.item.delete` event. This event is used to synchronize the server's understanding of the conversation history with the client's view.

[](#realtime-server-events/conversation/item/deleted-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/conversation/item/deleted-item_id)

item\_id

string

The ID of the item that was deleted.

[](#realtime-server-events/conversation/item/deleted-type)

type

string

The event type, must be `conversation.item.deleted`.

OBJECT conversation.item.deleted
    {
        "event_id": "event_2728",
        "type": "conversation.item.deleted",
        "item_id": "msg_005"
    }

input\_audio\_buffer.committed


----------------------------------

Returned when an input audio buffer is committed, either by the client or automatically in server VAD mode. The `item_id` property is the ID of the user message item that will be created, thus a `conversation.item.created` event will also be sent to the client.

[](#realtime-server-events/input_audio_buffer/committed-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/input_audio_buffer/committed-item_id)

item\_id

string

The ID of the user message item that will be created.

[](#realtime-server-events/input_audio_buffer/committed-previous_item_id)

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.

[](#realtime-server-events/input_audio_buffer/committed-type)

type

string

The event type, must be `input_audio_buffer.committed`.

OBJECT input\_audio\_buffer.committed
    {
        "event_id": "event_1121",
        "type": "input_audio_buffer.committed",
        "previous_item_id": "msg_001",
        "item_id": "msg_002"
    }

input\_audio\_buffer.cleared


--------------------------------

Returned when the input audio buffer is cleared by the client with a `input_audio_buffer.clear` event.

[](#realtime-server-events/input_audio_buffer/cleared-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/input_audio_buffer/cleared-type)

type

string

The event type, must be `input_audio_buffer.cleared`.

OBJECT input\_audio\_buffer.cleared
    {
        "event_id": "event_1314",
        "type": "input_audio_buffer.cleared"
    }

input\_audio\_buffer.speech\_started


----------------------------------------

Sent by the server when in `server_vad` mode to indicate that speech has been detected in the audio buffer. This can happen any time audio is added to the buffer (unless speech is already detected). The client may want to use this event to interrupt audio playback or provide visual feedback to the user.

The client should expect to receive a `input_audio_buffer.speech_stopped` event when speech stops. The `item_id` property is the ID of the user message item that will be created when speech stops and will also be included in the `input_audio_buffer.speech_stopped` event (unless the client manually commits the audio buffer during VAD activation).

[](#realtime-server-events/input_audio_buffer/speech_started-audio_start_ms)

audio\_start\_ms

integer

Milliseconds from the start of all audio written to the buffer during the session when speech was first detected. This will correspond to the beginning of audio sent to the model, and thus includes the `prefix_padding_ms` configured in the Session.

[](#realtime-server-events/input_audio_buffer/speech_started-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/input_audio_buffer/speech_started-item_id)

item\_id

string

The ID of the user message item that will be created when speech stops.

[](#realtime-server-events/input_audio_buffer/speech_started-type)

type

string

The event type, must be `input_audio_buffer.speech_started`.

OBJECT input\_audio\_buffer.speech\_started
    {
        "event_id": "event_1516",
        "type": "input_audio_buffer.speech_started",
        "audio_start_ms": 1000,
        "item_id": "msg_003"
    }

input\_audio\_buffer.speech\_stopped


----------------------------------------

Returned in `server_vad` mode when the server detects the end of speech in the audio buffer. The server will also send an `conversation.item.created` event with the user message item that is created from the audio buffer.

[](#realtime-server-events/input_audio_buffer/speech_stopped-audio_end_ms)

audio\_end\_ms

integer

Milliseconds since the session started when speech stopped. This will correspond to the end of audio sent to the model, and thus includes the `min_silence_duration_ms` configured in the Session.

[](#realtime-server-events/input_audio_buffer/speech_stopped-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/input_audio_buffer/speech_stopped-item_id)

item\_id

string

The ID of the user message item that will be created.

[](#realtime-server-events/input_audio_buffer/speech_stopped-type)

type

string

The event type, must be `input_audio_buffer.speech_stopped`.

OBJECT input\_audio\_buffer.speech\_stopped
    {
        "event_id": "event_1718",
        "type": "input_audio_buffer.speech_stopped",
        "audio_end_ms": 2000,
        "item_id": "msg_003"
    }

response.created


--------------------

Returned when a new Response is created. The first event of response creation, where the response is in an initial state of `in_progress`.

[](#realtime-server-events/response/created-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/created-response)

response

object

The response resource.

Show properties

[](#realtime-server-events/response/created-type)

type

string

The event type, must be `response.created`.

OBJECT response.created
    {
        "event_id": "event_2930",
        "type": "response.created",
        "response": {
            "id": "resp_001",
            "object": "realtime.response",
            "status": "in_progress",
            "status_details": null,
            "output": [],
            "usage": null
        }
    }

response.done


-----------------

Returned when a Response is done streaming. Always emitted, no matter the final state. The Response object included in the `response.done` event will include all output Items in the Response but will omit the raw audio data.

[](#realtime-server-events/response/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/done-response)

response

object

The response resource.

Show properties

[](#realtime-server-events/response/done-type)

type

string

The event type, must be `response.done`.

OBJECT response.done
    {
        "event_id": "event_3132",
        "type": "response.done",
        "response": {
            "id": "resp_001",
            "object": "realtime.response",
            "status": "completed",
            "status_details": null,
            "output": [
                {
                    "id": "msg_006",
                    "object": "realtime.item",
                    "type": "message",
                    "status": "completed",
                    "role": "assistant",
                    "content": [
                        {
                            "type": "text",
                            "text": "Sure, how can I assist you today?"
                        }
                    ]
                }
            ],
            "usage": {
                "total_tokens":275,
                "input_tokens":127,
                "output_tokens":148,
                "input_token_details": {
                    "cached_tokens":384,
                    "text_tokens":119,
                    "audio_tokens":8,
                    "cached_tokens_details": {
                        "text_tokens": 128,
                        "audio_tokens": 256
                    }
                },
                "output_token_details": {
                  "text_tokens":36,
                  "audio_tokens":112
                }
            }
        }
    }

response.output\_item.added


-------------------------------

Returned when a new Item is created during Response generation.

[](#realtime-server-events/response/output_item/added-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/output_item/added-item)

item

object

The item to add to the conversation.

Show properties

[](#realtime-server-events/response/output_item/added-output_index)

output\_index

integer

The index of the output item in the Response.

[](#realtime-server-events/response/output_item/added-response_id)

response\_id

string

The ID of the Response to which the item belongs.

[](#realtime-server-events/response/output_item/added-type)

type

string

The event type, must be `response.output_item.added`.

OBJECT response.output\_item.added
    {
        "event_id": "event_3334",
        "type": "response.output_item.added",
        "response_id": "resp_001",
        "output_index": 0,
        "item": {
            "id": "msg_007",
            "object": "realtime.item",
            "type": "message",
            "status": "in_progress",
            "role": "assistant",
            "content": []
        }
    }

response.output\_item.done


------------------------------

Returned when an Item is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/output_item/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/output_item/done-item)

item

object

The item to add to the conversation.

Show properties

[](#realtime-server-events/response/output_item/done-output_index)

output\_index

integer

The index of the output item in the Response.

[](#realtime-server-events/response/output_item/done-response_id)

response\_id

string

The ID of the Response to which the item belongs.

[](#realtime-server-events/response/output_item/done-type)

type

string

The event type, must be `response.output_item.done`.

OBJECT response.output\_item.done
    {
        "event_id": "event_3536",
        "type": "response.output_item.done",
        "response_id": "resp_001",
        "output_index": 0,
        "item": {
            "id": "msg_007",
            "object": "realtime.item",
            "type": "message",
            "status": "completed",
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "Sure, I can help with that."
                }
            ]
        }
    }

response.content\_part.added


--------------------------------

Returned when a new content part is added to an assistant message item during response generation.

[](#realtime-server-events/response/content_part/added-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/content_part/added-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/content_part/added-item_id)

item\_id

string

The ID of the item to which the content part was added.

[](#realtime-server-events/response/content_part/added-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/content_part/added-part)

part

object

The content part that was added.

Show properties

[](#realtime-server-events/response/content_part/added-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/content_part/added-type)

type

string

The event type, must be `response.content_part.added`.

OBJECT response.content\_part.added
    {
        "event_id": "event_3738",
        "type": "response.content_part.added",
        "response_id": "resp_001",
        "item_id": "msg_007",
        "output_index": 0,
        "content_index": 0,
        "part": {
            "type": "text",
            "text": ""
        }
    }

response.content\_part.done


-------------------------------

Returned when a content part is done streaming in an assistant message item. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/content_part/done-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/content_part/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/content_part/done-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/content_part/done-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/content_part/done-part)

part

object

The content part that is done.

Show properties

[](#realtime-server-events/response/content_part/done-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/content_part/done-type)

type

string

The event type, must be `response.content_part.done`.

OBJECT response.content\_part.done
    {
        "event_id": "event_3940",
        "type": "response.content_part.done",
        "response_id": "resp_001",
        "item_id": "msg_007",
        "output_index": 0,
        "content_index": 0,
        "part": {
            "type": "text",
            "text": "Sure, I can help with that."
        }
    }

response.text.delta


-----------------------

Returned when the text value of a "text" content part is updated.

[](#realtime-server-events/response/text/delta-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/text/delta-delta)

delta

string

The text delta.

[](#realtime-server-events/response/text/delta-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/text/delta-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/text/delta-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/text/delta-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/text/delta-type)

type

string

The event type, must be `response.text.delta`.

OBJECT response.text.delta
    {
        "event_id": "event_4142",
        "type": "response.text.delta",
        "response_id": "resp_001",
        "item_id": "msg_007",
        "output_index": 0,
        "content_index": 0,
        "delta": "Sure, I can h"
    }

response.text.done


----------------------

Returned when the text value of a "text" content part is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/text/done-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/text/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/text/done-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/text/done-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/text/done-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/text/done-text)

text

string

The final text content.

[](#realtime-server-events/response/text/done-type)

type

string

The event type, must be `response.text.done`.

OBJECT response.text.done
    {
        "event_id": "event_4344",
        "type": "response.text.done",
        "response_id": "resp_001",
        "item_id": "msg_007",
        "output_index": 0,
        "content_index": 0,
        "text": "Sure, I can help with that."
    }

response.audio\_transcript.delta


------------------------------------

Returned when the model-generated transcription of audio output is updated.

[](#realtime-server-events/response/audio_transcript/delta-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/audio_transcript/delta-delta)

delta

string

The transcript delta.

[](#realtime-server-events/response/audio_transcript/delta-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/audio_transcript/delta-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/audio_transcript/delta-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/audio_transcript/delta-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/audio_transcript/delta-type)

type

string

The event type, must be `response.audio_transcript.delta`.

OBJECT response.audio\_transcript.delta
    {
        "event_id": "event_4546",
        "type": "response.audio_transcript.delta",
        "response_id": "resp_001",
        "item_id": "msg_008",
        "output_index": 0,
        "content_index": 0,
        "delta": "Hello, how can I a"
    }

response.audio\_transcript.done


-----------------------------------

Returned when the model-generated transcription of audio output is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/audio_transcript/done-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/audio_transcript/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/audio_transcript/done-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/audio_transcript/done-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/audio_transcript/done-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/audio_transcript/done-transcript)

transcript

string

The final transcript of the audio.

[](#realtime-server-events/response/audio_transcript/done-type)

type

string

The event type, must be `response.audio_transcript.done`.

OBJECT response.audio\_transcript.done
    {
        "event_id": "event_4748",
        "type": "response.audio_transcript.done",
        "response_id": "resp_001",
        "item_id": "msg_008",
        "output_index": 0,
        "content_index": 0,
        "transcript": "Hello, how can I assist you today?"
    }

response.audio.delta


------------------------

Returned when the model-generated audio is updated.

[](#realtime-server-events/response/audio/delta-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/audio/delta-delta)

delta

string

Base64-encoded audio data delta.

[](#realtime-server-events/response/audio/delta-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/audio/delta-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/audio/delta-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/audio/delta-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/audio/delta-type)

type

string

The event type, must be `response.audio.delta`.

OBJECT response.audio.delta
    {
        "event_id": "event_4950",
        "type": "response.audio.delta",
        "response_id": "resp_001",
        "item_id": "msg_008",
        "output_index": 0,
        "content_index": 0,
        "delta": "Base64EncodedAudioDelta"
    }

response.audio.done


-----------------------

Returned when the model-generated audio is done. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/audio/done-content_index)

content\_index

integer

The index of the content part in the item's content array.

[](#realtime-server-events/response/audio/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/audio/done-item_id)

item\_id

string

The ID of the item.

[](#realtime-server-events/response/audio/done-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/audio/done-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/audio/done-type)

type

string

The event type, must be `response.audio.done`.

OBJECT response.audio.done
    {
        "event_id": "event_5152",
        "type": "response.audio.done",
        "response_id": "resp_001",
        "item_id": "msg_008",
        "output_index": 0,
        "content_index": 0
    }

response.function\_call\_arguments.delta


--------------------------------------------

Returned when the model-generated function call arguments are updated.

[](#realtime-server-events/response/function_call_arguments/delta-call_id)

call\_id

string

The ID of the function call.

[](#realtime-server-events/response/function_call_arguments/delta-delta)

delta

string

The arguments delta as a JSON string.

[](#realtime-server-events/response/function_call_arguments/delta-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/function_call_arguments/delta-item_id)

item\_id

string

The ID of the function call item.

[](#realtime-server-events/response/function_call_arguments/delta-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/function_call_arguments/delta-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/function_call_arguments/delta-type)

type

string

The event type, must be `response.function_call_arguments.delta`.

OBJECT response.function\_call\_arguments.delta
    {
        "event_id": "event_5354",
        "type": "response.function_call_arguments.delta",
        "response_id": "resp_002",
        "item_id": "fc_001",
        "output_index": 0,
        "call_id": "call_001",
        "delta": "{\"location\": \"San\""
    }

response.function\_call\_arguments.done


-------------------------------------------

Returned when the model-generated function call arguments are done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.

[](#realtime-server-events/response/function_call_arguments/done-arguments)

arguments

string

The final arguments as a JSON string.

[](#realtime-server-events/response/function_call_arguments/done-call_id)

call\_id

string

The ID of the function call.

[](#realtime-server-events/response/function_call_arguments/done-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/response/function_call_arguments/done-item_id)

item\_id

string

The ID of the function call item.

[](#realtime-server-events/response/function_call_arguments/done-output_index)

output\_index

integer

The index of the output item in the response.

[](#realtime-server-events/response/function_call_arguments/done-response_id)

response\_id

string

The ID of the response.

[](#realtime-server-events/response/function_call_arguments/done-type)

type

string

The event type, must be `response.function_call_arguments.done`.

OBJECT response.function\_call\_arguments.done
    {
        "event_id": "event_5556",
        "type": "response.function_call_arguments.done",
        "response_id": "resp_002",
        "item_id": "fc_001",
        "output_index": 0,
        "call_id": "call_001",
        "arguments": "{\"location\": \"San Francisco\"}"
    }

transcription\_session.updated


----------------------------------

Returned when a transcription session is updated with a `transcription_session.update` event, unless there is an error.

[](#realtime-server-events/transcription_session/updated-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/transcription_session/updated-session)

session

object

A new Realtime transcription session configuration.

When a session is created on the server via REST API, the session object also contains an ephemeral key. Default TTL for keys is one minute. This property is not present when a session is updated via the WebSocket API.

Show properties

[](#realtime-server-events/transcription_session/updated-type)

type

string

The event type, must be `transcription_session.updated`.

OBJECT transcription\_session.updated
    {
      "event_id": "event_5678",
      "type": "transcription_session.updated",
      "session": {
        "id": "sess_001",
        "object": "realtime.transcription_session",
        "input_audio_format": "pcm16",
        "input_audio_transcription": {
          "model": "gpt-4o-transcribe",
          "prompt": "",
          "language": ""
        },
        "turn_detection": {
          "type": "server_vad",
          "threshold": 0.5,
          "prefix_padding_ms": 300,
          "silence_duration_ms": 500,
          "create_response": true,
          // "interrupt_response": false  -- this will NOT be returned
        },
        "input_audio_noise_reduction": {
          "type": "near_field"
        },
        "include": [
          "item.input_audio_transcription.avg_logprob",
        ],
      }
    }

rate\_limits.updated


------------------------

Emitted at the beginning of a Response to indicate the updated rate limits. When a Response is created some tokens will be "reserved" for the output tokens, the rate limits shown here reflect that reservation, which is then adjusted accordingly once the Response is completed.

[](#realtime-server-events/rate_limits/updated-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/rate_limits/updated-rate_limits)

rate\_limits

array

List of rate limit information.

Show properties

[](#realtime-server-events/rate_limits/updated-type)

type

string

The event type, must be `rate_limits.updated`.

OBJECT rate\_limits.updated
    {
        "event_id": "event_5758",
        "type": "rate_limits.updated",
        "rate_limits": [
            {
                "name": "requests",
                "limit": 1000,
                "remaining": 999,
                "reset_seconds": 60
            },
            {
                "name": "tokens",
                "limit": 50000,
                "remaining": 49950,
                "reset_seconds": 60
            }
        ]
    }

output\_audio\_buffer.started


---------------------------------

**WebRTC Only:** Emitted when the server begins streaming audio to the client. This event is emitted after an audio content part has been added (`response.content_part.added`) to the response. [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).

[](#realtime-server-events/output_audio_buffer/started-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/output_audio_buffer/started-response_id)

response\_id

string

The unique ID of the response that produced the audio.

[](#realtime-server-events/output_audio_buffer/started-type)

type

string

The event type, must be `output_audio_buffer.started`.

OBJECT output\_audio\_buffer.started
    {
        "event_id": "event_abc123",
        "type": "output_audio_buffer.started",
        "response_id": "resp_abc123"
    }

output\_audio\_buffer.stopped


---------------------------------

**WebRTC Only:** Emitted when the output audio buffer has been completely drained on the server, and no more audio is forthcoming. This event is emitted after the full response data has been sent to the client (`response.done`). [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).

[](#realtime-server-events/output_audio_buffer/stopped-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/output_audio_buffer/stopped-response_id)

response\_id

string

The unique ID of the response that produced the audio.

[](#realtime-server-events/output_audio_buffer/stopped-type)

type

string

The event type, must be `output_audio_buffer.stopped`.

OBJECT output\_audio\_buffer.stopped
    {
        "event_id": "event_abc123",
        "type": "output_audio_buffer.stopped",
        "response_id": "resp_abc123"
    }

output\_audio\_buffer.cleared


---------------------------------

**WebRTC Only:** Emitted when the output audio buffer is cleared. This happens either in VAD mode when the user has interrupted (`input_audio_buffer.speech_started`), or when the client has emitted the `output_audio_buffer.clear` event to manually cut off the current audio response. [Learn more](/docs/guides/realtime-model-capabilities#client-and-server-events-for-audio-in-webrtc).

[](#realtime-server-events/output_audio_buffer/cleared-event_id)

event\_id

string

The unique ID of the server event.

[](#realtime-server-events/output_audio_buffer/cleared-response_id)

response\_id

string

The unique ID of the response that produced the audio.

[](#realtime-server-events/output_audio_buffer/cleared-type)

type

string

The event type, must be `output_audio_buffer.cleared`.

OBJECT output\_audio\_buffer.cleared
    {
        "event_id": "event_abc123",
        "type": "output_audio_buffer.cleared",
        "response_id": "resp_abc123"
    }

Audio


---------

Learn how to turn audio into text or text into audio.

Related guide: [Speech to text](/docs/guides/speech-to-text)

Create speech


-----------------

postÂ https://api.openai.com/v1/audio/speech

Generates audio from the input text.

#### Request body

[](#audio-createspeech-input)

input

string

Required

The text to generate audio for. The maximum length is 4096 characters.

[](#audio-createspeech-model)

model

string

Required

One of the available [TTS models](/docs/models#tts): `tts-1`, `tts-1-hd` or `gpt-4o-mini-tts`.

[](#audio-createspeech-voice)

voice

string

Required

The voice to use when generating the audio. Supported voices are `alloy`, `ash`, `ballad`, `coral`, `echo`, `fable`, `onyx`, `nova`, `sage`, `shimmer`, and `verse`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech#voice-options).

[](#audio-createspeech-instructions)

instructions

string

Optional

Control the voice of your generated audio with additional instructions. Does not work with `tts-1` or `tts-1-hd`.

[](#audio-createspeech-response_format)

response\_format

string

Optional

Defaults to mp3

The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.

[](#audio-createspeech-speed)

speed

number

Optional

Defaults to 1

The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default. Does not work with `gpt-4o-mini-tts`.

#### Returns

The audio file content.

Example request

curl
    curl https://api.openai.com/v1/audio/speech \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "gpt-4o-mini-tts",
        "input": "The quick brown fox jumped over the lazy dog.",
        "voice": "alloy"
      }' \
      --output speech.mp3
    from pathlib import Path
    import openai
    
    speech_file_path = Path(__file__).parent / "speech.mp3"
    with openai.audio.speech.with_streaming_response.create(
      model="gpt-4o-mini-tts",
      voice="alloy",
      input="The quick brown fox jumped over the lazy dog."
    ) as response:
      response.stream_to_file(speech_file_path)
    import fs from "fs";
    import path from "path";
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    const speechFile = path.resolve("./speech.mp3");
    
    async function main() {
      const mp3 = await openai.audio.speech.create({
        model: "gpt-4o-mini-tts",
        voice: "alloy",
        input: "Today is a wonderful day to build something people love!",
      });
      console.log(speechFile);
      const buffer = Buffer.from(await mp3.arrayBuffer());
      await fs.promises.writeFile(speechFile, buffer);
    }
    main();
    using System;
    using System.IO;
    
    using OpenAI.Audio;
    
    AudioClient client = new(
        model: "gpt-4o-mini-tts",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    BinaryData speech = client.GenerateSpeech(
        text: "The quick brown fox jumped over the lazy dog.",
        voice: GeneratedSpeechVoice.Alloy
    );
    
    using FileStream stream = File.OpenWrite("speech.mp3");
    speech.ToStream().CopyTo(stream);

Create transcription


------------------------

postÂ https://api.openai.com/v1/audio/transcriptions

Transcribes audio into the input language.

#### Request body

[](#audio-createtranscription-file)

file

file

Required

The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

[](#audio-createtranscription-model)

model

string

Required

ID of the model to use. The options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1` (which is powered by our open source Whisper V2 model).

[](#audio-createtranscription-chunking_strategy)

chunking\_strategy

"auto" or object

Optional

Controls how the audio is cut into chunks. When set to `"auto"`, the server first normalizes loudness and then uses voice activity detection (VAD) to choose boundaries. `server_vad` object can be provided to tweak VAD detection parameters manually. If unset, the audio is transcribed as a single block.

Show possible types

[](#audio-createtranscription-include)

include\[\]

array

Optional

Additional information to include in the transcription response. `logprobs` will return the log probabilities of the tokens in the response to understand the model's confidence in the transcription. `logprobs` only works with response\_format set to `json` and only with the models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`.

[](#audio-createtranscription-language)

language

string

Optional

The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format will improve accuracy and latency.

[](#audio-createtranscription-prompt)

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.

[](#audio-createtranscription-response_format)

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`. For `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`, the only supported format is `json`.

[](#audio-createtranscription-stream)

stream

boolean or null

Optional

Defaults to false

If set to true, the model response data will be streamed to the client as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format). See the [Streaming section of the Speech-to-Text guide](/docs/guides/speech-to-text?lang=curl#streaming-transcriptions) for more information.

Note: Streaming is not supported for the `whisper-1` model and will be ignored.

[](#audio-createtranscription-temperature)

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

[](#audio-createtranscription-timestamp_granularities)

timestamp\_granularities\[\]

array

Optional

Defaults to segment

The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

#### Returns

The [transcription object](/docs/api-reference/audio/json-object), a [verbose transcription object](/docs/api-reference/audio/verbose-json-object) or a [stream of transcript events](/docs/api-reference/audio/transcript-text-delta-event).

DefaultDefaultStreamingStreamingLogprobsLogprobsWord timestampsWord timestampsSegment timestampsSegment timestamps

Example request

curl
    curl https://api.openai.com/v1/audio/transcriptions \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: multipart/form-data" \
      -F file="@/path/to/file/audio.mp3" \
      -F model="gpt-4o-transcribe"
    from openai import OpenAI
    client = OpenAI()
    
    audio_file = open("speech.mp3", "rb")
    transcript = client.audio.transcriptions.create(
      model="gpt-4o-transcribe",
      file=audio_file
    )
    import fs from "fs";
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const transcription = await openai.audio.transcriptions.create({
        file: fs.createReadStream("audio.mp3"),
        model: "gpt-4o-transcribe",
      });
    
      console.log(transcription.text);
    }
    main();
    using System;
    
    using OpenAI.Audio;
    string audioFilePath = "audio.mp3";
    
    AudioClient client = new(
        model: "gpt-4o-transcribe",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    AudioTranscription transcription = client.TranscribeAudio(audioFilePath);
    
    Console.WriteLine($"{transcription.Text}");

Response
    {
      "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
    }

Create translation


----------------------

postÂ https://api.openai.com/v1/audio/translations

Translates audio into English.

#### Request body

[](#audio-createtranslation-file)

file

file

Required

The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

[](#audio-createtranslation-model)

model

string or "whisper-1"

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

[](#audio-createtranslation-prompt)

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English.

[](#audio-createtranslation-response_format)

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

[](#audio-createtranslation-temperature)

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

#### Returns

The translated text.

Example request

curl
    curl https://api.openai.com/v1/audio/translations \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: multipart/form-data" \
      -F file="@/path/to/file/german.m4a" \
      -F model="whisper-1"
    from openai import OpenAI
    client = OpenAI()
    
    audio_file = open("speech.mp3", "rb")
    transcript = client.audio.translations.create(
      model="whisper-1",
      file=audio_file
    )
    import fs from "fs";
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
        const translation = await openai.audio.translations.create({
            file: fs.createReadStream("speech.mp3"),
            model: "whisper-1",
        });
    
        console.log(translation.text);
    }
    main();
    using System;
    
    using OpenAI.Audio;
    
    string audioFilePath = "audio.mp3";
    
    AudioClient client = new(
        model: "whisper-1",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    AudioTranscription transcription = client.TranscribeAudio(audioFilePath);
    
    Console.WriteLine($"{transcription.Text}");

Response
    {
      "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
    }

The transcription object (JSON)


-----------------------------------

Represents a transcription response returned by model, based on the provided input.

[](#audio/json-object-logprobs)

logprobs

array

The log probabilities of the tokens in the transcription. Only returned with the models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe` if `logprobs` is added to the `include` array.

Show properties

[](#audio/json-object-text)

text

string

The transcribed text.

OBJECT The transcription object (JSON)
    {
      "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
    }

The transcription object (Verbose JSON)


-------------------------------------------

Represents a verbose json transcription response returned by model, based on the provided input.

[](#audio/verbose-json-object-duration)

duration

number

The duration of the input audio.

[](#audio/verbose-json-object-language)

language

string

The language of the input audio.

[](#audio/verbose-json-object-segments)

segments

array

Segments of the transcribed text and their corresponding details.

Show properties

[](#audio/verbose-json-object-text)

text

string

The transcribed text.

[](#audio/verbose-json-object-words)

words

array

Extracted words and their corresponding timestamps.

Show properties

OBJECT The transcription object (Verbose JSON)
    {
      "task": "transcribe",
      "language": "english",
      "duration": 8.470000267028809,
      "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.319999933242798,
          "text": " The beach was a popular spot on a hot summer day.",
          "tokens": [
            50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2860786020755768,
          "compression_ratio": 1.2363636493682861,
          "no_speech_prob": 0.00985979475080967
        },
        ...
      ]
    }

Stream Event (transcript.text.delta)


----------------------------------------

Emitted when there is an additional text delta. This is also the first event emitted when the transcription starts. Only emitted when you [create a transcription](/docs/api-reference/audio/create-transcription) with the `Stream` parameter set to `true`.

[](#audio/transcript-text-delta-event-delta)

delta

string

The text delta that was additionally transcribed.

[](#audio/transcript-text-delta-event-logprobs)

logprobs

array

The log probabilities of the delta. Only included if you [create a transcription](/docs/api-reference/audio/create-transcription) with the `include[]` parameter set to `logprobs`.

Show properties

[](#audio/transcript-text-delta-event-type)

type

string

The type of the event. Always `transcript.text.delta`.

OBJECT Stream Event (transcript.text.delta)
    {
      "type": "transcript.text.delta",
      "delta": " wonderful"
    }

Stream Event (transcript.text.done)


---------------------------------------

Emitted when the transcription is complete. Contains the complete transcription text. Only emitted when you [create a transcription](/docs/api-reference/audio/create-transcription) with the `Stream` parameter set to `true`.

[](#audio/transcript-text-done-event-logprobs)

logprobs

array

The log probabilities of the individual tokens in the transcription. Only included if you [create a transcription](/docs/api-reference/audio/create-transcription) with the `include[]` parameter set to `logprobs`.

Show properties

[](#audio/transcript-text-done-event-text)

text

string

The text that was transcribed.

[](#audio/transcript-text-done-event-type)

type

string

The type of the event. Always `transcript.text.done`.

OBJECT Stream Event (transcript.text.done)
    {
      "type": "transcript.text.done",
      "text": "I see skies of blue and clouds of white, the bright blessed days, the dark sacred nights, and I think to myself, what a wonderful world."
    }

Images


----------

Given a prompt and/or an input image, the model will generate a new image. Related guide: [Image generation](/docs/guides/images)

Create image


----------------

postÂ https://api.openai.com/v1/images/generations

Creates an image given a prompt. [Learn more](/docs/guides/images).

#### Request body

[](#images-create-prompt)

prompt

string

Required

A text description of the desired image(s). The maximum length is 32000 characters for `gpt-image-1`, 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.

[](#images-create-background)

background

string or null

Optional

Defaults to auto

Allows to set transparency for the background of the generated image(s). This parameter is only supported for `gpt-image-1`. Must be one of `transparent`, `opaque` or `auto` (default value). When `auto` is used, the model will automatically determine the best background for the image.

If `transparent`, the output format needs to support transparency, so it should be set to either `png` (default value) or `webp`.

[](#images-create-model)

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. One of `dall-e-2`, `dall-e-3`, or `gpt-image-1`. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.

[](#images-create-moderation)

moderation

string or null

Optional

Defaults to auto

Control the content-moderation level for images generated by `gpt-image-1`. Must be either `low` for less restrictive filtering or `auto` (default value).

[](#images-create-n)

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

[](#images-create-output_compression)

output\_compression

integer or null

Optional

Defaults to 100

The compression level (0-100%) for the generated images. This parameter is only supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and defaults to 100.

[](#images-create-output_format)

output\_format

string or null

Optional

Defaults to png

The format in which the generated images are returned. This parameter is only supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.

[](#images-create-quality)

quality

string or null

Optional

Defaults to auto

The quality of the image that will be generated.

*   `auto` (default value) will automatically select the best quality for the given model.
*   `high`, `medium` and `low` are supported for `gpt-image-1`.
*   `hd` and `standard` are supported for `dall-e-3`.
*   `standard` is the only option for `dall-e-2`.

[](#images-create-response_format)

response\_format

string or null

Optional

Defaults to url

The format in which generated images with `dall-e-2` and `dall-e-3` are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter isn't supported for `gpt-image-1` which will always return base64-encoded images.

[](#images-create-size)

size

string or null

Optional

Defaults to auto

The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.

[](#images-create-style)

style

string or null

Optional

Defaults to vivid

The style of the generated images. This parameter is only supported for `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images.

[](#images-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/images/generations \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "model": "gpt-image-1",
        "prompt": "A cute baby sea otter",
        "n": 1,
        "size": "1024x1024"
      }'
    import base64
    from openai import OpenAI
    client = OpenAI()
    
    img = client.images.generate(
        model="gpt-image-1",
        prompt="A cute baby sea otter",
        n=1,
        size="1024x1024"
    )
    
    image_bytes = base64.b64decode(img.data[0].b64_json)
    with open("output.png", "wb") as f:
        f.write(image_bytes)
    import OpenAI from "openai";
    import { writeFile } from "fs/promises";
    
    const client = new OpenAI();
    
    const img = await client.images.generate({
      model: "gpt-image-1",
      prompt: "A cute baby sea otter",
      n: 1,
      size: "1024x1024"
    });
    
    const imageBuffer = Buffer.from(img.data[0].b64_json, "base64");
    await writeFile("output.png", imageBuffer);

Response
    {
      "created": 1713833628,
      "data": [
        {
          "b64_json": "..."
        }
      ],
      "usage": {
        "total_tokens": 100,
        "input_tokens": 50,
        "output_tokens": 50,
        "input_tokens_details": {
          "text_tokens": 10,
          "image_tokens": 40
        }
      }
    }

Create image edit


---------------------

postÂ https://api.openai.com/v1/images/edits

Creates an edited or extended image given one or more source images and a prompt. This endpoint only supports `gpt-image-1` and `dall-e-2`.

#### Request body

[](#images-createedit-image)

image

string or array

Required

The image(s) to edit. Must be a supported image file or an array of images.

For `gpt-image-1`, each image should be a `png`, `webp`, or `jpg` file less than 25MB. You can provide up to 16 images.

For `dall-e-2`, you can only provide one image, and it should be a square `png` file less than 4MB.

[](#images-createedit-prompt)

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2`, and 32000 characters for `gpt-image-1`.

[](#images-createedit-background)

background

string or null

Optional

Defaults to auto

Allows to set transparency for the background of the generated image(s). This parameter is only supported for `gpt-image-1`. Must be one of `transparent`, `opaque` or `auto` (default value). When `auto` is used, the model will automatically determine the best background for the image.

If `transparent`, the output format needs to support transparency, so it should be set to either `png` (default value) or `webp`.

[](#images-createedit-mask)

mask

file

Optional

An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. If there are multiple images provided, the mask will be applied on the first image. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.

[](#images-createedit-model)

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` and `gpt-image-1` are supported. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.

[](#images-createedit-n)

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

[](#images-createedit-quality)

quality

string or null

Optional

Defaults to auto

The quality of the image that will be generated. `high`, `medium` and `low` are only supported for `gpt-image-1`. `dall-e-2` only supports `standard` quality. Defaults to `auto`.

[](#images-createedit-response_format)

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter is only supported for `dall-e-2`, as `gpt-image-1` will always return base64-encoded images.

[](#images-createedit-size)

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, and one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`.

[](#images-createedit-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

node.js
    curl -s -D >(grep -i x-request-id >&2) \
      -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png) \
      -X POST "https://api.openai.com/v1/images/edits" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -F "model=gpt-image-1" \
      -F "image[]=@body-lotion.png" \
      -F "image[]=@bath-bomb.png" \
      -F "image[]=@incense-kit.png" \
      -F "image[]=@soap.png" \
      -F 'prompt=Create a lovely gift basket with these four items in it'
    import base64
    from openai import OpenAI
    client = OpenAI()
    
    prompt = """
    Generate a photorealistic image of a gift basket on a white background 
    labeled 'Relax & Unwind' with a ribbon and handwriting-like font, 
    containing all the items in the reference pictures.
    """
    
    result = client.images.edit(
        model="gpt-image-1",
        image=[
            open("body-lotion.png", "rb"),
            open("bath-bomb.png", "rb"),
            open("incense-kit.png", "rb"),
            open("soap.png", "rb"),
        ],
        prompt=prompt
    )
    
    image_base64 = result.data[0].b64_json
    image_bytes = base64.b64decode(image_base64)
    
    # Save the image to a file
    with open("gift-basket.png", "wb") as f:
        f.write(image_bytes)
    import fs from "fs";
    import OpenAI, { toFile } from "openai";
    
    const client = new OpenAI();
    
    const imageFiles = [
        "bath-bomb.png",
        "body-lotion.png",
        "incense-kit.png",
        "soap.png",
    ];
    
    const images = await Promise.all(
        imageFiles.map(async (file) =>
            await toFile(fs.createReadStream(file), null, {
                type: "image/png",
            })
        ),
    );
    
    const rsp = await client.images.edit({
        model: "gpt-image-1",
        image: images,
        prompt: "Create a lovely gift basket with these four items in it",
    });
    
    // Save the image to a file
    const image_base64 = rsp.data[0].b64_json;
    const image_bytes = Buffer.from(image_base64, "base64");
    fs.writeFileSync("basket.png", image_bytes);

Response
    {
      "created": 1713833628,
      "data": [
        {
          "b64_json": "..."
        }
      ],
      "usage": {
        "total_tokens": 100,
        "input_tokens": 50,
        "output_tokens": 50,
        "input_tokens_details": {
          "text_tokens": 10,
          "image_tokens": 40
        }
      }
    }

Create image variation


--------------------------

postÂ https://api.openai.com/v1/images/variations

Creates a variation of a given image. This endpoint only supports `dall-e-2`.

#### Request body

[](#images-createvariation-image)

image

file

Required

The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.

[](#images-createvariation-model)

model

string or "dall-e-2"

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

[](#images-createvariation-n)

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

[](#images-createvariation-response_format)

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

[](#images-createvariation-size)

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

[](#images-createvariation-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/images/variations \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -F image="@otter.png" \
      -F n=2 \
      -F size="1024x1024"
    from openai import OpenAI
    client = OpenAI()
    
    response = client.images.create_variation(
      image=open("image_edit_original.png", "rb"),
      n=2,
      size="1024x1024"
    )
    import fs from "fs";
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const image = await openai.images.createVariation({
        image: fs.createReadStream("otter.png"),
      });
    
      console.log(image.data);
    }
    main();
    using System;
    
    using OpenAI.Images;
    
    ImageClient client = new(
        model: "dall-e-2",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    GeneratedImage image = client.GenerateImageVariation(imageFilePath: "otter.png");
    
    Console.WriteLine(image.ImageUri);

Response
    {
      "created": 1589478378,
      "data": [
        {
          "url": "https://..."
        },
        {
          "url": "https://..."
        }
      ]
    }

The image generation response


---------------------------------

The response from the image generation endpoint.

[](#images/object-created)

created

integer

The Unix timestamp (in seconds) of when the image was created.

[](#images/object-data)

data

array

The list of generated images.

Show properties

[](#images/object-usage)

usage

object

For `gpt-image-1` only, the token usage information for the image generation.

Show properties

OBJECT The image generation response
    {
      "created": 1713833628,
      "data": [
        {
          "b64_json": "..."
        }
      ],
      "usage": {
        "total_tokens": 100,
        "input_tokens": 50,
        "output_tokens": 50,
        "input_tokens_details": {
          "text_tokens": 10,
          "image_tokens": 40
        }
      }
    }

Embeddings


--------------

Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms. Related guide: [Embeddings](/docs/guides/embeddings)

Create embeddings


---------------------

postÂ https://api.openai.com/v1/embeddings

Creates an embedding vector representing the input text.

#### Request body

[](#embeddings-create-input)

input

string or array

Required

Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for all embedding models), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens. In addition to the per-input token limit, all embedding models enforce a maximum of 300,000 tokens summed across all inputs in a single request.

[](#embeddings-create-model)

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

[](#embeddings-create-dimensions)

dimensions

integer

Optional

The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.

[](#embeddings-create-encoding_format)

encoding\_format

string

Optional

Defaults to float

The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).

[](#embeddings-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

A list of [embedding](/docs/api-reference/embeddings/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/embeddings \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "input": "The food was delicious and the waiter...",
        "model": "text-embedding-ada-002",
        "encoding_format": "float"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    client.embeddings.create(
      model="text-embedding-ada-002",
      input="The food was delicious and the waiter...",
      encoding_format="float"
    )
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const embedding = await openai.embeddings.create({
        model: "text-embedding-ada-002",
        input: "The quick brown fox jumped over the lazy dog",
        encoding_format: "float",
      });
    
      console.log(embedding);
    }
    
    main();
    using System;
    
    using OpenAI.Embeddings;
    
    EmbeddingClient client = new(
        model: "text-embedding-3-small",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    OpenAIEmbedding embedding = client.GenerateEmbedding(input: "The quick brown fox jumped over the lazy dog");
    ReadOnlyMemory<float> vector = embedding.ToFloats();
    
    for (int i = 0; i < vector.Length; i++)
    {
        Console.WriteLine($"  [{i,4}] = {vector.Span[i]}");
    }

Response
    {
      "object": "list",
      "data": [
        {
          "object": "embedding",
          "embedding": [
            0.0023064255,
            -0.009327292,
            .... (1536 floats total for ada-002)
            -0.0028842222,
          ],
          "index": 0
        }
      ],
      "model": "text-embedding-ada-002",
      "usage": {
        "prompt_tokens": 8,
        "total_tokens": 8
      }
    }

The embedding object


------------------------

Represents an embedding vector returned by embedding endpoint.

[](#embeddings/object-embedding)

embedding

array

The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).

[](#embeddings/object-index)

index

integer

The index of the embedding in the list of embeddings.

[](#embeddings/object-object)

object

string

The object type, which is always "embedding".

OBJECT The embedding object
    {
      "object": "embedding",
      "embedding": [
        0.0023064255,
        -0.009327292,
        .... (1536 floats total for ada-002)
        -0.0028842222,
      ],
      "index": 0
    }

Evals


---------

Create, manage, and run evals in the OpenAI platform. Related guide: [Evals](/docs/guides/evals)

Create eval


---------------

postÂ https://api.openai.com/v1/evals

Create the structure of an evaluation that can be used to test a model's performance. An evaluation is a set of testing criteria and a datasource. After creating an evaluation, you can run it on different models and model parameters. We support several types of graders and datasources. For more information, see the [Evals guide](/docs/guides/evals).

#### Request body

[](#evals-create-data_source_config)

data\_source\_config

object

Required

The configuration for the data source used for the evaluation runs.

Show possible types

[](#evals-create-testing_criteria)

testing\_criteria

array

Required

A list of graders for all eval runs in this group.

Show possible types

[](#evals-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#evals-create-name)

name

string

Optional

The name of the evaluation.

#### Returns

The created [Eval](/docs/api-reference/evals/object) object.

Example request

curl
    curl https://api.openai.com/v1/evals \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
            "name": "Sentiment",
            "data_source_config": {
              "type": "stored_completions",
              "metadata": {
                  "usecase": "chatbot"
              }
            },
            "testing_criteria": [
              {
                "type": "label_model",
                "model": "o3-mini",
                "input": [
                  {
                    "role": "developer",
                    "content": "Classify the sentiment of the following statement as one of 'positive', 'neutral', or 'negative'"
                  },
                  {
                    "role": "user",
                    "content": "Statement: {{item.input}}"
                  }
                ],
                "passing_labels": [
                  "positive"
                ],
                "labels": [
                  "positive",
                  "neutral",
                  "negative"
                ],
                "name": "Example label grader"
              }
            ]
          }'

Response
    {
      "object": "eval",
      "id": "eval_67b7fa9a81a88190ab4aa417e397ea21",
      "data_source_config": {
        "type": "stored_completions",
        "metadata": {
          "usecase": "chatbot"
        },
        "schema": {
          "type": "object",
          "properties": {
            "item": {
              "type": "object"
            },
            "sample": {
              "type": "object"
            }
          },
          "required": [
            "item",
            "sample"
          ]
      },
      "testing_criteria": [
        {
          "name": "Example label grader",
          "type": "label_model",
          "model": "o3-mini",
          "input": [
            {
              "type": "message",
              "role": "developer",
              "content": {
                "type": "input_text",
                "text": "Classify the sentiment of the following statement as one of positive, neutral, or negative"
              }
            },
            {
              "type": "message",
              "role": "user",
              "content": {
                "type": "input_text",
                "text": "Statement: {{item.input}}"
              }
            }
          ],
          "passing_labels": [
            "positive"
          ],
          "labels": [
            "positive",
            "neutral",
            "negative"
          ]
        }
      ],
      "name": "Sentiment",
      "created_at": 1740110490,
      "metadata": {
        "description": "An eval for sentiment analysis"
      }
    }

Get an eval


---------------

getÂ https://api.openai.com/v1/evals/{eval\_id}

Get an evaluation by ID.

#### Path parameters

[](#evals-get-eval_id)

eval\_id

string

Required

The ID of the evaluation to retrieve.

#### Returns

The [Eval](/docs/api-reference/evals/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "eval",
      "id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "data_source_config": {
        "type": "custom",
        "schema": {
          "type": "object",
          "properties": {
            "item": {
              "type": "object",
              "properties": {
                "input": {
                  "type": "string"
                },
                "ground_truth": {
                  "type": "string"
                }
              },
              "required": [
                "input",
                "ground_truth"
              ]
            }
          },
          "required": [
            "item"
          ]
        }
      },
      "testing_criteria": [
        {
          "name": "String check",
          "id": "String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2",
          "type": "string_check",
          "input": "{{item.input}}",
          "reference": "{{item.ground_truth}}",
          "operation": "eq"
        }
      ],
      "name": "External Data Eval",
      "created_at": 1739314509,
      "metadata": {},
    }

Update an eval


------------------

postÂ https://api.openai.com/v1/evals/{eval\_id}

Update certain properties of an evaluation.

#### Path parameters

[](#evals-update-eval_id)

eval\_id

string

Required

The ID of the evaluation to update.

#### Request body

[](#evals-update-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#evals-update-name)

name

string

Optional

Rename the evaluation.

#### Returns

The [Eval](/docs/api-reference/evals/object) object matching the updated version.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{"name": "Updated Eval", "metadata": {"description": "Updated description"}}'

Response
    {
      "object": "eval",
      "id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "data_source_config": {
        "type": "custom",
        "schema": {
          "type": "object",
          "properties": {
            "item": {
              "type": "object",
              "properties": {
                "input": {
                  "type": "string"
                },
                "ground_truth": {
                  "type": "string"
                }
              },
              "required": [
                "input",
                "ground_truth"
              ]
            }
          },
          "required": [
            "item"
          ]
        }
      },
      "testing_criteria": [
        {
          "name": "String check",
          "id": "String check-2eaf2d8d-d649-4335-8148-9535a7ca73c2",
          "type": "string_check",
          "input": "{{item.input}}",
          "reference": "{{item.ground_truth}}",
          "operation": "eq"
        }
      ],
      "name": "Updated Eval",
      "created_at": 1739314509,
      "metadata": {"description": "Updated description"},
    }

Delete an eval


------------------

deleteÂ https://api.openai.com/v1/evals/{eval\_id}

Delete an evaluation.

#### Path parameters

[](#evals-delete-eval_id)

eval\_id

string

Required

The ID of the evaluation to delete.

#### Returns

A deletion confirmation object.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_abc123 \
      -X DELETE \
      -H "Authorization: Bearer $OPENAI_API_KEY"

Response
    {
      "object": "eval.deleted",
      "deleted": true,
      "eval_id": "eval_abc123"
    }

List evals


--------------

getÂ https://api.openai.com/v1/evals

List evaluations for a project.

#### Query parameters

[](#evals-list-after)

after

string

Optional

Identifier for the last eval from the previous pagination request.

[](#evals-list-limit)

limit

integer

Optional

Defaults to 20

Number of evals to retrieve.

[](#evals-list-order)

order

string

Optional

Defaults to asc

Sort order for evals by timestamp. Use `asc` for ascending order or `desc` for descending order.

[](#evals-list-order_by)

order\_by

string

Optional

Defaults to created\_at

Evals can be ordered by creation time or last updated time. Use `created_at` for creation time or `updated_at` for last updated time.

#### Returns

A list of [evals](/docs/api-reference/evals/object) matching the specified filters.

Example request

curl
    curl https://api.openai.com/v1/evals?limit=1 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "list",
      "data": [
        {
          "id": "eval_67abd54d9b0081909a86353f6fb9317a",
          "object": "eval",
          "data_source_config": {
            "type": "stored_completions",
            "metadata": {
              "usecase": "push_notifications_summarizer"
            },
            "schema": {
              "type": "object",
              "properties": {
                "item": {
                  "type": "object"
                },
                "sample": {
                  "type": "object"
                }
              },
              "required": [
                "item",
                "sample"
              ]
            }
          },
          "testing_criteria": [
            {
              "name": "Push Notification Summary Grader",
              "id": "Push Notification Summary Grader-9b876f24-4762-4be9-aff4-db7a9b31c673",
              "type": "label_model",
              "model": "o3-mini",
              "input": [
                {
                  "type": "message",
                  "role": "developer",
                  "content": {
                    "type": "input_text",
                    "text": "\nLabel the following push notification summary as either correct or incorrect.\nThe push notification and the summary will be provided below.\nA good push notificiation summary is concise and snappy.\nIf it is good, then label it as correct, if not, then incorrect.\n"
                  }
                },
                {
                  "type": "message",
                  "role": "user",
                  "content": {
                    "type": "input_text",
                    "text": "\nPush notifications: {{item.input}}\nSummary: {{sample.output_text}}\n"
                  }
                }
              ],
              "passing_labels": [
                "correct"
              ],
              "labels": [
                "correct",
                "incorrect"
              ],
              "sampling_params": null
            }
          ],
          "name": "Push Notification Summary Grader",
          "created_at": 1739314509,
          "metadata": {
            "description": "A stored completions eval for push notification summaries"
          }
        }
      ],
      "first_id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "last_id": "eval_67aa884cf6688190b58f657d4441c8b7",
      "has_more": true
    }

Get eval runs


-----------------

getÂ https://api.openai.com/v1/evals/{eval\_id}/runs

Get a list of runs for an evaluation.

#### Path parameters

[](#evals-getruns-eval_id)

eval\_id

string

Required

The ID of the evaluation to retrieve runs for.

#### Query parameters

[](#evals-getruns-after)

after

string

Optional

Identifier for the last run from the previous pagination request.

[](#evals-getruns-limit)

limit

integer

Optional

Defaults to 20

Number of runs to retrieve.

[](#evals-getruns-order)

order

string

Optional

Defaults to asc

Sort order for runs by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.

[](#evals-getruns-status)

status

string

Optional

Filter runs by status. One of `queued` | `in_progress` | `failed` | `completed` | `canceled`.

#### Returns

A list of [EvalRun](/docs/api-reference/evals/run-object) objects matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "eval.run",
          "id": "evalrun_67e0c7d31560819090d60c0780591042",
          "eval_id": "eval_67e0c726d560819083f19a957c4c640b",
          "report_url": "https://platform.openai.com/evaluations/eval_67e0c726d560819083f19a957c4c640b",
          "status": "completed",
          "model": "o3-mini",
          "name": "bulk_with_negative_examples_o3-mini",
          "created_at": 1742784467,
          "result_counts": {
            "total": 1,
            "errored": 0,
            "failed": 0,
            "passed": 1
          },
          "per_model_usage": [
            {
              "model_name": "o3-mini",
              "invocation_count": 1,
              "prompt_tokens": 563,
              "completion_tokens": 874,
              "total_tokens": 1437,
              "cached_tokens": 0
            }
          ],
          "per_testing_criteria_results": [
            {
              "testing_criteria": "Push Notification Summary Grader-1808cd0b-eeec-4e0b-a519-337e79f4f5d1",
              "passed": 1,
              "failed": 0
            }
          ],
          "data_source": {
            "type": "completions",
            "source": {
              "type": "file_content",
              "content": [
                {
                  "item": {
                    "notifications": "\n- New message from Sarah: \"Can you call me later?\"\n- Your package has been delivered!\n- Flash sale: 20% off electronics for the next 2 hours!\n"
                  }
                }
              ]
            },
            "input_messages": {
              "type": "template",
              "template": [
                {
                  "type": "message",
                  "role": "developer",
                  "content": {
                    "type": "input_text",
                    "text": "\n\n\n\nYou are a helpful assistant that takes in an array of push notifications and returns a collapsed summary of them.\nThe push notification will be provided as follows:\n<push_notifications>\n...notificationlist...\n</push_notifications>\n\nYou should return just the summary and nothing else.\n\n\nYou should return a summary that is concise and snappy.\n\n\nHere is an example of a good summary:\n<push_notifications>\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\n</push_notifications>\n<summary>\nTraffic alert, package expected by 5pm, suggestion for new friend (Emily).\n</summary>\n\n\nHere is an example of a bad summary:\n<push_notifications>\n- Traffic alert: Accident reported on Main Street.- Package out for delivery: Expected by 5 PM.- New friend suggestion: Connect with Emma.\n</push_notifications>\n<summary>\nTraffic alert reported on main street. You have a package that will arrive by 5pm, Emily is a new friend suggested for you.\n</summary>\n"
                  }
                },
                {
                  "type": "message",
                  "role": "user",
                  "content": {
                    "type": "input_text",
                    "text": "<push_notifications>{{item.notifications}}</push_notifications>"
                  }
                }
              ]
            },
            "model": "o3-mini",
            "sampling_params": null
          },
          "error": null,
          "metadata": {}
        }
      ],
      "first_id": "evalrun_67e0c7d31560819090d60c0780591042",
      "last_id": "evalrun_67e0c7d31560819090d60c0780591042",
      "has_more": true
    }

Get an eval run


-------------------

getÂ https://api.openai.com/v1/evals/{eval\_id}/runs/{run\_id}

Get an evaluation run by ID.

#### Path parameters

[](#evals-getrun-eval_id)

eval\_id

string

Required

The ID of the evaluation to retrieve runs for.

[](#evals-getrun-run_id)

run\_id

string

Required

The ID of the run to retrieve.

#### Returns

The [EvalRun](/docs/api-reference/evals/run-object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "eval.run",
      "id": "evalrun_67abd54d60ec8190832b46859da808f7",
      "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "report_url": "https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7",
      "status": "queued",
      "model": "gpt-4o-mini",
      "name": "gpt-4o-mini",
      "created_at": 1743092069,
      "result_counts": {
        "total": 0,
        "errored": 0,
        "failed": 0,
        "passed": 0
      },
      "per_model_usage": null,
      "per_testing_criteria_results": null,
      "data_source": {
        "type": "completions",
        "source": {
          "type": "file_content",
          "content": [
            {
              "item": {
                "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Summit Addresses Climate Change Strategies",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "National Team Qualifies for World Championship Finals",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Stock Markets Rally After Positive Economic Data Released",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "Global Manufacturer Announces Merger with Competitor",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Breakthrough in Renewable Energy Technology Unveiled",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "World Leaders Sign Historic Climate Agreement",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Professional Athlete Sets New Record in Championship Event",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Financial Institutions Adapt to New Regulatory Requirements",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Global Markets Respond to Oil Price Fluctuations",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Cooperation Strengthened Through New Treaty",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Sports League Announces Revised Schedule for Upcoming Season",
                "ground_truth": "Sports"
              }
            }
          ]
        },
        "input_messages": {
          "type": "template",
          "template": [
            {
              "type": "message",
              "role": "developer",
              "content": {
                "type": "input_text",
                "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
              }
            },
            {
              "type": "message",
              "role": "user",
              "content": {
                "type": "input_text",
                "text": "{{item.input}}"
              }
            }
          ]
        },
        "model": "gpt-4o-mini",
        "sampling_params": {
          "seed": 42,
          "temperature": 1.0,
          "top_p": 1.0,
          "max_completions_tokens": 2048
        }
      },
      "error": null,
      "metadata": {}
    }

Create eval run


-------------------

postÂ https://api.openai.com/v1/evals/{eval\_id}/runs

Create a new evaluation run. This is the endpoint that will kick off grading.

#### Path parameters

[](#evals-createrun-eval_id)

eval\_id

string

Required

The ID of the evaluation to create a run for.

#### Request body

[](#evals-createrun-data_source)

data\_source

object

Required

Details about the run's data source.

Show possible types

[](#evals-createrun-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#evals-createrun-name)

name

string

Optional

The name of the run.

#### Returns

The [EvalRun](/docs/api-reference/evals/run-object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67e579652b548190aaa83ada4b125f47/runs \
      -X POST \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{"name":"gpt-4o-mini","data_source":{"type":"completions","input_messages":{"type":"template","template":[{"role":"developer","content":"Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"} , {"role":"user","content":"{{item.input}}"}]},"sampling_params":{"temperature":1,"max_completions_tokens":2048,"top_p":1,"seed":42},"model":"gpt-4o-mini","source":{"type":"file_content","content":[{"item":{"input":"Tech Company Launches Advanced Artificial Intelligence Platform","ground_truth":"Technology"}}]}}'

Response
    {
      "object": "eval.run",
      "id": "evalrun_67e57965b480819094274e3a32235e4c",
      "eval_id": "eval_67e579652b548190aaa83ada4b125f47",
      "report_url": "https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47&run_id=evalrun_67e57965b480819094274e3a32235e4c",
      "status": "queued",
      "model": "gpt-4o-mini",
      "name": "gpt-4o-mini",
      "created_at": 1743092069,
      "result_counts": {
        "total": 0,
        "errored": 0,
        "failed": 0,
        "passed": 0
      },
      "per_model_usage": null,
      "per_testing_criteria_results": null,
      "data_source": {
        "type": "completions",
        "source": {
          "type": "file_content",
          "content": [
            {
              "item": {
                "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                "ground_truth": "Technology"
              }
            }
          ]
        },
        "input_messages": {
          "type": "template",
          "template": [
            {
              "type": "message",
              "role": "developer",
              "content": {
                "type": "input_text",
                "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
              }
            },
            {
              "type": "message",
              "role": "user",
              "content": {
                "type": "input_text",
                "text": "{{item.input}}"
              }
            }
          ]
        },
        "model": "gpt-4o-mini",
        "sampling_params": {
          "seed": 42,
          "temperature": 1.0,
          "top_p": 1.0,
          "max_completions_tokens": 2048
        }
      },
      "error": null,
      "metadata": {}
    }

Cancel eval run


-------------------

postÂ https://api.openai.com/v1/evals/{eval\_id}/runs/{run\_id}

Cancel an ongoing evaluation run.

#### Path parameters

[](#evals-cancelrun-eval_id)

eval\_id

string

Required

The ID of the evaluation whose run you want to cancel.

[](#evals-cancelrun-run_id)

run\_id

string

Required

The ID of the run to cancel.

#### Returns

The updated [EvalRun](/docs/api-reference/evals/run-object) object reflecting that the run is canceled.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/cancel \
      -X POST \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "eval.run",
      "id": "evalrun_67abd54d60ec8190832b46859da808f7",
      "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "report_url": "https://platform.openai.com/evaluations/eval_67abd54d9b0081909a86353f6fb9317a?run_id=evalrun_67abd54d60ec8190832b46859da808f7",
      "status": "canceled",
      "model": "gpt-4o-mini",
      "name": "gpt-4o-mini",
      "created_at": 1743092069,
      "result_counts": {
        "total": 0,
        "errored": 0,
        "failed": 0,
        "passed": 0
      },
      "per_model_usage": null,
      "per_testing_criteria_results": null,
      "data_source": {
        "type": "completions",
        "source": {
          "type": "file_content",
          "content": [
            {
              "item": {
                "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Summit Addresses Climate Change Strategies",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "National Team Qualifies for World Championship Finals",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Stock Markets Rally After Positive Economic Data Released",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "Global Manufacturer Announces Merger with Competitor",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Breakthrough in Renewable Energy Technology Unveiled",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "World Leaders Sign Historic Climate Agreement",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Professional Athlete Sets New Record in Championship Event",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Financial Institutions Adapt to New Regulatory Requirements",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Global Markets Respond to Oil Price Fluctuations",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Cooperation Strengthened Through New Treaty",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Sports League Announces Revised Schedule for Upcoming Season",
                "ground_truth": "Sports"
              }
            }
          ]
        },
        "input_messages": {
          "type": "template",
          "template": [
            {
              "type": "message",
              "role": "developer",
              "content": {
                "type": "input_text",
                "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
              }
            },
            {
              "type": "message",
              "role": "user",
              "content": {
                "type": "input_text",
                "text": "{{item.input}}"
              }
            }
          ]
        },
        "model": "gpt-4o-mini",
        "sampling_params": {
          "seed": 42,
          "temperature": 1.0,
          "top_p": 1.0,
          "max_completions_tokens": 2048
        }
      },
      "error": null,
      "metadata": {}
    }

Delete eval run


-------------------

deleteÂ https://api.openai.com/v1/evals/{eval\_id}/runs/{run\_id}

Delete an eval run.

#### Path parameters

[](#evals-deleterun-eval_id)

eval\_id

string

Required

The ID of the evaluation to delete the run from.

[](#evals-deleterun-run_id)

run\_id

string

Required

The ID of the run to delete.

#### Returns

An object containing the status of the delete operation.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_123abc/runs/evalrun_abc456 \
      -X DELETE \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "eval.run.deleted",
      "deleted": true,
      "run_id": "evalrun_abc456"
    }

Get an output item of an eval run


-------------------------------------

getÂ https://api.openai.com/v1/evals/{eval\_id}/runs/{run\_id}/output\_items/{output\_item\_id}

Get an evaluation run output item by ID.

#### Path parameters

[](#evals-getrunoutputitem-eval_id)

eval\_id

string

Required

The ID of the evaluation to retrieve runs for.

[](#evals-getrunoutputitem-output_item_id)

output\_item\_id

string

Required

The ID of the output item to retrieve.

[](#evals-getrunoutputitem-run_id)

run\_id

string

Required

The ID of the run to retrieve.

#### Returns

The [EvalRunOutputItem](/docs/api-reference/evals/run-output-item-object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/eval_67abd54d9b0081909a86353f6fb9317a/runs/evalrun_67abd54d60ec8190832b46859da808f7/output_items/outputitem_67abd55eb6548190bb580745d5644a33 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "eval.run.output_item",
      "id": "outputitem_67e5796c28e081909917bf79f6e6214d",
      "created_at": 1743092076,
      "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
      "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "status": "pass",
      "datasource_item_id": 5,
      "datasource_item": {
        "input": "Stock Markets Rally After Positive Economic Data Released",
        "ground_truth": "Markets"
      },
      "results": [
        {
          "name": "String check-a2486074-d803-4445-b431-ad2262e85d47",
          "sample": null,
          "passed": true,
          "score": 1.0
        }
      ],
      "sample": {
        "input": [
          {
            "role": "developer",
            "content": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n",
            "tool_call_id": null,
            "tool_calls": null,
            "function_call": null
          },
          {
            "role": "user",
            "content": "Stock Markets Rally After Positive Economic Data Released",
            "tool_call_id": null,
            "tool_calls": null,
            "function_call": null
          }
        ],
        "output": [
          {
            "role": "assistant",
            "content": "Markets",
            "tool_call_id": null,
            "tool_calls": null,
            "function_call": null
          }
        ],
        "finish_reason": "stop",
        "model": "gpt-4o-mini-2024-07-18",
        "usage": {
          "total_tokens": 325,
          "completion_tokens": 2,
          "prompt_tokens": 323,
          "cached_tokens": 0
        },
        "error": null,
        "temperature": 1.0,
        "max_completion_tokens": 2048,
        "top_p": 1.0,
        "seed": 42
      }
    }

Get eval run output items


-----------------------------

getÂ https://api.openai.com/v1/evals/{eval\_id}/runs/{run\_id}/output\_items

Get a list of output items for an evaluation run.

#### Path parameters

[](#evals-getrunoutputitems-eval_id)

eval\_id

string

Required

The ID of the evaluation to retrieve runs for.

[](#evals-getrunoutputitems-run_id)

run\_id

string

Required

The ID of the run to retrieve output items for.

#### Query parameters

[](#evals-getrunoutputitems-after)

after

string

Optional

Identifier for the last output item from the previous pagination request.

[](#evals-getrunoutputitems-limit)

limit

integer

Optional

Defaults to 20

Number of output items to retrieve.

[](#evals-getrunoutputitems-order)

order

string

Optional

Defaults to asc

Sort order for output items by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.

[](#evals-getrunoutputitems-status)

status

string

Optional

Filter output items by status. Use `failed` to filter by failed output items or `pass` to filter by passed output items.

#### Returns

A list of [EvalRunOutputItem](/docs/api-reference/evals/run-output-item-object) objects matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/evals/egroup_67abd54d9b0081909a86353f6fb9317a/runs/erun_67abd54d60ec8190832b46859da808f7/output_items \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "eval.run.output_item",
          "id": "outputitem_67e5796c28e081909917bf79f6e6214d",
          "created_at": 1743092076,
          "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
          "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
          "status": "pass",
          "datasource_item_id": 5,
          "datasource_item": {
            "input": "Stock Markets Rally After Positive Economic Data Released",
            "ground_truth": "Markets"
          },
          "results": [
            {
              "name": "String check-a2486074-d803-4445-b431-ad2262e85d47",
              "sample": null,
              "passed": true,
              "score": 1.0
            }
          ],
          "sample": {
            "input": [
              {
                "role": "developer",
                "content": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n",
                "tool_call_id": null,
                "tool_calls": null,
                "function_call": null
              },
              {
                "role": "user",
                "content": "Stock Markets Rally After Positive Economic Data Released",
                "tool_call_id": null,
                "tool_calls": null,
                "function_call": null
              }
            ],
            "output": [
              {
                "role": "assistant",
                "content": "Markets",
                "tool_call_id": null,
                "tool_calls": null,
                "function_call": null
              }
            ],
            "finish_reason": "stop",
            "model": "gpt-4o-mini-2024-07-18",
            "usage": {
              "total_tokens": 325,
              "completion_tokens": 2,
              "prompt_tokens": 323,
              "cached_tokens": 0
            },
            "error": null,
            "temperature": 1.0,
            "max_completion_tokens": 2048,
            "top_p": 1.0,
            "seed": 42
          }
        }
      ],
      "first_id": "outputitem_67e5796c28e081909917bf79f6e6214d",
      "last_id": "outputitem_67e5796c28e081909917bf79f6e6214d",
      "has_more": true
    }

The eval object


-------------------

An Eval object with a data source config and testing criteria. An Eval represents a task to be done for your LLM integration. Like:

*   Improve the quality of my chatbot
*   See how well my chatbot handles customer support
*   Check if o3-mini is better at my usecase than gpt-4o

[](#evals/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the eval was created.

[](#evals/object-data_source_config)

data\_source\_config

object

Configuration of data sources used in runs of the evaluation.

Show possible types

[](#evals/object-id)

id

string

Unique identifier for the evaluation.

[](#evals/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#evals/object-name)

name

string

The name of the evaluation.

[](#evals/object-object)

object

string

The object type.

[](#evals/object-testing_criteria)

testing\_criteria

array

A list of testing criteria.

Show possible types

OBJECT The eval object
    {
      "object": "eval",
      "id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "data_source_config": {
        "type": "custom",
        "item_schema": {
          "type": "object",
          "properties": {
            "label": {"type": "string"},
          },
          "required": ["label"]
        },
        "include_sample_schema": true
      },
      "testing_criteria": [
        {
          "name": "My string check grader",
          "type": "string_check",
          "input": "{{sample.output_text}}",
          "reference": "{{item.label}}",
          "operation": "eq",
        }
      ],
      "name": "External Data Eval",
      "created_at": 1739314509,
      "metadata": {
        "test": "synthetics",
      }
    }

The eval run object


-----------------------

A schema representing an evaluation run.

[](#evals/run-object-created_at)

created\_at

integer

Unix timestamp (in seconds) when the evaluation run was created.

[](#evals/run-object-data_source)

data\_source

object

Information about the run's data source.

Show possible types

[](#evals/run-object-error)

error

object

An object representing an error response from the Eval API.

Show properties

[](#evals/run-object-eval_id)

eval\_id

string

The identifier of the associated evaluation.

[](#evals/run-object-id)

id

string

Unique identifier for the evaluation run.

[](#evals/run-object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#evals/run-object-model)

model

string

The model that is evaluated, if applicable.

[](#evals/run-object-name)

name

string

The name of the evaluation run.

[](#evals/run-object-object)

object

string

The type of the object. Always "eval.run".

[](#evals/run-object-per_model_usage)

per\_model\_usage

array

Usage statistics for each model during the evaluation run.

Show properties

[](#evals/run-object-per_testing_criteria_results)

per\_testing\_criteria\_results

array

Results per testing criteria applied during the evaluation run.

Show properties

[](#evals/run-object-report_url)

report\_url

string

The URL to the rendered evaluation run report on the UI dashboard.

[](#evals/run-object-result_counts)

result\_counts

object

Counters summarizing the outcomes of the evaluation run.

Show properties

[](#evals/run-object-status)

status

string

The status of the evaluation run.

OBJECT The eval run object
    {
      "object": "eval.run",
      "id": "evalrun_67e57965b480819094274e3a32235e4c",
      "eval_id": "eval_67e579652b548190aaa83ada4b125f47",
      "report_url": "https://platform.openai.com/evaluations/eval_67e579652b548190aaa83ada4b125f47?run_id=evalrun_67e57965b480819094274e3a32235e4c",
      "status": "queued",
      "model": "gpt-4o-mini",
      "name": "gpt-4o-mini",
      "created_at": 1743092069,
      "result_counts": {
        "total": 0,
        "errored": 0,
        "failed": 0,
        "passed": 0
      },
      "per_model_usage": null,
      "per_testing_criteria_results": null,
      "data_source": {
        "type": "completions",
        "source": {
          "type": "file_content",
          "content": [
            {
              "item": {
                "input": "Tech Company Launches Advanced Artificial Intelligence Platform",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Central Bank Increases Interest Rates Amid Inflation Concerns",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Summit Addresses Climate Change Strategies",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Major Retailer Reports Record-Breaking Holiday Sales",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "National Team Qualifies for World Championship Finals",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Stock Markets Rally After Positive Economic Data Released",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "Global Manufacturer Announces Merger with Competitor",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Breakthrough in Renewable Energy Technology Unveiled",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "World Leaders Sign Historic Climate Agreement",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Professional Athlete Sets New Record in Championship Event",
                "ground_truth": "Sports"
              }
            },
            {
              "item": {
                "input": "Financial Institutions Adapt to New Regulatory Requirements",
                "ground_truth": "Business"
              }
            },
            {
              "item": {
                "input": "Tech Conference Showcases Advances in Artificial Intelligence",
                "ground_truth": "Technology"
              }
            },
            {
              "item": {
                "input": "Global Markets Respond to Oil Price Fluctuations",
                "ground_truth": "Markets"
              }
            },
            {
              "item": {
                "input": "International Cooperation Strengthened Through New Treaty",
                "ground_truth": "World"
              }
            },
            {
              "item": {
                "input": "Sports League Announces Revised Schedule for Upcoming Season",
                "ground_truth": "Sports"
              }
            }
          ]
        },
        "input_messages": {
          "type": "template",
          "template": [
            {
              "type": "message",
              "role": "developer",
              "content": {
                "type": "input_text",
                "text": "Categorize a given news headline into one of the following topics: Technology, Markets, World, Business, or Sports.\n\n# Steps\n\n1. Analyze the content of the news headline to understand its primary focus.\n2. Extract the subject matter, identifying any key indicators or keywords.\n3. Use the identified indicators to determine the most suitable category out of the five options: Technology, Markets, World, Business, or Sports.\n4. Ensure only one category is selected per headline.\n\n# Output Format\n\nRespond with the chosen category as a single word. For instance: \"Technology\", \"Markets\", \"World\", \"Business\", or \"Sports\".\n\n# Examples\n\n**Input**: \"Apple Unveils New iPhone Model, Featuring Advanced AI Features\"  \n**Output**: \"Technology\"\n\n**Input**: \"Global Stocks Mixed as Investors Await Central Bank Decisions\"  \n**Output**: \"Markets\"\n\n**Input**: \"War in Ukraine: Latest Updates on Negotiation Status\"  \n**Output**: \"World\"\n\n**Input**: \"Microsoft in Talks to Acquire Gaming Company for $2 Billion\"  \n**Output**: \"Business\"\n\n**Input**: \"Manchester United Secures Win in Premier League Football Match\"  \n**Output**: \"Sports\" \n\n# Notes\n\n- If the headline appears to fit into more than one category, choose the most dominant theme.\n- Keywords or phrases such as \"stocks\", \"company acquisition\", \"match\", or technological brands can be good indicators for classification.\n"
              }
            },
            {
              "type": "message",
              "role": "user",
              "content": {
                "type": "input_text",
                "text": "{{item.input}}"
              }
            }
          ]
        },
        "model": "gpt-4o-mini",
        "sampling_params": {
          "seed": 42,
          "temperature": 1.0,
          "top_p": 1.0,
          "max_completions_tokens": 2048
        }
      },
      "error": null,
      "metadata": {}
    }

The eval run output item object


-----------------------------------

A schema representing an evaluation run output item.

[](#evals/run-output-item-object-created_at)

created\_at

integer

Unix timestamp (in seconds) when the evaluation run was created.

[](#evals/run-output-item-object-datasource_item)

datasource\_item

object

Details of the input data source item.

[](#evals/run-output-item-object-datasource_item_id)

datasource\_item\_id

integer

The identifier for the data source item.

[](#evals/run-output-item-object-eval_id)

eval\_id

string

The identifier of the evaluation group.

[](#evals/run-output-item-object-id)

id

string

Unique identifier for the evaluation run output item.

[](#evals/run-output-item-object-object)

object

string

The type of the object. Always "eval.run.output\_item".

[](#evals/run-output-item-object-results)

results

array

A list of results from the evaluation run.

Show properties

[](#evals/run-output-item-object-run_id)

run\_id

string

The identifier of the evaluation run associated with this output item.

[](#evals/run-output-item-object-sample)

sample

object

A sample containing the input and output of the evaluation run.

Show properties

[](#evals/run-output-item-object-status)

status

string

The status of the evaluation run.

OBJECT The eval run output item object
    {
      "object": "eval.run.output_item",
      "id": "outputitem_67abd55eb6548190bb580745d5644a33",
      "run_id": "evalrun_67abd54d60ec8190832b46859da808f7",
      "eval_id": "eval_67abd54d9b0081909a86353f6fb9317a",
      "created_at": 1739314509,
      "status": "pass",
      "datasource_item_id": 137,
      "datasource_item": {
          "teacher": "To grade essays, I only check for style, content, and grammar.",
          "student": "I am a student who is trying to write the best essay."
      },
      "results": [
        {
          "name": "String Check Grader",
          "type": "string-check-grader",
          "score": 1.0,
          "passed": true,
        }
      ],
      "sample": {
        "input": [
          {
            "role": "system",
            "content": "You are an evaluator bot..."
          },
          {
            "role": "user",
            "content": "You are assessing..."
          }
        ],
        "output": [
          {
            "role": "assistant",
            "content": "The rubric is not clear nor concise."
          }
        ],
        "finish_reason": "stop",
        "model": "gpt-4o-2024-08-06",
        "usage": {
          "total_tokens": 521,
          "completion_tokens": 2,
          "prompt_tokens": 519,
          "cached_tokens": 0
        },
        "error": null,
        "temperature": 1.0,
        "max_completion_tokens": 2048,
        "top_p": 1.0,
        "seed": 42
      }
    }

Fine-tuning


---------------

Manage fine-tuning jobs to tailor a model to your specific training data. Related guide: [Fine-tune models](/docs/guides/fine-tuning)

Create fine-tuning job


--------------------------

postÂ https://api.openai.com/v1/fine\_tuning/jobs

Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

#### Request body

[](#fine-tuning-create-model)

model

string

Required

The name of the model to fine-tune. You can select one of the [supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).

[](#fine-tuning-create-training_file)

training\_file

string

Required

The ID of an uploaded file that contains training data.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input), [completions](/docs/api-reference/fine-tuning/completions-input) format, or if the fine-tuning method uses the [preference](/docs/api-reference/fine-tuning/preference-input) format.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

[](#fine-tuning-create-hyperparameters)

hyperparameters

Deprecated

object

Optional

The hyperparameters used for the fine-tuning job. This value is now deprecated in favor of `method`, and should be passed in under the `method` parameter.

Show properties

[](#fine-tuning-create-integrations)

integrations

array or null

Optional

A list of integrations to enable for your fine-tuning job.

Show properties

[](#fine-tuning-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#fine-tuning-create-method)

method

object

Optional

The method used for fine-tuning.

Show properties

[](#fine-tuning-create-seed)

seed

integer or null

Optional

The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases. If a seed is not specified, one will be generated for you.

[](#fine-tuning-create-suffix)

suffix

string or null

Optional

Defaults to null

A string of up to 64 characters that will be added to your fine-tuned model name.

For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.

[](#fine-tuning-create-validation_file)

validation\_file

string or null

Optional

The ID of an uploaded file that contains validation data.

If you provide this file, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in the fine-tuning results file. The same data should not be present in both train and validation files.

Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

#### Returns

A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.

DefaultDefaultEpochsEpochsDPODPOReinforcementReinforcementValidation fileValidation fileW&B IntegrationW&B Integration

Example request

node.js
    curl https://api.openai.com/v1/fine_tuning/jobs \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
        "model": "gpt-4o-mini"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.create(
      training_file="file-abc123",
      model="gpt-4o-mini"
    )
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const fineTune = await openai.fineTuning.jobs.create({
        training_file: "file-abc123"
      });
    
      console.log(fineTune);
    }
    
    main();

Response
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "gpt-4o-mini-2024-07-18",
      "created_at": 1721764800,
      "fine_tuned_model": null,
      "organization_id": "org-123",
      "result_files": [],
      "status": "queued",
      "validation_file": null,
      "training_file": "file-abc123",
      "method": {
        "type": "supervised",
        "supervised": {
          "hyperparameters": {
            "batch_size": "auto",
            "learning_rate_multiplier": "auto",
            "n_epochs": "auto",
          }
        }
      },
      "metadata": null
    }

List fine-tuning jobs


-------------------------

getÂ https://api.openai.com/v1/fine\_tuning/jobs

List your organization's fine-tuning jobs

#### Query parameters

[](#fine-tuning-list-after)

after

string

Optional

Identifier for the last job from the previous pagination request.

[](#fine-tuning-list-limit)

limit

integer

Optional

Defaults to 20

Number of fine-tuning jobs to retrieve.

[](#fine-tuning-list-metadata)

metadata

object or null

Optional

Optional metadata filter. To filter, use the syntax `metadata[k]=v`. Alternatively, set `metadata=null` to indicate no metadata.

#### Returns

A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/fine_tuning/jobs?limit=2&metadata[key]=value \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.list()
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const list = await openai.fineTuning.jobs.list();
    
      for await (const fineTune of list) {
        console.log(fineTune);
      }
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "object": "fine_tuning.job",
          "id": "ftjob-abc123",
          "model": "gpt-4o-mini-2024-07-18",
          "created_at": 1721764800,
          "fine_tuned_model": null,
          "organization_id": "org-123",
          "result_files": [],
          "status": "queued",
          "validation_file": null,
          "training_file": "file-abc123",
          "metadata": {
            "key": "value"
          }
        },
        { ... },
        { ... }
      ], "has_more": true
    }

List fine-tuning events


---------------------------

getÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/events

Get status updates for a fine-tuning job.

#### Path parameters

[](#fine-tuning-list-events-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get events for.

#### Query parameters

[](#fine-tuning-list-events-after)

after

string

Optional

Identifier for the last event from the previous pagination request.

[](#fine-tuning-list-events-limit)

limit

integer

Optional

Defaults to 20

Number of events to retrieve.

#### Returns

A list of fine-tuning event objects.

Example request

node.js
    curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.list_events(
      fine_tuning_job_id="ftjob-abc123",
      limit=2
    )
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const list = await openai.fineTuning.list_events(id="ftjob-abc123", limit=2);
    
      for await (const fineTune of list) {
        console.log(fineTune);
      }
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "object": "fine_tuning.job.event",
          "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",
          "created_at": 1721764800,
          "level": "info",
          "message": "Fine tuning job successfully completed",
          "data": null,
          "type": "message"
        },
        {
          "object": "fine_tuning.job.event",
          "id": "ft-event-tyiGuB72evQncpH87xe505Sv",
          "created_at": 1721764800,
          "level": "info",
          "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",
          "data": null,
          "type": "message"
        }
      ],
      "has_more": true
    }

List fine-tuning checkpoints


--------------------------------

getÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/checkpoints

List checkpoints for a fine-tuning job.

#### Path parameters

[](#fine-tuning-list-checkpoints-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get checkpoints for.

#### Query parameters

[](#fine-tuning-list-checkpoints-after)

after

string

Optional

Identifier for the last checkpoint ID from the previous pagination request.

[](#fine-tuning-list-checkpoints-limit)

limit

integer

Optional

Defaults to 10

Number of checkpoints to retrieve.

#### Returns

A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object) for a fine-tuning job.

Example request

curl
    curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
      -H "Authorization: Bearer $OPENAI_API_KEY"

Response
    {
      "object": "list"
      "data": [
        {
          "object": "fine_tuning.job.checkpoint",
          "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
          "created_at": 1721764867,
          "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",
          "metrics": {
            "full_valid_loss": 0.134,
            "full_valid_mean_token_accuracy": 0.874
          },
          "fine_tuning_job_id": "ftjob-abc123",
          "step_number": 2000,
        },
        {
          "object": "fine_tuning.job.checkpoint",
          "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
          "created_at": 1721764800,
          "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",
          "metrics": {
            "full_valid_loss": 0.167,
            "full_valid_mean_token_accuracy": 0.781
          },
          "fine_tuning_job_id": "ftjob-abc123",
          "step_number": 1000,
        },
      ],
      "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
      "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
      "has_more": true
    }

List checkpoint permissions


-------------------------------

getÂ https://api.openai.com/v1/fine\_tuning/checkpoints/{fine\_tuned\_model\_checkpoint}/permissions

**NOTE:** This endpoint requires an [admin API key](../admin-api-keys).

Organization owners can use this endpoint to view all permissions for a fine-tuned model checkpoint.

#### Path parameters

[](#fine-tuning-list-permissions-fine_tuned_model_checkpoint)

fine\_tuned\_model\_checkpoint

string

Required

The ID of the fine-tuned model checkpoint to get permissions for.

#### Query parameters

[](#fine-tuning-list-permissions-after)

after

string

Optional

Identifier for the last permission ID from the previous pagination request.

[](#fine-tuning-list-permissions-limit)

limit

integer

Optional

Defaults to 10

Number of permissions to retrieve.

[](#fine-tuning-list-permissions-order)

order

string

Optional

Defaults to descending

The order in which to retrieve permissions.

[](#fine-tuning-list-permissions-project_id)

project\_id

string

Optional

The ID of the project to get permissions for.

#### Returns

A list of fine-tuned model checkpoint [permission objects](/docs/api-reference/fine-tuning/permission-object) for a fine-tuned model checkpoint.

Example request

curl
    curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \
      -H "Authorization: Bearer $OPENAI_API_KEY"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "checkpoint.permission",
          "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
          "created_at": 1721764867,
          "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
        },
        {
          "object": "checkpoint.permission",
          "id": "cp_enQCFmOTGj3syEpYVhBRLTSy",
          "created_at": 1721764800,
          "project_id": "proj_iqGMw1llN8IrBb6SvvY5A1oF"
        },
      ],
      "first_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
      "last_id": "cp_enQCFmOTGj3syEpYVhBRLTSy",
      "has_more": false
    }

Create checkpoint permissions


---------------------------------

postÂ https://api.openai.com/v1/fine\_tuning/checkpoints/{fine\_tuned\_model\_checkpoint}/permissions

**NOTE:** Calling this endpoint requires an [admin API key](../admin-api-keys).

This enables organization owners to share fine-tuned models with other projects in their organization.

#### Path parameters

[](#fine-tuning-create-permission-fine_tuned_model_checkpoint)

fine\_tuned\_model\_checkpoint

string

Required

The ID of the fine-tuned model checkpoint to create a permission for.

#### Request body

[](#fine-tuning-create-permission-project_ids)

project\_ids

array

Required

The project identifiers to grant access to.

#### Returns

A list of fine-tuned model checkpoint [permission objects](/docs/api-reference/fine-tuning/permission-object) for a fine-tuned model checkpoint.

Example request

curl
    curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions \
      -H "Authorization: Bearer $OPENAI_API_KEY"
      -d '{"project_ids": ["proj_abGMw1llN8IrBb6SvvY5A1iH"]}'

Response
    {
      "object": "list",
      "data": [
        {
          "object": "checkpoint.permission",
          "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
          "created_at": 1721764867,
          "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
        }
      ],
      "first_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
      "last_id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
      "has_more": false
    }

Delete checkpoint permission


--------------------------------

deleteÂ https://api.openai.com/v1/fine\_tuning/checkpoints/{fine\_tuned\_model\_checkpoint}/permissions/{permission\_id}

**NOTE:** This endpoint requires an [admin API key](../admin-api-keys).

Organization owners can use this endpoint to delete a permission for a fine-tuned model checkpoint.

#### Path parameters

[](#fine-tuning-delete-permission-fine_tuned_model_checkpoint)

fine\_tuned\_model\_checkpoint

string

Required

The ID of the fine-tuned model checkpoint to delete a permission for.

[](#fine-tuning-delete-permission-permission_id)

permission\_id

string

Required

The ID of the fine-tuned model checkpoint permission to delete.

#### Returns

The deletion status of the fine-tuned model checkpoint [permission object](/docs/api-reference/fine-tuning/permission-object).

Example request

curl
    curl https://api.openai.com/v1/fine_tuning/checkpoints/ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd/permissions/cp_zc4Q7MP6XxulcVzj4MZdwsAB \
      -H "Authorization: Bearer $OPENAI_API_KEY"

Response
    {
      "object": "checkpoint.permission",
      "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
      "deleted": true
    }

Retrieve fine-tuning job


----------------------------

getÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}

Get info about a fine-tuning job.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

#### Path parameters

[](#fine-tuning-retrieve-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job.

#### Returns

The [fine-tuning](/docs/api-reference/fine-tuning/object) object with the given ID.

Example request

node.js
    curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.retrieve("ftjob-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const fineTune = await openai.fineTuning.jobs.retrieve("ftjob-abc123");
    
      console.log(fineTune);
    }
    
    main();

Response
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "davinci-002",
      "created_at": 1692661014,
      "finished_at": 1692661190,
      "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
      "organization_id": "org-123",
      "result_files": [
          "file-abc123"
      ],
      "status": "succeeded",
      "validation_file": null,
      "training_file": "file-abc123",
      "hyperparameters": {
          "n_epochs": 4,
          "batch_size": 1,
          "learning_rate_multiplier": 1.0
      },
      "trained_tokens": 5768,
      "integrations": [],
      "seed": 0,
      "estimated_finish": 0,
      "method": {
        "type": "supervised",
        "supervised": {
          "hyperparameters": {
            "n_epochs": 4,
            "batch_size": 1,
            "learning_rate_multiplier": 1.0
          }
        }
      }
    }

Cancel fine-tuning


----------------------

postÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/cancel

Immediately cancel a fine-tune job.

#### Path parameters

[](#fine-tuning-cancel-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to cancel.

#### Returns

The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

node.js
    curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.cancel("ftjob-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const fineTune = await openai.fineTuning.jobs.cancel("ftjob-abc123");
    
      console.log(fineTune);
    }
    main();

Response
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "gpt-4o-mini-2024-07-18",
      "created_at": 1721764800,
      "fine_tuned_model": null,
      "organization_id": "org-123",
      "result_files": [],
      "status": "cancelled",
      "validation_file": "file-abc123",
      "training_file": "file-abc123"
    }

Resume fine-tuning


----------------------

postÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/resume

Resume a fine-tune job.

#### Path parameters

[](#fine-tuning-resume-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to resume.

#### Returns

The resumed [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

node.js
    curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/resume \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.resume("ftjob-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const fineTune = await openai.fineTuning.jobs.resume("ftjob-abc123");
    
      console.log(fineTune);
    }
    main();

Response
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "gpt-4o-mini-2024-07-18",
      "created_at": 1721764800,
      "fine_tuned_model": null,
      "organization_id": "org-123",
      "result_files": [],
      "status": "queued",
      "validation_file": "file-abc123",
      "training_file": "file-abc123"
    }

Pause fine-tuning


---------------------

postÂ https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/pause

Pause a fine-tune job.

#### Path parameters

[](#fine-tuning-pause-fine_tuning_job_id)

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to pause.

#### Returns

The paused [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

node.js
    curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/pause \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.fine_tuning.jobs.pause("ftjob-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const fineTune = await openai.fineTuning.jobs.pause("ftjob-abc123");
    
      console.log(fineTune);
    }
    main();

Response
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "gpt-4o-mini-2024-07-18",
      "created_at": 1721764800,
      "fine_tuned_model": null,
      "organization_id": "org-123",
      "result_files": [],
      "status": "paused",
      "validation_file": "file-abc123",
      "training_file": "file-abc123"
    }

Training format for chat models using the supervised method


---------------------------------------------------------------

The per-line training example of a fine-tuning input file for chat models using the supervised method.

[](#fine-tuning/chat-input-functions)

functions

Deprecated

array

A list of functions the model may generate JSON inputs for.

Show properties

[](#fine-tuning/chat-input-messages)

messages

array

Show possible types

[](#fine-tuning/chat-input-parallel_tool_calls)

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

[](#fine-tuning/chat-input-tools)

tools

array

A list of tools the model may generate JSON inputs for.

Show properties

OBJECT Training format for chat models using the supervised method
    {
      "messages": [
        { "role": "user", "content": "What is the weather in San Francisco?" },
        {
          "role": "assistant",
          "tool_calls": [
            {
              "id": "call_id",
              "type": "function",
              "function": {
                "name": "get_current_weather",
                "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"
              }
            }
          ]
        }
      ],
      "parallel_tool_calls": false,
      "tools": [
        {
          "type": "function",
          "function": {
            "name": "get_current_weather",
            "description": "Get the current weather",
            "parameters": {
              "type": "object",
              "properties": {
                "location": {
                    "type": "string",
                    "description": "The city and country, eg. San Francisco, USA"
                },
                "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }
              },
              "required": ["location", "format"]
            }
          }
        }
      ]
    }

Training format for chat models using the preference method


---------------------------------------------------------------

The per-line training example of a fine-tuning input file for chat models using the dpo method.

[](#fine-tuning/preference-input-input)

input

object

Show properties

[](#fine-tuning/preference-input-non_preferred_completion)

non\_preferred\_completion

array

The non-preferred completion message for the output.

Show possible types

[](#fine-tuning/preference-input-preferred_completion)

preferred\_completion

array

The preferred completion message for the output.

Show possible types

OBJECT Training format for chat models using the preference method
    {
      "input": {
        "messages": [
          { "role": "user", "content": "What is the weather in San Francisco?" }
        ]
      },
      "preferred_completion": [
        {
          "role": "assistant",
          "content": "The weather in San Francisco is 70 degrees Fahrenheit."
        }
      ],
      "non_preferred_completion": [
        {
          "role": "assistant",
          "content": "The weather in San Francisco is 21 degrees Celsius."
        }
      ]
    }

Training format for reasoning models using the reinforcement method


-----------------------------------------------------------------------

Per-line training example for reinforcement fine-tuning. Note that `messages` and `tools` are the only reserved keywords. Any other arbitrary key-value data can be included on training datapoints and will be available to reference during grading under the `{{ item.XXX }}` template variable.

[](#fine-tuning/reinforcement-input-messages)

messages

array

Show possible types

[](#fine-tuning/reinforcement-input-tools)

tools

array

A list of tools the model may generate JSON inputs for.

Show properties

OBJECT Training format for reasoning models using the reinforcement method
    {
      "messages": [
        {
          "role": "user",
          "content": "Your task is to take a chemical in SMILES format and predict the number of hydrobond bond donors and acceptors according to Lipinkski's rule. CCN(CC)CCC(=O)c1sc(N)nc1C"
        },
      ],
      # Any other JSON data can be inserted into an example and referenced during RFT grading
      "reference_answer": {
        "donor_bond_counts": 5,
        "acceptor_bond_counts": 7
      }
    }

The fine-tuning job object


------------------------------

The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.

[](#fine-tuning/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

[](#fine-tuning/object-error)

error

object or null

For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.

Show properties

[](#fine-tuning/object-estimated_finish)

estimated\_finish

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.

[](#fine-tuning/object-fine_tuned_model)

fine\_tuned\_model

string or null

The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.

[](#fine-tuning/object-finished_at)

finished\_at

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.

[](#fine-tuning/object-hyperparameters)

hyperparameters

object

The hyperparameters used for the fine-tuning job. This value will only be returned when running `supervised` jobs.

Show properties

[](#fine-tuning/object-id)

id

string

The object identifier, which can be referenced in the API endpoints.

[](#fine-tuning/object-integrations)

integrations

array or null

A list of integrations to enable for this fine-tuning job.

Show possible types

[](#fine-tuning/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#fine-tuning/object-method)

method

object

The method used for fine-tuning.

Show properties

[](#fine-tuning/object-model)

model

string

The base model that is being fine-tuned.

[](#fine-tuning/object-object)

object

string

The object type, which is always "fine\_tuning.job".

[](#fine-tuning/object-organization_id)

organization\_id

string

The organization that owns the fine-tuning job.

[](#fine-tuning/object-result_files)

result\_files

array

The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).

[](#fine-tuning/object-seed)

seed

integer

The seed used for the fine-tuning job.

[](#fine-tuning/object-status)

status

string

The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.

[](#fine-tuning/object-trained_tokens)

trained\_tokens

integer or null

The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.

[](#fine-tuning/object-training_file)

training\_file

string

The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents).

[](#fine-tuning/object-validation_file)

validation\_file

string or null

The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents).

OBJECT The fine-tuning job object
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "davinci-002",
      "created_at": 1692661014,
      "finished_at": 1692661190,
      "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
      "organization_id": "org-123",
      "result_files": [
          "file-abc123"
      ],
      "status": "succeeded",
      "validation_file": null,
      "training_file": "file-abc123",
      "hyperparameters": {
          "n_epochs": 4,
          "batch_size": 1,
          "learning_rate_multiplier": 1.0
      },
      "trained_tokens": 5768,
      "integrations": [],
      "seed": 0,
      "estimated_finish": 0,
      "method": {
        "type": "supervised",
        "supervised": {
          "hyperparameters": {
            "n_epochs": 4,
            "batch_size": 1,
            "learning_rate_multiplier": 1.0
          }
        }
      },
      "metadata": {
        "key": "value"
      }
    }

The fine-tuning job event object


------------------------------------

Fine-tuning job event object

[](#fine-tuning/event-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

[](#fine-tuning/event-object-data)

data

object

The data associated with the event.

[](#fine-tuning/event-object-id)

id

string

The object identifier.

[](#fine-tuning/event-object-level)

level

string

The log level of the event.

[](#fine-tuning/event-object-message)

message

string

The message of the event.

[](#fine-tuning/event-object-object)

object

string

The object type, which is always "fine\_tuning.job.event".

[](#fine-tuning/event-object-type)

type

string

The type of event.

OBJECT The fine-tuning job event object
    {
      "object": "fine_tuning.job.event",
      "id": "ftevent-abc123"
      "created_at": 1677610602,
      "level": "info",
      "message": "Created fine-tuning job",
      "data": {},
      "type": "message"
    }

The fine-tuning job checkpoint object


-----------------------------------------

The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.

[](#fine-tuning/checkpoint-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the checkpoint was created.

[](#fine-tuning/checkpoint-object-fine_tuned_model_checkpoint)

fine\_tuned\_model\_checkpoint

string

The name of the fine-tuned checkpoint model that is created.

[](#fine-tuning/checkpoint-object-fine_tuning_job_id)

fine\_tuning\_job\_id

string

The name of the fine-tuning job that this checkpoint was created from.

[](#fine-tuning/checkpoint-object-id)

id

string

The checkpoint identifier, which can be referenced in the API endpoints.

[](#fine-tuning/checkpoint-object-metrics)

metrics

object

Metrics at the step number during the fine-tuning job.

Show properties

[](#fine-tuning/checkpoint-object-object)

object

string

The object type, which is always "fine\_tuning.job.checkpoint".

[](#fine-tuning/checkpoint-object-step_number)

step\_number

integer

The step number that the checkpoint was created at.

OBJECT The fine-tuning job checkpoint object
    {
      "object": "fine_tuning.job.checkpoint",
      "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
      "created_at": 1712211699,
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
      "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
      "metrics": {
        "step": 88,
        "train_loss": 0.478,
        "train_mean_token_accuracy": 0.924,
        "valid_loss": 10.112,
        "valid_mean_token_accuracy": 0.145,
        "full_valid_loss": 0.567,
        "full_valid_mean_token_accuracy": 0.944
      },
      "step_number": 88
    }

The fine-tuned model checkpoint permission object


-----------------------------------------------------

The `checkpoint.permission` object represents a permission for a fine-tuned model checkpoint.

[](#fine-tuning/permission-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the permission was created.

[](#fine-tuning/permission-object-id)

id

string

The permission identifier, which can be referenced in the API endpoints.

[](#fine-tuning/permission-object-object)

object

string

The object type, which is always "checkpoint.permission".

[](#fine-tuning/permission-object-project_id)

project\_id

string

The project identifier that the permission is for.

OBJECT The fine-tuned model checkpoint permission object
    {
      "object": "checkpoint.permission",
      "id": "cp_zc4Q7MP6XxulcVzj4MZdwsAB",
      "created_at": 1712211699,
      "project_id": "proj_abGMw1llN8IrBb6SvvY5A1iH"
    }

Graders


-----------

Manage and run graders in the OpenAI platform. Related guide: [Graders](/docs/guides/graders)

String Check Grader


-----------------------

A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.

[](#graders/string-check-input)

input

string

The input text. This may include template strings.

[](#graders/string-check-name)

name

string

The name of the grader.

[](#graders/string-check-operation)

operation

string

The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.

[](#graders/string-check-reference)

reference

string

The reference text. This may include template strings.

[](#graders/string-check-type)

type

string

The object type, which is always `string_check`.

OBJECT String Check Grader
    {
      "type": "string_check",
      "name": "Example string check grader",
      "input": "{{sample.output_text}}",
      "reference": "{{item.label}}",
      "operation": "eq"
    }

Text Similarity Grader


--------------------------

A TextSimilarityGrader object which grades text based on similarity metrics.

[](#graders/text-similarity-evaluation_metric)

evaluation\_metric

string

The evaluation metric to use. One of `fuzzy_match`, `bleu`, `gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`, or `rouge_l`.

[](#graders/text-similarity-input)

input

string

The text being graded.

[](#graders/text-similarity-name)

name

string

The name of the grader.

[](#graders/text-similarity-reference)

reference

string

The text being graded against.

[](#graders/text-similarity-type)

type

string

The type of grader.

OBJECT Text Similarity Grader
    {
      "type": "text_similarity",
      "name": "Example text similarity grader",
      "input": "{{sample.output_text}}",
      "reference": "{{item.label}}",
      "evaluation_metric": "fuzzy_match"
    }

Score Model Grader


----------------------

A ScoreModelGrader object that uses a model to assign a score to the input.

[](#graders/score-model-input)

input

array

The input text. This may include template strings.

Show properties

[](#graders/score-model-model)

model

string

The model to use for the evaluation.

[](#graders/score-model-name)

name

string

The name of the grader.

[](#graders/score-model-range)

range

array

The range of the score. Defaults to `[0, 1]`.

[](#graders/score-model-sampling_params)

sampling\_params

object

The sampling parameters for the model.

[](#graders/score-model-type)

type

string

The object type, which is always `score_model`.

OBJECT Score Model Grader
    {
        "type": "score_model",
        "name": "Example score model grader",
        "input": [
            {
                "role": "user",
                "content": (
                    "Score how close the reference answer is to the model answer. Score 1.0 if they are the same and 0.0 if they are different."
                    " Return just a floating point score\n\n"
                    " Reference answer: {{item.label}}\n\n"
                    " Model answer: {{sample.output_text}}"
                ),
            }
        ],
        "model": "gpt-4o-2024-08-06",
        "sampling_params": {
            "temperature": 1,
            "top_p": 1,
            "seed": 42,
        },
    }

Label Model Grader


----------------------

A LabelModelGrader object which uses a model to assign labels to each item in the evaluation.

[](#graders/label-model-input)

input

array

Show properties

[](#graders/label-model-labels)

labels

array

The labels to assign to each item in the evaluation.

[](#graders/label-model-model)

model

string

The model to use for the evaluation. Must support structured outputs.

[](#graders/label-model-name)

name

string

The name of the grader.

[](#graders/label-model-passing_labels)

passing\_labels

array

The labels that indicate a passing result. Must be a subset of labels.

[](#graders/label-model-type)

type

string

The object type, which is always `label_model`.

OBJECT Label Model Grader
    {
      "name": "First label grader",
      "type": "label_model",
      "model": "gpt-4o-2024-08-06",
      "input": [
        {
          "type": "message",
          "role": "system",
          "content": {
            "type": "input_text",
            "text": "Classify the sentiment of the following statement as one of positive, neutral, or negative"
          }
        },
        {
          "type": "message",
          "role": "user",
          "content": {
            "type": "input_text",
            "text": "Statement: {{item.response}}"
          }
        }
      ],
      "passing_labels": [
        "positive"
      ],
      "labels": [
        "positive",
        "neutral",
        "negative"
      ]
    }

Python Grader


-----------------

A PythonGrader object that runs a python script on the input.

[](#graders/python-image_tag)

image\_tag

string

The image tag to use for the python script.

[](#graders/python-name)

name

string

The name of the grader.

[](#graders/python-source)

source

string

The source code of the python script.

[](#graders/python-type)

type

string

The object type, which is always `python`.

OBJECT Python Grader
    {
      "type": "python",
      "name": "Example python grader",
      "image_tag": "2025-05-08",
      "source": """
    def grade(sample: dict, item: dict) -> float:
        \"""
        Returns 1.0 if `output_text` equals `label`, otherwise 0.0.
        \"""
        output = sample.get("output_text")
        label = item.get("label")
        return 1.0 if output == label else 0.0
    """,
    }

Multi Grader


----------------

A MultiGrader object combines the output of multiple graders to produce a single score.

[](#graders/multi-calculate_output)

calculate\_output

string

A formula to calculate the output based on grader results.

[](#graders/multi-graders)

graders

object

[](#graders/multi-name)

name

string

The name of the grader.

[](#graders/multi-type)

type

string

The type of grader.

OBJECT Multi Grader
    {
      "type": "multi",
      "name": "example multi grader",
      "graders": [
        {
          "type": "text_similarity",
          "name": "example text similarity grader",
          "input": "The graded text",
          "reference": "The reference text",
          "evaluation_metric": "fuzzy_match"
        },
        {
          "type": "string_check",
          "name": "Example string check grader",
          "input": "{{sample.output_text}}",
          "reference": "{{item.label}}",
          "operation": "eq"
        }
      ],
      "calculate_output": "0.5 * text_similarity_score +  0.5 * string_check_score)"
    }

Run grader

Beta


--------------------

postÂ https://api.openai.com/v1/fine\_tuning/alpha/graders/run

Run a grader.

#### Request body

[](#graders-run-grader)

grader

object

Required

The grader used for the fine-tuning job.

Show possible types

[](#graders-run-model_sample)

model\_sample

string

Required

The model sample to be evaluated.

[](#graders-run-reference_answer)

reference\_answer

string / object / array / number

Required

The reference answer for the evaluation.

Show possible types

#### Returns

The results from the grader run.

Example request

curl
    curl -X POST https://api.openai.com/v1/fine_tuning/alpha/graders/run \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "grader": {
          "type": "score_model",
          "name": "Example score model grader",
          "input": [
            {
              "role": "user",
              "content": "Score how close the reference answer is to the model answer. Score 1.0 if they are the same and 0.0 if they are different. Return just a floating point score\n\nReference answer: {{item.reference_answer}}\n\nModel answer: {{sample.output_text}}"
            }
          ],
          "model": "gpt-4o-2024-08-06",
          "sampling_params": {
            "temperature": 1,
            "top_p": 1,
            "seed": 42
          }
        },
        "reference_answer": "fuzzy wuzzy was a bear",
        "model_sample": "fuzzy wuzzy was a bear"
      }'

Response
    {
      "reward": 1.0,
      "metadata": {
        "name": "Example score model grader",
        "type": "score_model",
        "errors": {
          "formula_parse_error": false,
          "sample_parse_error": false,
          "truncated_observation_error": false,
          "unresponsive_reward_error": false,
          "invalid_variable_error": false,
          "other_error": false,
          "python_grader_server_error": false,
          "python_grader_server_error_type": null,
          "python_grader_runtime_error": false,
          "python_grader_runtime_error_details": null,
          "model_grader_server_error": false,
          "model_grader_refusal_error": false,
          "model_grader_parse_error": false,
          "model_grader_server_error_details": null
        },
        "execution_time": 4.365238428115845,
        "scores": {},
        "token_usage": {
          "prompt_tokens": 190,
          "total_tokens": 324,
          "completion_tokens": 134,
          "cached_tokens": 0
        },
        "sampled_model_name": "gpt-4o-2024-08-06"
      },
      "sub_rewards": {},
      "model_grader_token_usage_per_model": {
        "gpt-4o-2024-08-06": {
          "prompt_tokens": 190,
          "total_tokens": 324,
          "completion_tokens": 134,
          "cached_tokens": 0
        }
      }
    }

Validate grader

Beta


-------------------------

postÂ https://api.openai.com/v1/fine\_tuning/alpha/graders/validate

Validate a grader.

#### Request body

[](#graders-validate-grader)

grader

object

Required

The grader used for the fine-tuning job.

Show possible types

#### Returns

The validated grader object.

Example request

curl
    curl https://api.openai.com/v1/fine_tuning/alpha/graders/validate \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "grader": {
          "type": "string_check",
          "name": "Example string check grader",
          "input": "{{sample.output_text}}",
          "reference": "{{item.label}}",
          "operation": "eq"
        }
      }'

Response
    {
      "grader": {
        "type": "string_check",
        "name": "Example string check grader",
        "input": "{{sample.output_text}}",
        "reference": "{{item.label}}",
        "operation": "eq"
      }
    }

Batch


---------

Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount. Related guide: [Batch](/docs/guides/batch)

Create batch


----------------

postÂ https://api.openai.com/v1/batches

Creates and executes a batch from an uploaded file of requests

#### Request body

[](#batch-create-completion_window)

completion\_window

string

Required

The time frame within which the batch should be processed. Currently only `24h` is supported.

[](#batch-create-endpoint)

endpoint

string

Required

The endpoint to be used for all requests in the batch. Currently `/v1/responses`, `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.

[](#batch-create-input_file_id)

input\_file\_id

string

Required

The ID of an uploaded file that contains requests for the new batch.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.

[](#batch-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

#### Returns

The created [Batch](/docs/api-reference/batch/object) object.

Example request

curl
    curl https://api.openai.com/v1/batches \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "input_file_id": "file-abc123",
        "endpoint": "/v1/chat/completions",
        "completion_window": "24h"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    client.batches.create(
      input_file_id="file-abc123",
      endpoint="/v1/chat/completions",
      completion_window="24h"
    )
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const batch = await openai.batches.create({
        input_file_id: "file-abc123",
        endpoint: "/v1/chat/completions",
        completion_window: "24h"
      });
    
      console.log(batch);
    }
    
    main();

Response
    {
      "id": "batch_abc123",
      "object": "batch",
      "endpoint": "/v1/chat/completions",
      "errors": null,
      "input_file_id": "file-abc123",
      "completion_window": "24h",
      "status": "validating",
      "output_file_id": null,
      "error_file_id": null,
      "created_at": 1711471533,
      "in_progress_at": null,
      "expires_at": null,
      "finalizing_at": null,
      "completed_at": null,
      "failed_at": null,
      "expired_at": null,
      "cancelling_at": null,
      "cancelled_at": null,
      "request_counts": {
        "total": 0,
        "completed": 0,
        "failed": 0
      },
      "metadata": {
        "customer_id": "user_123456789",
        "batch_description": "Nightly eval job",
      }
    }

Retrieve batch


------------------

getÂ https://api.openai.com/v1/batches/{batch\_id}

Retrieves a batch.

#### Path parameters

[](#batch-retrieve-batch_id)

batch\_id

string

Required

The ID of the batch to retrieve.

#### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/batches/batch_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
    from openai import OpenAI
    client = OpenAI()
    
    client.batches.retrieve("batch_abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const batch = await openai.batches.retrieve("batch_abc123");
    
      console.log(batch);
    }
    
    main();

Response
    {
      "id": "batch_abc123",
      "object": "batch",
      "endpoint": "/v1/completions",
      "errors": null,
      "input_file_id": "file-abc123",
      "completion_window": "24h",
      "status": "completed",
      "output_file_id": "file-cvaTdG",
      "error_file_id": "file-HOWS94",
      "created_at": 1711471533,
      "in_progress_at": 1711471538,
      "expires_at": 1711557933,
      "finalizing_at": 1711493133,
      "completed_at": 1711493163,
      "failed_at": null,
      "expired_at": null,
      "cancelling_at": null,
      "cancelled_at": null,
      "request_counts": {
        "total": 100,
        "completed": 95,
        "failed": 5
      },
      "metadata": {
        "customer_id": "user_123456789",
        "batch_description": "Nightly eval job",
      }
    }

Cancel batch


----------------

postÂ https://api.openai.com/v1/batches/{batch\_id}/cancel

Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.

#### Path parameters

[](#batch-cancel-batch_id)

batch\_id

string

Required

The ID of the batch to cancel.

#### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/batches/batch_abc123/cancel \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -X POST
    from openai import OpenAI
    client = OpenAI()
    
    client.batches.cancel("batch_abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const batch = await openai.batches.cancel("batch_abc123");
    
      console.log(batch);
    }
    
    main();

Response
    {
      "id": "batch_abc123",
      "object": "batch",
      "endpoint": "/v1/chat/completions",
      "errors": null,
      "input_file_id": "file-abc123",
      "completion_window": "24h",
      "status": "cancelling",
      "output_file_id": null,
      "error_file_id": null,
      "created_at": 1711471533,
      "in_progress_at": 1711471538,
      "expires_at": 1711557933,
      "finalizing_at": null,
      "completed_at": null,
      "failed_at": null,
      "expired_at": null,
      "cancelling_at": 1711475133,
      "cancelled_at": null,
      "request_counts": {
        "total": 100,
        "completed": 23,
        "failed": 1
      },
      "metadata": {
        "customer_id": "user_123456789",
        "batch_description": "Nightly eval job",
      }
    }

List batch


--------------

getÂ https://api.openai.com/v1/batches

List your organization's batches.

#### Query parameters

[](#batch-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#batch-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of paginated [Batch](/docs/api-reference/batch/object) objects.

Example request

curl
    curl https://api.openai.com/v1/batches?limit=2 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json"
    from openai import OpenAI
    client = OpenAI()
    
    client.batches.list()
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const list = await openai.batches.list();
    
      for await (const batch of list) {
        console.log(batch);
      }
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "batch_abc123",
          "object": "batch",
          "endpoint": "/v1/chat/completions",
          "errors": null,
          "input_file_id": "file-abc123",
          "completion_window": "24h",
          "status": "completed",
          "output_file_id": "file-cvaTdG",
          "error_file_id": "file-HOWS94",
          "created_at": 1711471533,
          "in_progress_at": 1711471538,
          "expires_at": 1711557933,
          "finalizing_at": 1711493133,
          "completed_at": 1711493163,
          "failed_at": null,
          "expired_at": null,
          "cancelling_at": null,
          "cancelled_at": null,
          "request_counts": {
            "total": 100,
            "completed": 95,
            "failed": 5
          },
          "metadata": {
            "customer_id": "user_123456789",
            "batch_description": "Nightly job",
          }
        },
        { ... },
      ],
      "first_id": "batch_abc123",
      "last_id": "batch_abc456",
      "has_more": true
    }

The batch object


--------------------

[](#batch/object-cancelled_at)

cancelled\_at

integer

The Unix timestamp (in seconds) for when the batch was cancelled.

[](#batch/object-cancelling_at)

cancelling\_at

integer

The Unix timestamp (in seconds) for when the batch started cancelling.

[](#batch/object-completed_at)

completed\_at

integer

The Unix timestamp (in seconds) for when the batch was completed.

[](#batch/object-completion_window)

completion\_window

string

The time frame within which the batch should be processed.

[](#batch/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the batch was created.

[](#batch/object-endpoint)

endpoint

string

The OpenAI API endpoint used by the batch.

[](#batch/object-error_file_id)

error\_file\_id

string

The ID of the file containing the outputs of requests with errors.

[](#batch/object-errors)

errors

object

Show properties

[](#batch/object-expired_at)

expired\_at

integer

The Unix timestamp (in seconds) for when the batch expired.

[](#batch/object-expires_at)

expires\_at

integer

The Unix timestamp (in seconds) for when the batch will expire.

[](#batch/object-failed_at)

failed\_at

integer

The Unix timestamp (in seconds) for when the batch failed.

[](#batch/object-finalizing_at)

finalizing\_at

integer

The Unix timestamp (in seconds) for when the batch started finalizing.

[](#batch/object-id)

id

string

[](#batch/object-in_progress_at)

in\_progress\_at

integer

The Unix timestamp (in seconds) for when the batch started processing.

[](#batch/object-input_file_id)

input\_file\_id

string

The ID of the input file for the batch.

[](#batch/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#batch/object-object)

object

string

The object type, which is always `batch`.

[](#batch/object-output_file_id)

output\_file\_id

string

The ID of the file containing the outputs of successfully executed requests.

[](#batch/object-request_counts)

request\_counts

object

The request counts for different statuses within the batch.

Show properties

[](#batch/object-status)

status

string

The current status of the batch.

OBJECT The batch object
    {
      "id": "batch_abc123",
      "object": "batch",
      "endpoint": "/v1/completions",
      "errors": null,
      "input_file_id": "file-abc123",
      "completion_window": "24h",
      "status": "completed",
      "output_file_id": "file-cvaTdG",
      "error_file_id": "file-HOWS94",
      "created_at": 1711471533,
      "in_progress_at": 1711471538,
      "expires_at": 1711557933,
      "finalizing_at": 1711493133,
      "completed_at": 1711493163,
      "failed_at": null,
      "expired_at": null,
      "cancelling_at": null,
      "cancelled_at": null,
      "request_counts": {
        "total": 100,
        "completed": 95,
        "failed": 5
      },
      "metadata": {
        "customer_id": "user_123456789",
        "batch_description": "Nightly eval job",
      }
    }

The request input object


----------------------------

The per-line object of the batch input file

[](#batch/request-input-custom_id)

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.

[](#batch/request-input-method)

method

string

The HTTP method to be used for the request. Currently only `POST` is supported.

[](#batch/request-input-url)

url

string

The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.

OBJECT The request input object

    {"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}

The request output object


-----------------------------

The per-line object of the batch output and error files

[](#batch/request-output-custom_id)

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs.

[](#batch/request-output-error)

error

object or null

For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.

Show properties

[](#batch/request-output-id)

id

string

[](#batch/request-output-response)

response

object or null

Show properties

OBJECT The request output object

    {"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}

Files


---------

Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).

Upload file


---------------

postÂ https://api.openai.com/v1/files

Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

Please [contact us](https://help.openai.com/) if you need to increase these storage limits.

#### Request body

[](#files-create-file)

file

file

Required

The File object (not file name) to be uploaded.

[](#files-create-purpose)

purpose

string

Required

The intended purpose of the uploaded file. One of: - `assistants`: Used in the Assistants API - `batch`: Used in the Batch API - `fine-tune`: Used for fine-tuning - `vision`: Images used for vision fine-tuning - `user_data`: Flexible file type for any purpose - `evals`: Used for eval data sets

#### Returns

The uploaded [File](/docs/api-reference/files/object) object.

Example request

node.js
    curl https://api.openai.com/v1/files \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -F purpose="fine-tune" \
      -F file="@mydata.jsonl"
    from openai import OpenAI
    client = OpenAI()
    
    client.files.create(
      file=open("mydata.jsonl", "rb"),
      purpose="fine-tune"
    )
    import fs from "fs";
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const file = await openai.files.create({
        file: fs.createReadStream("mydata.jsonl"),
        purpose: "fine-tune",
      });
    
      console.log(file);
    }
    
    main();

Response
    {
      "id": "file-abc123",
      "object": "file",
      "bytes": 120000,
      "created_at": 1677610602,
      "filename": "mydata.jsonl",
      "purpose": "fine-tune",
    }

List files


--------------

getÂ https://api.openai.com/v1/files

Returns a list of files.

#### Query parameters

[](#files-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#files-list-limit)

limit

integer

Optional

Defaults to 10000

A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.

[](#files-list-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

[](#files-list-purpose)

purpose

string

Optional

Only return files with the given purpose.

#### Returns

A list of [File](/docs/api-reference/files/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/files \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.files.list()
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const list = await openai.files.list();
    
      for await (const file of list) {
        console.log(file);
      }
    }
    
    main();

Response
    {
      "data": [
        {
          "id": "file-abc123",
          "object": "file",
          "bytes": 175,
          "created_at": 1613677385,
          "filename": "salesOverview.pdf",
          "purpose": "assistants",
        },
        {
          "id": "file-abc123",
          "object": "file",
          "bytes": 140,
          "created_at": 1613779121,
          "filename": "puppy.jsonl",
          "purpose": "fine-tune",
        }
      ],
      "object": "list"
    }

Retrieve file


-----------------

getÂ https://api.openai.com/v1/files/{file\_id}

Returns information about a specific file.

#### Path parameters

[](#files-retrieve-file_id)

file\_id

string

Required

The ID of the file to use for this request.

#### Returns

The [File](/docs/api-reference/files/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/files/file-abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.files.retrieve("file-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const file = await openai.files.retrieve("file-abc123");
    
      console.log(file);
    }
    
    main();

Response
    {
      "id": "file-abc123",
      "object": "file",
      "bytes": 120000,
      "created_at": 1677610602,
      "filename": "mydata.jsonl",
      "purpose": "fine-tune",
    }

Delete file


---------------

deleteÂ https://api.openai.com/v1/files/{file\_id}

Delete a file.

#### Path parameters

[](#files-delete-file_id)

file\_id

string

Required

The ID of the file to use for this request.

#### Returns

Deletion status.

Example request

node.js
    curl https://api.openai.com/v1/files/file-abc123 \
      -X DELETE \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.files.delete("file-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const file = await openai.files.del("file-abc123");
    
      console.log(file);
    }
    
    main();

Response
    {
      "id": "file-abc123",
      "object": "file",
      "deleted": true
    }

Retrieve file content


-------------------------

getÂ https://api.openai.com/v1/files/{file\_id}/content

Returns the contents of the specified file.

#### Path parameters

[](#files-retrieve-contents-file_id)

file\_id

string

Required

The ID of the file to use for this request.

#### Returns

The file content.

Example request

node.js
    curl https://api.openai.com/v1/files/file-abc123/content \
      -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
    from openai import OpenAI
    client = OpenAI()
    
    content = client.files.content("file-abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const file = await openai.files.content("file-abc123");
    
      console.log(file);
    }
    
    main();

The file object


-------------------

The `File` object represents a document that has been uploaded to OpenAI.

[](#files/object-bytes)

bytes

integer

The size of the file, in bytes.

[](#files/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the file was created.

[](#files/object-expires_at)

expires\_at

integer

The Unix timestamp (in seconds) for when the file will expire.

[](#files/object-filename)

filename

string

The name of the file.

[](#files/object-id)

id

string

The file identifier, which can be referenced in the API endpoints.

[](#files/object-object)

object

string

The object type, which is always `file`.

[](#files/object-purpose)

purpose

string

The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results` and `vision`.

[](#files/object-status)

status

Deprecated

string

Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.

[](#files/object-status_details)

status\_details

Deprecated

string

Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.

OBJECT The file object
    {
      "id": "file-abc123",
      "object": "file",
      "bytes": 120000,
      "created_at": 1677610602,
      "expires_at": 1680202602,
      "filename": "salesOverview.pdf",
      "purpose": "assistants",
    }

Uploads


-----------

Allows you to upload large files in multiple parts.

Create upload


-----------------

postÂ https://api.openai.com/v1/uploads

Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.

Once you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.

For certain `purpose` values, the correct `mime_type` must be specified. Please refer to documentation for the [supported MIME types for your use case](/docs/assistants/tools/file-search#supported-files).

For guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).

#### Request body

[](#uploads-create-bytes)

bytes

integer

Required

The number of bytes in the file you are uploading.

[](#uploads-create-filename)

filename

string

Required

The name of the file to upload.

[](#uploads-create-mime_type)

mime\_type

string

Required

The MIME type of the file.

This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.

[](#uploads-create-purpose)

purpose

string

Required

The intended purpose of the uploaded file.

See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).

#### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `pending`.

Example request

curl
    curl https://api.openai.com/v1/uploads \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "purpose": "fine-tune",
        "filename": "training_examples.jsonl",
        "bytes": 2147483648,
        "mime_type": "text/jsonl"
      }'

Response
    {
      "id": "upload_abc123",
      "object": "upload",
      "bytes": 2147483648,
      "created_at": 1719184911,
      "filename": "training_examples.jsonl",
      "purpose": "fine-tune",
      "status": "pending",
      "expires_at": 1719127296
    }

Add upload part


-------------------

postÂ https://api.openai.com/v1/uploads/{upload\_id}/parts

Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object) object. A Part represents a chunk of bytes from the file you are trying to upload.

Each Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.

It is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you [complete the Upload](/docs/api-reference/uploads/complete).

#### Path parameters

[](#uploads-add-part-upload_id)

upload\_id

string

Required

The ID of the Upload.

#### Request body

[](#uploads-add-part-data)

data

file

Required

The chunk of bytes for this Part.

#### Returns

The upload [Part](/docs/api-reference/uploads/part-object) object.

Example request

curl
    curl https://api.openai.com/v1/uploads/upload_abc123/parts
      -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."

Response
    {
      "id": "part_def456",
      "object": "upload.part",
      "created_at": 1719185911,
      "upload_id": "upload_abc123"
    }

Complete upload


-------------------

postÂ https://api.openai.com/v1/uploads/{upload\_id}/complete

Completes the [Upload](/docs/api-reference/uploads/object).

Within the returned Upload object, there is a nested [File](/docs/api-reference/files/object) object that is ready to use in the rest of the platform.

You can specify the order of the Parts by passing in an ordered list of the Part IDs.

The number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is completed.

#### Path parameters

[](#uploads-complete-upload_id)

upload\_id

string

Required

The ID of the Upload.

#### Request body

[](#uploads-complete-part_ids)

part\_ids

array

Required

The ordered list of Part IDs.

[](#uploads-complete-md5)

md5

string

Optional

The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.

#### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `completed` with an additional `file` property containing the created usable File object.

Example request

curl
    curl https://api.openai.com/v1/uploads/upload_abc123/complete
      -d '{
        "part_ids": ["part_def456", "part_ghi789"]
      }'

Response
    {
      "id": "upload_abc123",
      "object": "upload",
      "bytes": 2147483648,
      "created_at": 1719184911,
      "filename": "training_examples.jsonl",
      "purpose": "fine-tune",
      "status": "completed",
      "expires_at": 1719127296,
      "file": {
        "id": "file-xyz321",
        "object": "file",
        "bytes": 2147483648,
        "created_at": 1719186911,
        "filename": "training_examples.jsonl",
        "purpose": "fine-tune",
      }
    }

Cancel upload


-----------------

postÂ https://api.openai.com/v1/uploads/{upload\_id}/cancel

Cancels the Upload. No Parts may be added after an Upload is cancelled.

#### Path parameters

[](#uploads-cancel-upload_id)

upload\_id

string

Required

The ID of the Upload.

#### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `cancelled`.

Example request

curl

    curl https://api.openai.com/v1/uploads/upload_abc123/cancel

Response
    {
      "id": "upload_abc123",
      "object": "upload",
      "bytes": 2147483648,
      "created_at": 1719184911,
      "filename": "training_examples.jsonl",
      "purpose": "fine-tune",
      "status": "cancelled",
      "expires_at": 1719127296
    }

The upload object


---------------------

The Upload object can accept byte chunks in the form of Parts.

[](#uploads/object-bytes)

bytes

integer

The intended number of bytes to be uploaded.

[](#uploads/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

[](#uploads/object-expires_at)

expires\_at

integer

The Unix timestamp (in seconds) for when the Upload will expire.

[](#uploads/object-file)

file

undefined or null

The ready File object after the Upload is completed.

[](#uploads/object-filename)

filename

string

The name of the file to be uploaded.

[](#uploads/object-id)

id

string

The Upload unique identifier, which can be referenced in API endpoints.

[](#uploads/object-object)

object

string

The object type, which is always "upload".

[](#uploads/object-purpose)

purpose

string

The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose) for acceptable values.

[](#uploads/object-status)

status

string

The status of the Upload.

OBJECT The upload object
    {
      "id": "upload_abc123",
      "object": "upload",
      "bytes": 2147483648,
      "created_at": 1719184911,
      "filename": "training_examples.jsonl",
      "purpose": "fine-tune",
      "status": "completed",
      "expires_at": 1719127296,
      "file": {
        "id": "file-xyz321",
        "object": "file",
        "bytes": 2147483648,
        "created_at": 1719186911,
        "filename": "training_examples.jsonl",
        "purpose": "fine-tune",
      }
    }

The upload part object


--------------------------

The upload Part represents a chunk of bytes we can add to an Upload object.

[](#uploads/part-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the Part was created.

[](#uploads/part-object-id)

id

string

The upload Part unique identifier, which can be referenced in API endpoints.

[](#uploads/part-object-object)

object

string

The object type, which is always `upload.part`.

[](#uploads/part-object-upload_id)

upload\_id

string

The ID of the Upload object that this Part was added to.

OBJECT The upload part object
    {
        "id": "part_def456",
        "object": "upload.part",
        "created_at": 1719186911,
        "upload_id": "upload_abc123"
    }

Models


----------

List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.

List models


---------------

getÂ https://api.openai.com/v1/models

Lists the currently available models, and provides basic information about each one such as the owner and availability.

#### Returns

A list of [model](/docs/api-reference/models/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/models \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.models.list()
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const list = await openai.models.list();
    
      for await (const model of list) {
        console.log(model);
      }
    }
    main();
    using System;
    
    using OpenAI.Models;
    
    OpenAIModelClient client = new(
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    foreach (var model in client.GetModels().Value)
    {
        Console.WriteLine(model.Id);
    }

Response
    {
      "object": "list",
      "data": [
        {
          "id": "model-id-0",
          "object": "model",
          "created": 1686935002,
          "owned_by": "organization-owner"
        },
        {
          "id": "model-id-1",
          "object": "model",
          "created": 1686935002,
          "owned_by": "organization-owner",
        },
        {
          "id": "model-id-2",
          "object": "model",
          "created": 1686935002,
          "owned_by": "openai"
        },
      ],
      "object": "list"
    }

Retrieve model


------------------

getÂ https://api.openai.com/v1/models/{model}

Retrieves a model instance, providing basic information about the model such as the owner and permissioning.

#### Path parameters

[](#models-retrieve-model)

model

string

Required

The ID of the model to use for this request

#### Returns

The [model](/docs/api-reference/models/object) object matching the specified ID.

Example request

gpt-4.1

node.js
    curl https://api.openai.com/v1/models/gpt-4.1 \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.models.retrieve("gpt-4.1")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const model = await openai.models.retrieve("gpt-4.1");
    
      console.log(model);
    }
    
    main();
    using System;
    using System.ClientModel;
    
    using OpenAI.Models;
    
      OpenAIModelClient client = new(
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    ClientResult<OpenAIModel> model = client.GetModel("babbage-002");
    Console.WriteLine(model.Value.Id);

Response
    {
      "id": "gpt-4.1",
      "object": "model",
      "created": 1686935002,
      "owned_by": "openai"
    }

Delete a fine-tuned model


-----------------------------

deleteÂ https://api.openai.com/v1/models/{model}

Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.

#### Path parameters

[](#models-delete-model)

model

string

Required

The model to delete

#### Returns

Deletion status.

Example request

node.js
    curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
      -X DELETE \
      -H "Authorization: Bearer $OPENAI_API_KEY"
    from openai import OpenAI
    client = OpenAI()
    
    client.models.delete("ft:gpt-4o-mini:acemeco:suffix:abc123")
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const model = await openai.models.del("ft:gpt-4o-mini:acemeco:suffix:abc123");
    
      console.log(model);
    }
    main();
    using System;
    using System.ClientModel;
    
    using OpenAI.Models;
    
    OpenAIModelClient client = new(
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    ClientResult success = client.DeleteModel("ft:gpt-4o-mini:acemeco:suffix:abc123");
    Console.WriteLine(success);

Response
    {
      "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
      "object": "model",
      "deleted": true
    }

The model object


--------------------

Describes an OpenAI model offering that can be used with the API.

[](#models/object-created)

created

integer

The Unix timestamp (in seconds) when the model was created.

[](#models/object-id)

id

string

The model identifier, which can be referenced in the API endpoints.

[](#models/object-object)

object

string

The object type, which is always "model".

[](#models/object-owned_by)

owned\_by

string

The organization that owns the model.

OBJECT The model object
    {
      "id": "gpt-4.1",
      "object": "model",
      "created": 1686935002,
      "owned_by": "openai"
    }

Moderations


---------------

Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories. Related guide: [Moderations](/docs/guides/moderation)

Create moderation


---------------------

postÂ https://api.openai.com/v1/moderations

Classifies if text and/or image inputs are potentially harmful. Learn more in the [moderation guide](/docs/guides/moderation).

#### Request body

[](#moderations-create-input)

input

string or array

Required

Input (or inputs) to classify. Can be a single string, an array of strings, or an array of multi-modal input objects similar to other models.

Show possible types

[](#moderations-create-model)

model

string

Optional

Defaults to omni-moderation-latest

The content moderation model you would like to use. Learn more in [the moderation guide](/docs/guides/moderation), and learn about available models [here](/docs/models#moderation).

#### Returns

A [moderation](/docs/api-reference/moderations/object) object.

Single stringSingle stringImage and textImage and text

Example request

node.js
    curl https://api.openai.com/v1/moderations \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "input": "I want to kill them."
      }'
    from openai import OpenAI
    client = OpenAI()
    
    moderation = client.moderations.create(input="I want to kill them.")
    print(moderation)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const moderation = await openai.moderations.create({ input: "I want to kill them." });
    
      console.log(moderation);
    }
    main();
    using System;
    using System.ClientModel;
    
    using OpenAI.Moderations;
    
    ModerationClient client = new(
        model: "omni-moderation-latest",
        apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
    );
    
    ClientResult<ModerationResult> moderation = client.ClassifyText("I want to kill them.");

Response
    {
      "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
      "model": "text-moderation-007",
      "results": [
        {
          "flagged": true,
          "categories": {
            "sexual": false,
            "hate": false,
            "harassment": true,
            "self-harm": false,
            "sexual/minors": false,
            "hate/threatening": false,
            "violence/graphic": false,
            "self-harm/intent": false,
            "self-harm/instructions": false,
            "harassment/threatening": true,
            "violence": true
          },
          "category_scores": {
            "sexual": 0.000011726012417057063,
            "hate": 0.22706663608551025,
            "harassment": 0.5215635299682617,
            "self-harm": 2.227119921371923e-6,
            "sexual/minors": 7.107352217872176e-8,
            "hate/threatening": 0.023547329008579254,
            "violence/graphic": 0.00003391829886822961,
            "self-harm/intent": 1.646940972932498e-6,
            "self-harm/instructions": 1.1198755256458526e-9,
            "harassment/threatening": 0.5694745779037476,
            "violence": 0.9971134662628174
          }
        }
      ]
    }

The moderation object


-------------------------

Represents if a given text input is potentially harmful.

[](#moderations/object-id)

id

string

The unique identifier for the moderation request.

[](#moderations/object-model)

model

string

The model used to generate the moderation results.

[](#moderations/object-results)

results

array

A list of moderation objects.

Show properties

OBJECT The moderation object
    {
      "id": "modr-0d9740456c391e43c445bf0f010940c7",
      "model": "omni-moderation-latest",
      "results": [
        {
          "flagged": true,
          "categories": {
            "harassment": true,
            "harassment/threatening": true,
            "sexual": false,
            "hate": false,
            "hate/threatening": false,
            "illicit": false,
            "illicit/violent": false,
            "self-harm/intent": false,
            "self-harm/instructions": false,
            "self-harm": false,
            "sexual/minors": false,
            "violence": true,
            "violence/graphic": true
          },
          "category_scores": {
            "harassment": 0.8189693396524255,
            "harassment/threatening": 0.804985420696006,
            "sexual": 1.573112165348997e-6,
            "hate": 0.007562942636942845,
            "hate/threatening": 0.004208854591835476,
            "illicit": 0.030535955153511665,
            "illicit/violent": 0.008925306722380033,
            "self-harm/intent": 0.00023023930975076432,
            "self-harm/instructions": 0.0002293869201073356,
            "self-harm": 0.012598046106750154,
            "sexual/minors": 2.212566909570261e-8,
            "violence": 0.9999992735124786,
            "violence/graphic": 0.843064871157054
          },
          "category_applied_input_types": {
            "harassment": [
              "text"
            ],
            "harassment/threatening": [
              "text"
            ],
            "sexual": [
              "text",
              "image"
            ],
            "hate": [
              "text"
            ],
            "hate/threatening": [
              "text"
            ],
            "illicit": [
              "text"
            ],
            "illicit/violent": [
              "text"
            ],
            "self-harm/intent": [
              "text",
              "image"
            ],
            "self-harm/instructions": [
              "text",
              "image"
            ],
            "self-harm": [
              "text",
              "image"
            ],
            "sexual/minors": [
              "text"
            ],
            "violence": [
              "text",
              "image"
            ],
            "violence/graphic": [
              "text",
              "image"
            ]
          }
        }
      ]
    }

Vector stores


-----------------

Vector stores power semantic search for the Retrieval API and the `file_search` tool in the Responses and Assistants APIs.

Related guide: [File Search](/docs/assistants/tools/file-search)

Create vector store


-----------------------

postÂ https://api.openai.com/v1/vector\_stores

Create a vector store.

#### Request body

[](#vector-stores-create-chunking_strategy)

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty.

Show possible types

[](#vector-stores-create-expires_after)

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

[](#vector-stores-create-file_ids)

file\_ids

array

Optional

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

[](#vector-stores-create-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#vector-stores-create-name)

name

string

Optional

The name of the vector store.

#### Returns

A [vector store](/docs/api-reference/vector-stores/object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
        "name": "Support FAQ"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    vector_store = client.vector_stores.create(
      name="Support FAQ"
    )
    print(vector_store)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStore = await openai.vectorStores.create({
        name: "Support FAQ"
      });
      console.log(vectorStore);
    }
    
    main();

Response
    {
      "id": "vs_abc123",
      "object": "vector_store",
      "created_at": 1699061776,
      "name": "Support FAQ",
      "bytes": 139920,
      "file_counts": {
        "in_progress": 0,
        "completed": 3,
        "failed": 0,
        "cancelled": 0,
        "total": 3
      }
    }

List vector stores


----------------------

getÂ https://api.openai.com/v1/vector\_stores

Returns a list of vector stores.

#### Query parameters

[](#vector-stores-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#vector-stores-list-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#vector-stores-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#vector-stores-list-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [vector store](/docs/api-reference/vector-stores/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_stores = client.vector_stores.list()
    print(vector_stores)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStores = await openai.vectorStores.list();
      console.log(vectorStores);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "vs_abc123",
          "object": "vector_store",
          "created_at": 1699061776,
          "name": "Support FAQ",
          "bytes": 139920,
          "file_counts": {
            "in_progress": 0,
            "completed": 3,
            "failed": 0,
            "cancelled": 0,
            "total": 3
          }
        },
        {
          "id": "vs_abc456",
          "object": "vector_store",
          "created_at": 1699061776,
          "name": "Support FAQ v2",
          "bytes": 139920,
          "file_counts": {
            "in_progress": 0,
            "completed": 3,
            "failed": 0,
            "cancelled": 0,
            "total": 3
          }
        }
      ],
      "first_id": "vs_abc123",
      "last_id": "vs_abc456",
      "has_more": false
    }

Retrieve vector store


-------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Retrieves a vector store.

#### Path parameters

[](#vector-stores-retrieve-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store to retrieve.

#### Returns

The [vector store](/docs/api-reference/vector-stores/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_store = client.vector_stores.retrieve(
      vector_store_id="vs_abc123"
    )
    print(vector_store)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStore = await openai.vectorStores.retrieve(
        "vs_abc123"
      );
      console.log(vectorStore);
    }
    
    main();

Response
    {
      "id": "vs_abc123",
      "object": "vector_store",
      "created_at": 1699061776
    }

Modify vector store


-----------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Modifies a vector store.

#### Path parameters

[](#vector-stores-modify-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store to modify.

#### Request body

[](#vector-stores-modify-expires_after)

expires\_after

object or null

Optional

The expiration policy for a vector store.

Show properties

[](#vector-stores-modify-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#vector-stores-modify-name)

name

string or null

Optional

The name of the vector store.

#### Returns

The modified [vector store](/docs/api-reference/vector-stores/object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
      -d '{
        "name": "Support FAQ"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    vector_store = client.vector_stores.update(
      vector_store_id="vs_abc123",
      name="Support FAQ"
    )
    print(vector_store)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStore = await openai.vectorStores.update(
        "vs_abc123",
        {
          name: "Support FAQ"
        }
      );
      console.log(vectorStore);
    }
    
    main();

Response
    {
      "id": "vs_abc123",
      "object": "vector_store",
      "created_at": 1699061776,
      "name": "Support FAQ",
      "bytes": 139920,
      "file_counts": {
        "in_progress": 0,
        "completed": 3,
        "failed": 0,
        "cancelled": 0,
        "total": 3
      }
    }

Delete vector store


-----------------------

deleteÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Delete a vector store.

#### Path parameters

[](#vector-stores-delete-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store to delete.

#### Returns

Deletion status

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -X DELETE
    from openai import OpenAI
    client = OpenAI()
    
    deleted_vector_store = client.vector_stores.delete(
      vector_store_id="vs_abc123"
    )
    print(deleted_vector_store)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const deletedVectorStore = await openai.vectorStores.del(
        "vs_abc123"
      );
      console.log(deletedVectorStore);
    }
    
    main();

Response
    {
      id: "vs_abc123",
      object: "vector_store.deleted",
      deleted: true
    }

Search vector store


-----------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/search

Search a vector store for relevant chunks based on a query and file attributes filter.

#### Path parameters

[](#vector-stores-search-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store to search.

#### Request body

[](#vector-stores-search-query)

query

string or array

Required

A query string for a search

[](#vector-stores-search-filters)

filters

object

Optional

A filter to apply based on file attributes.

Show possible types

[](#vector-stores-search-max_num_results)

max\_num\_results

integer

Optional

Defaults to 10

The maximum number of results to return. This number should be between 1 and 50 inclusive.

[](#vector-stores-search-ranking_options)

ranking\_options

object

Optional

Ranking options for search.

Show properties

[](#vector-stores-search-rewrite_query)

rewrite\_query

boolean

Optional

Defaults to false

Whether to rewrite the natural language query for vector search.

#### Returns

A page of search results from the vector store.

Example request

curl
    curl -X POST \
    https://api.openai.com/v1/vector_stores/vs_abc123/search \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{"query": "What is the return policy?", "filters": {...}}'

Response
    {
      "object": "vector_store.search_results.page",
      "search_query": "What is the return policy?",
      "data": [
        {
          "file_id": "file_123",
          "filename": "document.pdf",
          "score": 0.95,
          "attributes": {
            "author": "John Doe",
            "date": "2023-01-01"
          },
          "content": [
            {
              "type": "text",
              "text": "Relevant chunk"
            }
          ]
        },
        {
          "file_id": "file_456",
          "filename": "notes.txt",
          "score": 0.89,
          "attributes": {
            "author": "Jane Smith",
            "date": "2023-01-02"
          },
          "content": [
            {
              "type": "text",
              "text": "Sample text content from the vector store."
            }
          ]
        }
      ],
      "has_more": false,
      "next_page": null
    }

The vector store object


---------------------------

A vector store is a collection of processed files can be used by the `file_search` tool.

[](#vector-stores/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the vector store was created.

[](#vector-stores/object-expires_after)

expires\_after

object

The expiration policy for a vector store.

Show properties

[](#vector-stores/object-expires_at)

expires\_at

integer or null

The Unix timestamp (in seconds) for when the vector store will expire.

[](#vector-stores/object-file_counts)

file\_counts

object

Show properties

[](#vector-stores/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#vector-stores/object-last_active_at)

last\_active\_at

integer or null

The Unix timestamp (in seconds) for when the vector store was last active.

[](#vector-stores/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#vector-stores/object-name)

name

string

The name of the vector store.

[](#vector-stores/object-object)

object

string

The object type, which is always `vector_store`.

[](#vector-stores/object-status)

status

string

The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.

[](#vector-stores/object-usage_bytes)

usage\_bytes

integer

The total number of bytes used by the files in the vector store.

OBJECT The vector store object
    {
      "id": "vs_123",
      "object": "vector_store",
      "created_at": 1698107661,
      "usage_bytes": 123456,
      "last_active_at": 1698107661,
      "name": "my_vector_store",
      "status": "completed",
      "file_counts": {
        "in_progress": 0,
        "completed": 100,
        "cancelled": 0,
        "failed": 0,
        "total": 100
      },
      "last_used_at": 1698107661
    }

Vector store files


----------------------

Vector store files represent files inside a vector store.

Related guide: [File Search](/docs/assistants/tools/file-search)

Create vector store file


----------------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Create a vector store file by attaching a [File](/docs/api-reference/files) to a [vector store](/docs/api-reference/vector-stores/object).

#### Path parameters

[](#vector-stores-files-createfile-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store for which to create a File.

#### Request body

[](#vector-stores-files-createfile-file_id)

file\_id

string

Required

A [File](/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.

[](#vector-stores-files-createfile-attributes)

attributes

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.

[](#vector-stores-files-createfile-chunking_strategy)

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

#### Returns

A [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
        -H "Authorization: Bearer $OPENAI_API_KEY" \
        -H "Content-Type: application/json" \
        -H "OpenAI-Beta: assistants=v2" \
        -d '{
          "file_id": "file-abc123"
        }'
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_file = client.vector_stores.files.create(
      vector_store_id="vs_abc123",
      file_id="file-abc123"
    )
    print(vector_store_file)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const myVectorStoreFile = await openai.vectorStores.files.create(
        "vs_abc123",
        {
          file_id: "file-abc123"
        }
      );
      console.log(myVectorStoreFile);
    }
    
    main();

Response
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "created_at": 1699061776,
      "usage_bytes": 1234,
      "vector_store_id": "vs_abcd",
      "status": "completed",
      "last_error": null
    }

List vector store files


---------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Returns a list of vector store files.

#### Path parameters

[](#vector-stores-files-listfiles-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

#### Query parameters

[](#vector-stores-files-listfiles-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#vector-stores-files-listfiles-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#vector-stores-files-listfiles-filter)

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

[](#vector-stores-files-listfiles-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#vector-stores-files-listfiles-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_files = client.vector_stores.files.list(
      vector_store_id="vs_abc123"
    )
    print(vector_store_files)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStoreFiles = await openai.vectorStores.files.list(
        "vs_abc123"
      );
      console.log(vectorStoreFiles);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "file-abc123",
          "object": "vector_store.file",
          "created_at": 1699061776,
          "vector_store_id": "vs_abc123"
        },
        {
          "id": "file-abc456",
          "object": "vector_store.file",
          "created_at": 1699061776,
          "vector_store_id": "vs_abc123"
        }
      ],
      "first_id": "file-abc123",
      "last_id": "file-abc456",
      "has_more": false
    }

Retrieve vector store file


------------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Retrieves a vector store file.

#### Path parameters

[](#vector-stores-files-getfile-file_id)

file\_id

string

Required

The ID of the file being retrieved.

[](#vector-stores-files-getfile-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

#### Returns

The [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_file = client.vector_stores.files.retrieve(
      vector_store_id="vs_abc123",
      file_id="file-abc123"
    )
    print(vector_store_file)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStoreFile = await openai.vectorStores.files.retrieve(
        "vs_abc123",
        "file-abc123"
      );
      console.log(vectorStoreFile);
    }
    
    main();

Response
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "created_at": 1699061776,
      "vector_store_id": "vs_abcd",
      "status": "completed",
      "last_error": null
    }

Retrieve vector store file content


--------------------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}/content

Retrieve the parsed contents of a vector store file.

#### Path parameters

[](#vector-stores-files-getcontent-file_id)

file\_id

string

Required

The ID of the file within the vector store.

[](#vector-stores-files-getcontent-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store.

#### Returns

The parsed contents of the specified vector store file.

Example request

curl
    curl \
    https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123/content \
    -H "Authorization: Bearer $OPENAI_API_KEY"

Response
    {
      "file_id": "file-abc123",
      "filename": "example.txt",
      "attributes": {"key": "value"},
      "content": [
        {"type": "text", "text": "..."},
        ...
      ]
    }

Update vector store file attributes


---------------------------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Update attributes on a vector store file.

#### Path parameters

[](#vector-stores-files-updateattributes-file_id)

file\_id

string

Required

The ID of the file to update attributes.

[](#vector-stores-files-updateattributes-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store the file belongs to.

#### Request body

[](#vector-stores-files-updateattributes-attributes)

attributes

map

Required

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.

#### Returns

The updated [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl
    curl https://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id} \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{"attributes": {"key1": "value1", "key2": 2}}'

Response
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "usage_bytes": 1234,
      "created_at": 1699061776,
      "vector_store_id": "vs_abcd",
      "status": "completed",
      "last_error": null,
      "chunking_strategy": {...},
      "attributes": {"key1": "value1", "key2": 2}
    }

Delete vector store file


----------------------------

deleteÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](/docs/api-reference/files/delete) endpoint.

#### Path parameters

[](#vector-stores-files-deletefile-file_id)

file\_id

string

Required

The ID of the file to delete.

[](#vector-stores-files-deletefile-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

#### Returns

Deletion status

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -X DELETE
    from openai import OpenAI
    client = OpenAI()
    
    deleted_vector_store_file = client.vector_stores.files.delete(
        vector_store_id="vs_abc123",
        file_id="file-abc123"
    )
    print(deleted_vector_store_file)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const deletedVectorStoreFile = await openai.vectorStores.files.del(
        "vs_abc123",
        "file-abc123"
      );
      console.log(deletedVectorStoreFile);
    }
    
    main();

Response
    {
      id: "file-abc123",
      object: "vector_store.file.deleted",
      deleted: true
    }

The vector store file object

Beta


--------------------------------------

A list of files attached to a vector store.

[](#vector-stores-files/file-object-attributes)

attributes

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.

[](#vector-stores-files/file-object-chunking_strategy)

chunking\_strategy

object

The strategy used to chunk the file.

Show possible types

[](#vector-stores-files/file-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the vector store file was created.

[](#vector-stores-files/file-object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#vector-stores-files/file-object-last_error)

last\_error

object or null

The last error associated with this vector store file. Will be `null` if there are no errors.

Show properties

[](#vector-stores-files/file-object-object)

object

string

The object type, which is always `vector_store.file`.

[](#vector-stores-files/file-object-status)

status

string

The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.

[](#vector-stores-files/file-object-usage_bytes)

usage\_bytes

integer

The total vector store usage in bytes. Note that this may be different from the original file size.

[](#vector-stores-files/file-object-vector_store_id)

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

OBJECT The vector store file object
    {
      "id": "file-abc123",
      "object": "vector_store.file",
      "usage_bytes": 1234,
      "created_at": 1698107661,
      "vector_store_id": "vs_abc123",
      "status": "completed",
      "last_error": null,
      "chunking_strategy": {
        "type": "static",
        "static": {
          "max_chunk_size_tokens": 800,
          "chunk_overlap_tokens": 400
        }
      }
    }

Vector store file batches


-----------------------------

Vector store file batches represent operations to add multiple files to a vector store. Related guide: [File Search](/docs/assistants/tools/file-search)

Create vector store file batch


----------------------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches

Create a vector store file batch.

#### Path parameters

[](#vector-stores-file-batches-createbatch-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store for which to create a File Batch.

#### Request body

[](#vector-stores-file-batches-createbatch-file_ids)

file\_ids

array

Required

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

[](#vector-stores-file-batches-createbatch-attributes)

attributes

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters, booleans, or numbers.

[](#vector-stores-file-batches-createbatch-chunking_strategy)

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

#### Returns

A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
        -H "Authorization: Bearer $OPENAI_API_KEY" \
        -H "Content-Type: application/json \
        -H "OpenAI-Beta: assistants=v2" \
        -d '{
          "file_ids": ["file-abc123", "file-abc456"]
        }'
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_file_batch = client.vector_stores.file_batches.create(
      vector_store_id="vs_abc123",
      file_ids=["file-abc123", "file-abc456"]
    )
    print(vector_store_file_batch)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const myVectorStoreFileBatch = await openai.vectorStores.fileBatches.create(
        "vs_abc123",
        {
          file_ids: ["file-abc123", "file-abc456"]
        }
      );
      console.log(myVectorStoreFileBatch);
    }
    
    main();

Response
    {
      "id": "vsfb_abc123",
      "object": "vector_store.file_batch",
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123",
      "status": "in_progress",
      "file_counts": {
        "in_progress": 1,
        "completed": 1,
        "failed": 0,
        "cancelled": 0,
        "total": 0,
      }
    }

Retrieve vector store file batch


------------------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}

Retrieves a vector store file batch.

#### Path parameters

[](#vector-stores-file-batches-getbatch-batch_id)

batch\_id

string

Required

The ID of the file batch being retrieved.

[](#vector-stores-file-batches-getbatch-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

#### Returns

The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_file_batch = client.vector_stores.file_batches.retrieve(
      vector_store_id="vs_abc123",
      batch_id="vsfb_abc123"
    )
    print(vector_store_file_batch)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStoreFileBatch = await openai.vectorStores.fileBatches.retrieve(
        "vs_abc123",
        "vsfb_abc123"
      );
      console.log(vectorStoreFileBatch);
    }
    
    main();

Response
    {
      "id": "vsfb_abc123",
      "object": "vector_store.file_batch",
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123",
      "status": "in_progress",
      "file_counts": {
        "in_progress": 1,
        "completed": 1,
        "failed": 0,
        "cancelled": 0,
        "total": 0,
      }
    }

Cancel vector store file batch


----------------------------------

postÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/cancel

Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.

#### Path parameters

[](#vector-stores-file-batches-cancelbatch-batch_id)

batch\_id

string

Required

The ID of the file batch to cancel.

[](#vector-stores-file-batches-cancelbatch-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

#### Returns

The modified vector store file batch object.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -X POST
    from openai import OpenAI
    client = OpenAI()
    
    deleted_vector_store_file_batch = client.vector_stores.file_batches.cancel(
        vector_store_id="vs_abc123",
        file_batch_id="vsfb_abc123"
    )
    print(deleted_vector_store_file_batch)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const deletedVectorStoreFileBatch = await openai.vectorStores.fileBatches.cancel(
        "vs_abc123",
        "vsfb_abc123"
      );
      console.log(deletedVectorStoreFileBatch);
    }
    
    main();

Response
    {
      "id": "vsfb_abc123",
      "object": "vector_store.file_batch",
      "created_at": 1699061776,
      "vector_store_id": "vs_abc123",
      "status": "in_progress",
      "file_counts": {
        "in_progress": 12,
        "completed": 3,
        "failed": 0,
        "cancelled": 0,
        "total": 15,
      }
    }

List vector store files in a batch


--------------------------------------

getÂ https://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/files

Returns a list of vector store files in a batch.

#### Path parameters

[](#vector-stores-file-batches-listbatchfiles-batch_id)

batch\_id

string

Required

The ID of the file batch that the files belong to.

[](#vector-stores-file-batches-listbatchfiles-vector_store_id)

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

#### Query parameters

[](#vector-stores-file-batches-listbatchfiles-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#vector-stores-file-batches-listbatchfiles-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#vector-stores-file-batches-listbatchfiles-filter)

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

[](#vector-stores-file-batches-listbatchfiles-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#vector-stores-file-batches-listbatchfiles-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

node.js
    curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    vector_store_files = client.vector_stores.file_batches.list_files(
      vector_store_id="vs_abc123",
      batch_id="vsfb_abc123"
    )
    print(vector_store_files)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const vectorStoreFiles = await openai.vectorStores.fileBatches.listFiles(
        "vs_abc123",
        "vsfb_abc123"
      );
      console.log(vectorStoreFiles);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "file-abc123",
          "object": "vector_store.file",
          "created_at": 1699061776,
          "vector_store_id": "vs_abc123"
        },
        {
          "id": "file-abc456",
          "object": "vector_store.file",
          "created_at": 1699061776,
          "vector_store_id": "vs_abc123"
        }
      ],
      "first_id": "file-abc123",
      "last_id": "file-abc456",
      "has_more": false
    }

The vector store files batch object

Beta


---------------------------------------------

A batch of files attached to a vector store.

[](#vector-stores-file-batches/batch-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the vector store files batch was created.

[](#vector-stores-file-batches/batch-object-file_counts)

file\_counts

object

Show properties

[](#vector-stores-file-batches/batch-object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#vector-stores-file-batches/batch-object-object)

object

string

The object type, which is always `vector_store.file_batch`.

[](#vector-stores-file-batches/batch-object-status)

status

string

The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.

[](#vector-stores-file-batches/batch-object-vector_store_id)

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

OBJECT The vector store files batch object
    {
      "id": "vsfb_123",
      "object": "vector_store.files_batch",
      "created_at": 1698107661,
      "vector_store_id": "vs_abc123",
      "status": "completed",
      "file_counts": {
        "in_progress": 0,
        "completed": 100,
        "failed": 0,
        "cancelled": 0,
        "total": 100
      }
    }

Assistants

Beta


--------------------

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

Create assistant

Beta


--------------------------

postÂ https://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

#### Request body

[](#assistants-createassistant-model)

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

[](#assistants-createassistant-description)

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

[](#assistants-createassistant-instructions)

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

[](#assistants-createassistant-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#assistants-createassistant-name)

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

[](#assistants-createassistant-reasoning_effort)

reasoning\_effort

string or null

Optional

Defaults to medium

**o-series models only**

Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `low`, `medium`, and `high`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

[](#assistants-createassistant-response_format)

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#assistants-createassistant-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

[](#assistants-createassistant-tool_resources)

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

[](#assistants-createassistant-tools)

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

[](#assistants-createassistant-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

#### Returns

An [assistant](/docs/api-reference/assistants/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

node.js
    curl "https://api.openai.com/v1/assistants" \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
        "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
        "name": "Math Tutor",
        "tools": [{"type": "code_interpreter"}],
        "model": "gpt-4o"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    my_assistant = client.beta.assistants.create(
        instructions="You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
        name="Math Tutor",
        tools=[{"type": "code_interpreter"}],
        model="gpt-4o",
    )
    print(my_assistant)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const myAssistant = await openai.beta.assistants.create({
        instructions:
          "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
        name: "Math Tutor",
        tools: [{ type: "code_interpreter" }],
        model: "gpt-4o",
      });
    
      console.log(myAssistant);
    }
    
    main();

Response
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1698984975,
      "name": "Math Tutor",
      "description": null,
      "model": "gpt-4o",
      "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    }

List assistants

Beta


-------------------------

getÂ https://api.openai.com/v1/assistants

Returns a list of assistants.

#### Query parameters

[](#assistants-listassistants-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#assistants-listassistants-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#assistants-listassistants-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#assistants-listassistants-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [assistant](/docs/api-reference/assistants/object) objects.

Example request

node.js
    curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    my_assistants = client.beta.assistants.list(
        order="desc",
        limit="20",
    )
    print(my_assistants.data)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const myAssistants = await openai.beta.assistants.list({
        order: "desc",
        limit: "20",
      });
    
      console.log(myAssistants.data);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "asst_abc123",
          "object": "assistant",
          "created_at": 1698982736,
          "name": "Coding Tutor",
          "description": null,
          "model": "gpt-4o",
          "instructions": "You are a helpful assistant designed to make me better at coding!",
          "tools": [],
          "tool_resources": {},
          "metadata": {},
          "top_p": 1.0,
          "temperature": 1.0,
          "response_format": "auto"
        },
        {
          "id": "asst_abc456",
          "object": "assistant",
          "created_at": 1698982718,
          "name": "My Assistant",
          "description": null,
          "model": "gpt-4o",
          "instructions": "You are a helpful assistant designed to make me better at coding!",
          "tools": [],
          "tool_resources": {},
          "metadata": {},
          "top_p": 1.0,
          "temperature": 1.0,
          "response_format": "auto"
        },
        {
          "id": "asst_abc789",
          "object": "assistant",
          "created_at": 1698982643,
          "name": null,
          "description": null,
          "model": "gpt-4o",
          "instructions": null,
          "tools": [],
          "tool_resources": {},
          "metadata": {},
          "top_p": 1.0,
          "temperature": 1.0,
          "response_format": "auto"
        }
      ],
      "first_id": "asst_abc123",
      "last_id": "asst_abc789",
      "has_more": false
    }

Retrieve assistant

Beta


----------------------------

getÂ https://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

#### Path parameters

[](#assistants-getassistant-assistant_id)

assistant\_id

string

Required

The ID of the assistant to retrieve.

#### Returns

The [assistant](/docs/api-reference/assistants/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/assistants/asst_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    my_assistant = client.beta.assistants.retrieve("asst_abc123")
    print(my_assistant)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const myAssistant = await openai.beta.assistants.retrieve(
        "asst_abc123"
      );
    
      console.log(myAssistant);
    }
    
    main();

Response
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1699009709,
      "name": "HR Helper",
      "description": null,
      "model": "gpt-4o",
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
      "tools": [
        {
          "type": "file_search"
        }
      ],
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    }

Modify assistant

Beta


--------------------------

postÂ https://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

#### Path parameters

[](#assistants-modifyassistant-assistant_id)

assistant\_id

string

Required

The ID of the assistant to modify.

#### Request body

[](#assistants-modifyassistant-description)

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

[](#assistants-modifyassistant-instructions)

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

[](#assistants-modifyassistant-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#assistants-modifyassistant-model)

model

string

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

[](#assistants-modifyassistant-name)

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

[](#assistants-modifyassistant-reasoning_effort)

reasoning\_effort

string or null

Optional

Defaults to medium

**o-series models only**

Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `low`, `medium`, and `high`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

[](#assistants-modifyassistant-response_format)

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#assistants-modifyassistant-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

[](#assistants-modifyassistant-tool_resources)

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

[](#assistants-modifyassistant-tools)

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

[](#assistants-modifyassistant-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

#### Returns

The modified [assistant](/docs/api-reference/assistants/object) object.

Example request

node.js
    curl https://api.openai.com/v1/assistants/asst_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
          "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
          "tools": [{"type": "file_search"}],
          "model": "gpt-4o"
        }'
    from openai import OpenAI
    client = OpenAI()
    
    my_updated_assistant = client.beta.assistants.update(
      "asst_abc123",
      instructions="You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      name="HR Helper",
      tools=[{"type": "file_search"}],
      model="gpt-4o"
    )
    
    print(my_updated_assistant)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const myUpdatedAssistant = await openai.beta.assistants.update(
        "asst_abc123",
        {
          instructions:
            "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
          name: "HR Helper",
          tools: [{ type: "file_search" }],
          model: "gpt-4o"
        }
      );
    
      console.log(myUpdatedAssistant);
    }
    
    main();

Response
    {
      "id": "asst_123",
      "object": "assistant",
      "created_at": 1699009709,
      "name": "HR Helper",
      "description": null,
      "model": "gpt-4o",
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [
        {
          "type": "file_search"
        }
      ],
      "tool_resources": {
        "file_search": {
          "vector_store_ids": []
        }
      },
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    }

Delete assistant

Beta


--------------------------

deleteÂ https://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

#### Path parameters

[](#assistants-deleteassistant-assistant_id)

assistant\_id

string

Required

The ID of the assistant to delete.

#### Returns

Deletion status

Example request

node.js
    curl https://api.openai.com/v1/assistants/asst_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -X DELETE
    from openai import OpenAI
    client = OpenAI()
    
    response = client.beta.assistants.delete("asst_abc123")
    print(response)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const response = await openai.beta.assistants.del("asst_abc123");
    
      console.log(response);
    }
    main();

Response
    {
      "id": "asst_abc123",
      "object": "assistant.deleted",
      "deleted": true
    }

The assistant object

Beta


------------------------------

Represents an `assistant` that can call the model and use tools.

[](#assistants/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

[](#assistants/object-description)

description

string or null

The description of the assistant. The maximum length is 512 characters.

[](#assistants/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#assistants/object-instructions)

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

[](#assistants/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#assistants/object-model)

model

string

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

[](#assistants/object-name)

name

string or null

The name of the assistant. The maximum length is 256 characters.

[](#assistants/object-object)

object

string

The object type, which is always `assistant`.

[](#assistants/object-response_format)

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#assistants/object-temperature)

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

[](#assistants/object-tool_resources)

tool\_resources

object or null

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

[](#assistants/object-tools)

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

[](#assistants/object-top_p)

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

OBJECT The assistant object
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1698984975,
      "name": "Math Tutor",
      "description": null,
      "model": "gpt-4o",
      "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "metadata": {},
      "top_p": 1.0,
      "temperature": 1.0,
      "response_format": "auto"
    }

Threads

Beta


-----------------

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

Create thread

Beta


-----------------------

postÂ https://api.openai.com/v1/threads

Create a thread.

#### Request body

[](#threads-createthread-messages)

messages

array

Optional

A list of [messages](/docs/api-reference/messages) to start the thread with.

Show properties

[](#threads-createthread-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#threads-createthread-tool_resources)

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

#### Returns

A [thread](/docs/api-reference/threads) object.

EmptyEmptyMessagesMessages

Example request

node.js
    curl https://api.openai.com/v1/threads \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d ''
    from openai import OpenAI
    client = OpenAI()
    
    empty_thread = client.beta.threads.create()
    print(empty_thread)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const emptyThread = await openai.beta.threads.create();
    
      console.log(emptyThread);
    }
    
    main();

Response
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1699012949,
      "metadata": {},
      "tool_resources": {}
    }

Retrieve thread

Beta


-------------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

#### Path parameters

[](#threads-getthread-thread_id)

thread\_id

string

Required

The ID of the thread to retrieve.

#### Returns

The [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    my_thread = client.beta.threads.retrieve("thread_abc123")
    print(my_thread)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const myThread = await openai.beta.threads.retrieve(
        "thread_abc123"
      );
    
      console.log(myThread);
    }
    
    main();

Response
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1699014083,
      "metadata": {},
      "tool_resources": {
        "code_interpreter": {
          "file_ids": []
        }
      }
    }

Modify thread

Beta


-----------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

#### Path parameters

[](#threads-modifythread-thread_id)

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

#### Request body

[](#threads-modifythread-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#threads-modifythread-tool_resources)

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

#### Returns

The modified [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
          "metadata": {
            "modified": "true",
            "user": "abc123"
          }
        }'
    from openai import OpenAI
    client = OpenAI()
    
    my_updated_thread = client.beta.threads.update(
      "thread_abc123",
      metadata={
        "modified": "true",
        "user": "abc123"
      }
    )
    print(my_updated_thread)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const updatedThread = await openai.beta.threads.update(
        "thread_abc123",
        {
          metadata: { modified: "true", user: "abc123" },
        }
      );
    
      console.log(updatedThread);
    }
    
    main();

Response
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1699014083,
      "metadata": {
        "modified": "true",
        "user": "abc123"
      },
      "tool_resources": {}
    }

Delete thread

Beta


-----------------------

deleteÂ https://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

#### Path parameters

[](#threads-deletethread-thread_id)

thread\_id

string

Required

The ID of the thread to delete.

#### Returns

Deletion status

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -X DELETE
    from openai import OpenAI
    client = OpenAI()
    
    response = client.beta.threads.delete("thread_abc123")
    print(response)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const response = await openai.beta.threads.del("thread_abc123");
    
      console.log(response);
    }
    main();

Response
    {
      "id": "thread_abc123",
      "object": "thread.deleted",
      "deleted": true
    }

The thread object

Beta


---------------------------

Represents a thread that contains [messages](/docs/api-reference/messages).

[](#threads/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

[](#threads/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#threads/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#threads/object-object)

object

string

The object type, which is always `thread`.

[](#threads/object-tool_resources)

tool\_resources

object or null

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

OBJECT The thread object
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1698107661,
      "metadata": {}
    }

Messages

Beta


------------------

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

Create message

Beta


------------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

#### Path parameters

[](#messages-createmessage-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to create a message for.

#### Request body

[](#messages-createmessage-content)

content

string or array

Required

Show possible types

[](#messages-createmessage-role)

role

string

Required

The role of the entity that is creating the message. Allowed values include:

*   `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
*   `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

[](#messages-createmessage-attachments)

attachments

array or null

Optional

A list of files attached to the message, and the tools they should be added to.

Show properties

[](#messages-createmessage-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

#### Returns

A [message](/docs/api-reference/messages/object) object.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/messages \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
          "role": "user",
          "content": "How does AI work? Explain it in simple terms."
        }'
    from openai import OpenAI
    client = OpenAI()
    
    thread_message = client.beta.threads.messages.create(
      "thread_abc123",
      role="user",
      content="How does AI work? Explain it in simple terms.",
    )
    print(thread_message)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const threadMessages = await openai.beta.threads.messages.create(
        "thread_abc123",
        { role: "user", content: "How does AI work? Explain it in simple terms." }
      );
    
      console.log(threadMessages);
    }
    
    main();

Response
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1713226573,
      "assistant_id": null,
      "thread_id": "thread_abc123",
      "run_id": null,
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "How does AI work? Explain it in simple terms.",
            "annotations": []
          }
        }
      ],
      "attachments": [],
      "metadata": {}
    }

List messages

Beta


-----------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

#### Path parameters

[](#messages-listmessages-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) the messages belong to.

#### Query parameters

[](#messages-listmessages-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#messages-listmessages-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#messages-listmessages-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#messages-listmessages-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

[](#messages-listmessages-run_id)

run\_id

string

Optional

Filter messages by the run ID that generated them.

#### Returns

A list of [message](/docs/api-reference/messages) objects.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/messages \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    thread_messages = client.beta.threads.messages.list("thread_abc123")
    print(thread_messages.data)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const threadMessages = await openai.beta.threads.messages.list(
        "thread_abc123"
      );
    
      console.log(threadMessages.data);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "msg_abc123",
          "object": "thread.message",
          "created_at": 1699016383,
          "assistant_id": null,
          "thread_id": "thread_abc123",
          "run_id": null,
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": {
                "value": "How does AI work? Explain it in simple terms.",
                "annotations": []
              }
            }
          ],
          "attachments": [],
          "metadata": {}
        },
        {
          "id": "msg_abc456",
          "object": "thread.message",
          "created_at": 1699016383,
          "assistant_id": null,
          "thread_id": "thread_abc123",
          "run_id": null,
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": {
                "value": "Hello, what is AI?",
                "annotations": []
              }
            }
          ],
          "attachments": [],
          "metadata": {}
        }
      ],
      "first_id": "msg_abc123",
      "last_id": "msg_abc456",
      "has_more": false
    }

Retrieve message

Beta


--------------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

#### Path parameters

[](#messages-getmessage-message_id)

message\_id

string

Required

The ID of the message to retrieve.

[](#messages-getmessage-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this message belongs.

#### Returns

The [message](/docs/api-reference/messages/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    message = client.beta.threads.messages.retrieve(
      message_id="msg_abc123",
      thread_id="thread_abc123",
    )
    print(message)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const message = await openai.beta.threads.messages.retrieve(
        "thread_abc123",
        "msg_abc123"
      );
    
      console.log(message);
    }
    
    main();

Response
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1699017614,
      "assistant_id": null,
      "thread_id": "thread_abc123",
      "run_id": null,
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "How does AI work? Explain it in simple terms.",
            "annotations": []
          }
        }
      ],
      "attachments": [],
      "metadata": {}
    }

Modify message

Beta


------------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

#### Path parameters

[](#messages-modifymessage-message_id)

message\_id

string

Required

The ID of the message to modify.

[](#messages-modifymessage-thread_id)

thread\_id

string

Required

The ID of the thread to which this message belongs.

#### Request body

[](#messages-modifymessage-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

#### Returns

The modified [message](/docs/api-reference/messages/object) object.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
          "metadata": {
            "modified": "true",
            "user": "abc123"
          }
        }'
    from openai import OpenAI
    client = OpenAI()
    
    message = client.beta.threads.messages.update(
      message_id="msg_abc12",
      thread_id="thread_abc123",
      metadata={
        "modified": "true",
        "user": "abc123",
      },
    )
    print(message)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const message = await openai.beta.threads.messages.update(
        "thread_abc123",
        "msg_abc123",
        {
          metadata: {
            modified: "true",
            user: "abc123",
          },
        }
      }'

Response
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1699017614,
      "assistant_id": null,
      "thread_id": "thread_abc123",
      "run_id": null,
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "How does AI work? Explain it in simple terms.",
            "annotations": []
          }
        }
      ],
      "file_ids": [],
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }

Delete message

Beta


------------------------

deleteÂ https://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Deletes a message.

#### Path parameters

[](#messages-deletemessage-message_id)

message\_id

string

Required

The ID of the message to delete.

[](#messages-deletemessage-thread_id)

thread\_id

string

Required

The ID of the thread to which this message belongs.

#### Returns

Deletion status

Example request

node.js
    curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    deleted_message = client.beta.threads.messages.delete(
      message_id="msg_abc12",
      thread_id="thread_abc123",
    )
    print(deleted_message)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const deletedMessage = await openai.beta.threads.messages.del(
        "thread_abc123",
        "msg_abc123"
      );
    
      console.log(deletedMessage);
    }

Response
    {
      "id": "msg_abc123",
      "object": "thread.message.deleted",
      "deleted": true
    }

The message object

Beta


----------------------------

Represents a message within a [thread](/docs/api-reference/threads).

[](#messages/object-assistant_id)

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message.

[](#messages/object-attachments)

attachments

array or null

A list of files attached to the message, and the tools they were added to.

Show properties

[](#messages/object-completed_at)

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

[](#messages/object-content)

content

array

The content of the message in array of text and/or images.

Show possible types

[](#messages/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

[](#messages/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#messages/object-incomplete_at)

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

[](#messages/object-incomplete_details)

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

[](#messages/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#messages/object-object)

object

string

The object type, which is always `thread.message`.

[](#messages/object-role)

role

string

The entity that produced the message. One of `user` or `assistant`.

[](#messages/object-run_id)

run\_id

string or null

The ID of the [run](/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

[](#messages/object-status)

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

[](#messages/object-thread_id)

thread\_id

string

The [thread](/docs/api-reference/threads) ID that this message belongs to.

OBJECT The message object
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1698983503,
      "thread_id": "thread_abc123",
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "Hi! How can I help you today?",
            "annotations": []
          }
        }
      ],
      "assistant_id": "asst_abc123",
      "run_id": "run_abc123",
      "attachments": [],
      "metadata": {}
    }

Runs

Beta


--------------

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

Create run

Beta


--------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

#### Path parameters

[](#runs-createrun-thread_id)

thread\_id

string

Required

The ID of the thread to run.

#### Query parameters

[](#runs-createrun-include)

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

#### Request body

[](#runs-createrun-assistant_id)

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

[](#runs-createrun-additional_instructions)

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

[](#runs-createrun-additional_messages)

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

[](#runs-createrun-instructions)

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

[](#runs-createrun-max_completion_tokens)

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

[](#runs-createrun-max_prompt_tokens)

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

[](#runs-createrun-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#runs-createrun-model)

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

[](#runs-createrun-parallel_tool_calls)

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

[](#runs-createrun-reasoning_effort)

reasoning\_effort

string or null

Optional

Defaults to medium

**o-series models only**

Constrains effort on reasoning for [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `low`, `medium`, and `high`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

[](#runs-createrun-response_format)

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#runs-createrun-stream)

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

[](#runs-createrun-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

[](#runs-createrun-tool_choice)

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model. `none` means the model will not call any tools and instead generates a message. `auto` is the default value and means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user. Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

[](#runs-createrun-tools)

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

[](#runs-createrun-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

[](#runs-createrun-truncation_strategy)

truncation\_strategy

object or null

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

#### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
        "assistant_id": "asst_abc123"
      }'
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.runs.create(
      thread_id="thread_abc123",
      assistant_id="asst_abc123"
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.runs.create(
        "thread_abc123",
        { assistant_id: "asst_abc123" }
      );
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699063290,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "queued",
      "started_at": 1699063290,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699063291,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "incomplete_details": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "metadata": {},
      "usage": null,
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

Create thread and run

Beta


-------------------------------

postÂ https://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

#### Request body

[](#runs-createthreadandrun-assistant_id)

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

[](#runs-createthreadandrun-instructions)

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

[](#runs-createthreadandrun-max_completion_tokens)

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

[](#runs-createthreadandrun-max_prompt_tokens)

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

[](#runs-createthreadandrun-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#runs-createthreadandrun-model)

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

[](#runs-createthreadandrun-parallel_tool_calls)

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

[](#runs-createthreadandrun-response_format)

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#runs-createthreadandrun-stream)

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

[](#runs-createthreadandrun-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

[](#runs-createthreadandrun-thread)

thread

object

Optional

Options to create a new thread. If no thread is provided when running a request, an empty thread will be created.

Show properties

[](#runs-createthreadandrun-tool_choice)

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model. `none` means the model will not call any tools and instead generates a message. `auto` is the default value and means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user. Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

[](#runs-createthreadandrun-tool_resources)

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

[](#runs-createthreadandrun-tools)

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

[](#runs-createthreadandrun-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

[](#runs-createthreadandrun-truncation_strategy)

truncation\_strategy

object or null

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

#### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

node.js
    curl https://api.openai.com/v1/threads/runs \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
          "assistant_id": "asst_abc123",
          "thread": {
            "messages": [
              {"role": "user", "content": "Explain deep learning to a 5 year old."}
            ]
          }
        }'
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.create_and_run(
      assistant_id="asst_abc123",
      thread={
        "messages": [
          {"role": "user", "content": "Explain deep learning to a 5 year old."}
        ]
      }
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.createAndRun({
        assistant_id: "asst_abc123",
        thread: {
          messages: [
            { role: "user", content: "Explain deep learning to a 5 year old." },
          ],
        },
      });
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699076792,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "queued",
      "started_at": null,
      "expires_at": 1699077392,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": null,
      "required_action": null,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": "You are a helpful assistant.",
      "tools": [],
      "tool_resources": {},
      "metadata": {},
      "temperature": 1.0,
      "top_p": 1.0,
      "max_completion_tokens": null,
      "max_prompt_tokens": null,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "incomplete_details": null,
      "usage": null,
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

List runs

Beta


-------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

#### Path parameters

[](#runs-listruns-thread_id)

thread\_id

string

Required

The ID of the thread the run belongs to.

#### Query parameters

[](#runs-listruns-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#runs-listruns-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#runs-listruns-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#runs-listruns-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [run](/docs/api-reference/runs/object) objects.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    runs = client.beta.threads.runs.list(
      "thread_abc123"
    )
    
    print(runs)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const runs = await openai.beta.threads.runs.list(
        "thread_abc123"
      );
    
      console.log(runs);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "run_abc123",
          "object": "thread.run",
          "created_at": 1699075072,
          "assistant_id": "asst_abc123",
          "thread_id": "thread_abc123",
          "status": "completed",
          "started_at": 1699075072,
          "expires_at": null,
          "cancelled_at": null,
          "failed_at": null,
          "completed_at": 1699075073,
          "last_error": null,
          "model": "gpt-4o",
          "instructions": null,
          "incomplete_details": null,
          "tools": [
            {
              "type": "code_interpreter"
            }
          ],
          "tool_resources": {
            "code_interpreter": {
              "file_ids": [
                "file-abc123",
                "file-abc456"
              ]
            }
          },
          "metadata": {},
          "usage": {
            "prompt_tokens": 123,
            "completion_tokens": 456,
            "total_tokens": 579
          },
          "temperature": 1.0,
          "top_p": 1.0,
          "max_prompt_tokens": 1000,
          "max_completion_tokens": 1000,
          "truncation_strategy": {
            "type": "auto",
            "last_messages": null
          },
          "response_format": "auto",
          "tool_choice": "auto",
          "parallel_tool_calls": true
        },
        {
          "id": "run_abc456",
          "object": "thread.run",
          "created_at": 1699063290,
          "assistant_id": "asst_abc123",
          "thread_id": "thread_abc123",
          "status": "completed",
          "started_at": 1699063290,
          "expires_at": null,
          "cancelled_at": null,
          "failed_at": null,
          "completed_at": 1699063291,
          "last_error": null,
          "model": "gpt-4o",
          "instructions": null,
          "incomplete_details": null,
          "tools": [
            {
              "type": "code_interpreter"
            }
          ],
          "tool_resources": {
            "code_interpreter": {
              "file_ids": [
                "file-abc123",
                "file-abc456"
              ]
            }
          },
          "metadata": {},
          "usage": {
            "prompt_tokens": 123,
            "completion_tokens": 456,
            "total_tokens": 579
          },
          "temperature": 1.0,
          "top_p": 1.0,
          "max_prompt_tokens": 1000,
          "max_completion_tokens": 1000,
          "truncation_strategy": {
            "type": "auto",
            "last_messages": null
          },
          "response_format": "auto",
          "tool_choice": "auto",
          "parallel_tool_calls": true
        }
      ],
      "first_id": "run_abc123",
      "last_id": "run_abc456",
      "has_more": false
    }

Retrieve run

Beta


----------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

#### Path parameters

[](#runs-getrun-run_id)

run\_id

string

Required

The ID of the run to retrieve.

[](#runs-getrun-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

#### Returns

The [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.runs.retrieve(
      thread_id="thread_abc123",
      run_id="run_abc123"
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.runs.retrieve(
        "thread_abc123",
        "run_abc123"
      );
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699075072,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699075072,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699075073,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "incomplete_details": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "metadata": {},
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

Modify run

Beta


--------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

#### Path parameters

[](#runs-modifyrun-run_id)

run\_id

string

Required

The ID of the run to modify.

[](#runs-modifyrun-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

#### Request body

[](#runs-modifyrun-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

#### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
        "metadata": {
          "user_id": "user_abc123"
        }
      }'
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.runs.update(
      thread_id="thread_abc123",
      run_id="run_abc123",
      metadata={"user_id": "user_abc123"},
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.runs.update(
        "thread_abc123",
        "run_abc123",
        {
          metadata: {
            user_id: "user_abc123",
          },
        }
      );
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699075072,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699075072,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699075073,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "incomplete_details": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "tool_resources": {
        "code_interpreter": {
          "file_ids": [
            "file-abc123",
            "file-abc456"
          ]
        }
      },
      "metadata": {
        "user_id": "user_abc123"
      },
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

Submit tool outputs to run

Beta


------------------------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

#### Path parameters

[](#runs-submittooloutputs-run_id)

run\_id

string

Required

The ID of the run that requires the tool output submission.

[](#runs-submittooloutputs-thread_id)

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this run belongs.

#### Request body

[](#runs-submittooloutputs-tool_outputs)

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

[](#runs-submittooloutputs-stream)

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

#### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2" \
      -d '{
        "tool_outputs": [
          {
            "tool_call_id": "call_001",
            "output": "70 degrees and sunny."
          }
        ]
      }'
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.runs.submit_tool_outputs(
      thread_id="thread_123",
      run_id="run_123",
      tool_outputs=[
        {
          "tool_call_id": "call_001",
          "output": "70 degrees and sunny."
        }
      ]
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.runs.submitToolOutputs(
        "thread_123",
        "run_123",
        {
          tool_outputs: [
            {
              tool_call_id: "call_001",
              output: "70 degrees and sunny.",
            },
          ],
        }
      );
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_123",
      "object": "thread.run",
      "created_at": 1699075592,
      "assistant_id": "asst_123",
      "thread_id": "thread_123",
      "status": "queued",
      "started_at": 1699075592,
      "expires_at": 1699076192,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": null,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "tools": [
        {
          "type": "function",
          "function": {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
              "type": "object",
              "properties": {
                "location": {
                  "type": "string",
                  "description": "The city and state, e.g. San Francisco, CA"
                },
                "unit": {
                  "type": "string",
                  "enum": ["celsius", "fahrenheit"]
                }
              },
              "required": ["location"]
            }
          }
        }
      ],
      "metadata": {},
      "usage": null,
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

Cancel a run

Beta


----------------------

postÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

#### Path parameters

[](#runs-cancelrun-run_id)

run\_id

string

Required

The ID of the run to cancel.

[](#runs-cancelrun-thread_id)

thread\_id

string

Required

The ID of the thread to which this run belongs.

#### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Beta: assistants=v2" \
      -X POST
    from openai import OpenAI
    client = OpenAI()
    
    run = client.beta.threads.runs.cancel(
      thread_id="thread_abc123",
      run_id="run_abc123"
    )
    
    print(run)
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const run = await openai.beta.threads.runs.cancel(
        "thread_abc123",
        "run_abc123"
      );
    
      console.log(run);
    }
    
    main();

Response
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699076126,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "cancelling",
      "started_at": 1699076126,
      "expires_at": 1699076726,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": null,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": "You summarize books.",
      "tools": [
        {
          "type": "file_search"
        }
      ],
      "tool_resources": {
        "file_search": {
          "vector_store_ids": ["vs_123"]
        }
      },
      "metadata": {},
      "usage": null,
      "temperature": 1.0,
      "top_p": 1.0,
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

The run object

Beta


------------------------

Represents an execution run on a [thread](/docs/api-reference/threads).

[](#runs/object-assistant_id)

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run.

[](#runs/object-cancelled_at)

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

[](#runs/object-completed_at)

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

[](#runs/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

[](#runs/object-expires_at)

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

[](#runs/object-failed_at)

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

[](#runs/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#runs/object-incomplete_details)

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

[](#runs/object-instructions)

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants) used for this run.

[](#runs/object-last_error)

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

[](#runs/object-max_completion_tokens)

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

[](#runs/object-max_prompt_tokens)

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

[](#runs/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#runs/object-model)

model

string

The model that the [assistant](/docs/api-reference/assistants) used for this run.

[](#runs/object-object)

object

string

The object type, which is always `thread.run`.

[](#runs/object-parallel_tool_calls)

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

[](#runs/object-required_action)

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

[](#runs/object-response_format)

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

[](#runs/object-started_at)

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

[](#runs/object-status)

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.

[](#runs/object-temperature)

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

[](#runs/object-thread_id)

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run.

[](#runs/object-tool_choice)

tool\_choice

string or object

Controls which (if any) tool is called by the model. `none` means the model will not call any tools and instead generates a message. `auto` is the default value and means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user. Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

[](#runs/object-tools)

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.

Show possible types

[](#runs/object-top_p)

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

[](#runs/object-truncation_strategy)

truncation\_strategy

object or null

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

[](#runs/object-usage)

usage

object or null

Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).

Show properties

OBJECT The run object
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1698107661,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699073476,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699073498,
      "last_error": null,
      "model": "gpt-4o",
      "instructions": null,
      "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
      "metadata": {},
      "incomplete_details": null,
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      },
      "temperature": 1.0,
      "top_p": 1.0,
      "max_prompt_tokens": 1000,
      "max_completion_tokens": 1000,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "response_format": "auto",
      "tool_choice": "auto",
      "parallel_tool_calls": true
    }

Run steps

Beta


-------------------

Represents the steps (model and tool calls) taken during the run.

Related guide: [Assistants](/docs/assistants/overview)

List run steps

Beta


------------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

#### Path parameters

[](#run-steps-listrunsteps-run_id)

run\_id

string

Required

The ID of the run the run steps belong to.

[](#run-steps-listrunsteps-thread_id)

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

#### Query parameters

[](#run-steps-listrunsteps-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#run-steps-listrunsteps-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#run-steps-listrunsteps-include)

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

[](#run-steps-listrunsteps-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#run-steps-listrunsteps-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [run step](/docs/api-reference/run-steps/step-object) objects.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    run_steps = client.beta.threads.runs.steps.list(
        thread_id="thread_abc123",
        run_id="run_abc123"
    )
    
    print(run_steps)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const runStep = await openai.beta.threads.runs.steps.list(
        "thread_abc123",
        "run_abc123"
      );
      console.log(runStep);
    }
    
    main();

Response
    {
      "object": "list",
      "data": [
        {
          "id": "step_abc123",
          "object": "thread.run.step",
          "created_at": 1699063291,
          "run_id": "run_abc123",
          "assistant_id": "asst_abc123",
          "thread_id": "thread_abc123",
          "type": "message_creation",
          "status": "completed",
          "cancelled_at": null,
          "completed_at": 1699063291,
          "expired_at": null,
          "failed_at": null,
          "last_error": null,
          "step_details": {
            "type": "message_creation",
            "message_creation": {
              "message_id": "msg_abc123"
            }
          },
          "usage": {
            "prompt_tokens": 123,
            "completion_tokens": 456,
            "total_tokens": 579
          }
        }
      ],
      "first_id": "step_abc123",
      "last_id": "step_abc456",
      "has_more": false
    }

Retrieve run step

Beta


---------------------------

getÂ https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

#### Path parameters

[](#run-steps-getrunstep-run_id)

run\_id

string

Required

The ID of the run to which the run step belongs.

[](#run-steps-getrunstep-step_id)

step\_id

string

Required

The ID of the run step to retrieve.

[](#run-steps-getrunstep-thread_id)

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

#### Query parameters

[](#run-steps-getrunstep-include)

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

#### Returns

The [run step](/docs/api-reference/run-steps/step-object) object matching the specified ID.

Example request

node.js
    curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -H "OpenAI-Beta: assistants=v2"
    from openai import OpenAI
    client = OpenAI()
    
    run_step = client.beta.threads.runs.steps.retrieve(
        thread_id="thread_abc123",
        run_id="run_abc123",
        step_id="step_abc123"
    )
    
    print(run_step)
    import OpenAI from "openai";
    const openai = new OpenAI();
    
    async function main() {
      const runStep = await openai.beta.threads.runs.steps.retrieve(
        "thread_abc123",
        "run_abc123",
        "step_abc123"
      );
      console.log(runStep);
    }
    
    main();

Response
    {
      "id": "step_abc123",
      "object": "thread.run.step",
      "created_at": 1699063291,
      "run_id": "run_abc123",
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "type": "message_creation",
      "status": "completed",
      "cancelled_at": null,
      "completed_at": 1699063291,
      "expired_at": null,
      "failed_at": null,
      "last_error": null,
      "step_details": {
        "type": "message_creation",
        "message_creation": {
          "message_id": "msg_abc123"
        }
      },
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      }
    }

The run step object

Beta


-----------------------------

Represents a step in execution of a run.

[](#run-steps/step-object-assistant_id)

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) associated with the run step.

[](#run-steps/step-object-cancelled_at)

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

[](#run-steps/step-object-completed_at)

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

[](#run-steps/step-object-created_at)

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

[](#run-steps/step-object-expired_at)

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

[](#run-steps/step-object-failed_at)

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

[](#run-steps/step-object-id)

id

string

The identifier of the run step, which can be referenced in API endpoints.

[](#run-steps/step-object-last_error)

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

[](#run-steps/step-object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

[](#run-steps/step-object-object)

object

string

The object type, which is always `thread.run.step`.

[](#run-steps/step-object-run_id)

run\_id

string

The ID of the [run](/docs/api-reference/runs) that this run step is a part of.

[](#run-steps/step-object-status)

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

[](#run-steps/step-object-step_details)

step\_details

object

The details of the run step.

Show possible types

[](#run-steps/step-object-thread_id)

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was run.

[](#run-steps/step-object-type)

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

[](#run-steps/step-object-usage)

usage

object or null

Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.

Show properties

OBJECT The run step object
    {
      "id": "step_abc123",
      "object": "thread.run.step",
      "created_at": 1699063291,
      "run_id": "run_abc123",
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "type": "message_creation",
      "status": "completed",
      "cancelled_at": null,
      "completed_at": 1699063291,
      "expired_at": null,
      "failed_at": null,
      "last_error": null,
      "step_details": {
        "type": "message_creation",
        "message_creation": {
          "message_id": "msg_abc123"
        }
      },
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      }
    }

Streaming

Beta


-------------------

Stream the result of executing a Run or resuming a Run after submitting tool outputs. You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun), [Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs) endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream. Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the [Assistants API quickstart](/docs/assistants/overview) to learn more.

The message delta object

Beta


----------------------------------

Represents a message delta i.e. any changed fields on a message during streaming.

[](#assistants-streaming/message-delta-object-delta)

delta

object

The delta containing the fields that have changed on the Message.

Show properties

[](#assistants-streaming/message-delta-object-id)

id

string

The identifier of the message, which can be referenced in API endpoints.

[](#assistants-streaming/message-delta-object-object)

object

string

The object type, which is always `thread.message.delta`.

OBJECT The message delta object
    {
      "id": "msg_123",
      "object": "thread.message.delta",
      "delta": {
        "content": [
          {
            "index": 0,
            "type": "text",
            "text": { "value": "Hello", "annotations": [] }
          }
        ]
      }
    }

The run step delta object

Beta


-----------------------------------

Represents a run step delta i.e. any changed fields on a run step during streaming.

[](#assistants-streaming/run-step-delta-object-delta)

delta

object

The delta containing the fields that have changed on the run step.

Show properties

[](#assistants-streaming/run-step-delta-object-id)

id

string

The identifier of the run step, which can be referenced in API endpoints.

[](#assistants-streaming/run-step-delta-object-object)

object

string

The object type, which is always `thread.run.step.delta`.

OBJECT The run step delta object
    {
      "id": "step_123",
      "object": "thread.run.step.delta",
      "delta": {
        "step_details": {
          "type": "tool_calls",
          "tool_calls": [
            {
              "index": 0,
              "id": "call_123",
              "type": "code_interpreter",
              "code_interpreter": { "input": "", "outputs": [] }
            }
          ]
        }
      }
    }

Assistant stream events

Beta


---------------------------------

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

    event: thread.created
    data: {"id": "thread_123", "object": "thread", ...}

We emit events whenever a new object is created, transitions to a new state, or is being streamed in parts (deltas). For example, we emit `thread.run.created` when a new run is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses to create a message during a run, we emit a `thread.message.created event`, a `thread.message.in_progress` event, many `thread.message.delta` events, and finally a `thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to integrate the Assistants API with streaming.

[](#assistants-streaming/events-done)

done

`data` is `[DONE]`

Occurs when a stream ends.

[](#assistants-streaming/events-error)

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

[](#assistants-streaming/events-thread-created)

thread.created

`data` is a [thread](/docs/api-reference/threads/object)

Occurs when a new [thread](/docs/api-reference/threads/object) is created.

[](#assistants-streaming/events-thread-message-completed)

thread.message.completed

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is completed.

[](#assistants-streaming/events-thread-message-created)

thread.message.created

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is created.

[](#assistants-streaming/events-thread-message-delta)

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages/object) are being streamed.

[](#assistants-streaming/events-thread-message-in_progress)

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) moves to an `in_progress` state.

[](#assistants-streaming/events-thread-message-incomplete)

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) ends before it is completed.

[](#assistants-streaming/events-thread-run-cancelled)

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is cancelled.

[](#assistants-streaming/events-thread-run-cancelling)

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `cancelling` status.

[](#assistants-streaming/events-thread-run-completed)

thread.run.completed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is completed.

[](#assistants-streaming/events-thread-run-created)

thread.run.created

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a new [run](/docs/api-reference/runs/object) is created.

[](#assistants-streaming/events-thread-run-expired)

thread.run.expired

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) expires.

[](#assistants-streaming/events-thread-run-failed)

thread.run.failed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) fails.

[](#assistants-streaming/events-thread-run-in_progress)

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to an `in_progress` status.

[](#assistants-streaming/events-thread-run-incomplete)

thread.run.incomplete

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) ends with status `incomplete`.

[](#assistants-streaming/events-thread-run-queued)

thread.run.queued

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `queued` status.

[](#assistants-streaming/events-thread-run-requires_action)

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `requires_action` status.

[](#assistants-streaming/events-thread-run-step-cancelled)

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is cancelled.

[](#assistants-streaming/events-thread-run-step-completed)

thread.run.step.completed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is completed.

[](#assistants-streaming/events-thread-run-step-created)

thread.run.step.created

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is created.

[](#assistants-streaming/events-thread-run-step-delta)

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object) are being streamed.

[](#assistants-streaming/events-thread-run-step-expired)

thread.run.step.expired

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) expires.

[](#assistants-streaming/events-thread-run-step-failed)

thread.run.step.failed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) fails.

[](#assistants-streaming/events-thread-run-step-in_progress)

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) moves to an `in_progress` state.

Administration


------------------

Programmatically manage your organization. The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes. To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints. For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)

Admin API Keys


------------------

Admin API keys enable Organization Owners to programmatically manage various aspects of their organization, including users, projects, and API keys. These keys provide administrative capabilities, such as creating, updating, and deleting users; managing projects; and overseeing API key lifecycles.

Key Features of Admin API Keys:

*   User Management: Invite new users, update roles, and remove users from the organization.
    
*   Project Management: Create, update, archive projects, and manage user assignments within projects.
    
*   API Key Oversight: List, retrieve, and delete API keys associated with projects.
    

Only Organization Owners have the authority to create and utilize Admin API keys. To manage these keys, Organization Owners can navigate to the Admin Keys section of their API Platform dashboard.

For direct access to the Admin Keys management page, Organization Owners can use the following link:

[https://platform.openai.com/settings/organization/admin-keys](https://platform.openai.com/settings/organization/admin-keys)

It's crucial to handle Admin API keys with care due to their elevated permissions. Adhering to best practices, such as regular key rotation and assigning appropriate permissions, enhances security and ensures proper governance within the organization.

List all organization and project API keys.


-----------------------------------------------

getÂ https://api.openai.com/v1/organization/admin\_api\_keys

List organization API keys

#### Query parameters

[](#admin-api-keys-list-after)

after

string or null

Optional

[](#admin-api-keys-list-limit)

limit

integer

Optional

Defaults to 20

[](#admin-api-keys-list-order)

order

string

Optional

Defaults to asc

#### Returns

A list of admin and project API key objects.

Example request

curl
    curl https://api.openai.com/v1/organization/admin_api_keys?after=key_abc&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "organization.admin_api_key",
          "id": "key_abc",
          "name": "Main Admin Key",
          "redacted_value": "sk-admin...def",
          "created_at": 1711471533,
          "last_used_at": 1711471534,
          "owner": {
            "type": "service_account",
            "object": "organization.service_account",
            "id": "sa_456",
            "name": "My Service Account",
            "created_at": 1711471533,
            "role": "member"
          }
        }
      ],
      "first_id": "key_abc",
      "last_id": "key_abc",
      "has_more": false
    }

Create admin API key


------------------------

postÂ https://api.openai.com/v1/organization/admin\_api\_keys

Create an organization admin API key

#### Request body

[](#admin-api-keys-create-name)

name

string

Required

#### Returns

The created [AdminApiKey](/docs/api-reference/admin-api-keys/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/admin_api_keys \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "name": "New Admin Key"
      }'

Response
    {
      "object": "organization.admin_api_key",
      "id": "key_xyz",
      "name": "New Admin Key",
      "redacted_value": "sk-admin...xyz",
      "created_at": 1711471533,
      "last_used_at": 1711471534,
      "owner": {
        "type": "user",
        "object": "organization.user",
        "id": "user_123",
        "name": "John Doe",
        "created_at": 1711471533,
        "role": "owner"
      },
      "value": "sk-admin-1234abcd"
    }

Retrieve admin API key


--------------------------

getÂ https://api.openai.com/v1/organization/admin\_api\_keys/{key\_id}

Retrieve a single organization API key

#### Path parameters

[](#admin-api-keys-listget-key_id)

key\_id

string

Required

#### Returns

The requested [AdminApiKey](/docs/api-reference/admin-api-keys/object) object.

Example request

curl
    curl https://api.openai.com/v1/organization/admin_api_keys/key_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "organization.admin_api_key",
      "id": "key_abc",
      "name": "Main Admin Key",
      "redacted_value": "sk-admin...xyz",
      "created_at": 1711471533,
      "last_used_at": 1711471534,
      "owner": {
        "type": "user",
        "object": "organization.user",
        "id": "user_123",
        "name": "John Doe",
        "created_at": 1711471533,
        "role": "owner"
      }
    }

Delete admin API key


------------------------

deleteÂ https://api.openai.com/v1/organization/admin\_api\_keys/{key\_id}

Delete an organization admin API key

#### Path parameters

[](#admin-api-keys-delete-key_id)

key\_id

string

Required

#### Returns

A confirmation object indicating the key was deleted.

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/admin_api_keys/key_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "id": "key_abc",
      "object": "organization.admin_api_key.deleted",
      "deleted": true
    }

The admin API key object


----------------------------

Represents an individual Admin API key in an org.

[](#admin-api-keys/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) of when the API key was created

[](#admin-api-keys/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#admin-api-keys/object-last_used_at)

last\_used\_at

integer or null

The Unix timestamp (in seconds) of when the API key was last used

[](#admin-api-keys/object-name)

name

string

The name of the API key

[](#admin-api-keys/object-object)

object

string

The object type, which is always `organization.admin_api_key`

[](#admin-api-keys/object-owner)

owner

object

Show properties

[](#admin-api-keys/object-redacted_value)

redacted\_value

string

The redacted value of the API key

[](#admin-api-keys/object-value)

value

string

The value of the API key. Only shown on create.

OBJECT The admin API key object
    {
      "object": "organization.admin_api_key",
      "id": "key_abc",
      "name": "Main Admin Key",
      "redacted_value": "sk-admin...xyz",
      "created_at": 1711471533,
      "last_used_at": 1711471534,
      "owner": {
        "type": "user",
        "object": "organization.user",
        "id": "user_123",
        "name": "John Doe",
        "created_at": 1711471533,
        "role": "owner"
      }
    }

Invites


-----------

Invite and manage invitations for an organization.

List invites


----------------

getÂ https://api.openai.com/v1/organization/invites

Returns a list of invites in the organization.

#### Query parameters

[](#invite-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#invite-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [Invite](/docs/api-reference/invite/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "organization.invite",
          "id": "invite-abc",
          "email": "user@example.com",
          "role": "owner",
          "status": "accepted",
          "invited_at": 1711471533,
          "expires_at": 1711471533,
          "accepted_at": 1711471533
        }
      ],
      "first_id": "invite-abc",
      "last_id": "invite-abc",
      "has_more": false
    }

Create invite


-----------------

postÂ https://api.openai.com/v1/organization/invites

Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.

#### Request body

[](#invite-create-email)

email

string

Required

Send an email to this address

[](#invite-create-role)

role

string

Required

`owner` or `reader`

[](#invite-create-projects)

projects

array

Optional

An array of projects to which membership is granted at the same time the org invite is accepted. If omitted, the user will be invited to the default project for compatibility with legacy behavior.

Show properties

#### Returns

The created [Invite](/docs/api-reference/invite/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/invites \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "email": "anotheruser@example.com",
          "role": "reader",
          "projects": [
            {
              "id": "project-xyz",
              "role": "member"
            },
            {
              "id": "project-abc",
              "role": "owner"
            }
          ]
      }'

Response
    {
      "object": "organization.invite",
      "id": "invite-def",
      "email": "anotheruser@example.com",
      "role": "reader",
      "status": "pending",
      "invited_at": 1711471533,
      "expires_at": 1711471533,
      "accepted_at": null,
      "projects": [
        {
          "id": "project-xyz",
          "role": "member"
        },
        {
          "id": "project-abc",
          "role": "owner"
        }
      ]
    }

Retrieve invite


-------------------

getÂ https://api.openai.com/v1/organization/invites/{invite\_id}

Retrieves an invite.

#### Path parameters

[](#invite-retrieve-invite_id)

invite\_id

string

Required

The ID of the invite to retrieve.

#### Returns

The [Invite](/docs/api-reference/invite/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/invites/invite-abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.invite",
        "id": "invite-abc",
        "email": "user@example.com",
        "role": "owner",
        "status": "accepted",
        "invited_at": 1711471533,
        "expires_at": 1711471533,
        "accepted_at": 1711471533
    }

Delete invite


-----------------

deleteÂ https://api.openai.com/v1/organization/invites/{invite\_id}

Delete an invite. If the invite has already been accepted, it cannot be deleted.

#### Path parameters

[](#invite-delete-invite_id)

invite\_id

string

Required

The ID of the invite to delete.

#### Returns

Confirmation that the invite has been deleted

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.invite.deleted",
        "id": "invite-abc",
        "deleted": true
    }

The invite object


---------------------

Represents an individual `invite` to the organization.

[](#invite/object-accepted_at)

accepted\_at

integer

The Unix timestamp (in seconds) of when the invite was accepted.

[](#invite/object-email)

email

string

The email address of the individual to whom the invite was sent

[](#invite/object-expires_at)

expires\_at

integer

The Unix timestamp (in seconds) of when the invite expires.

[](#invite/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#invite/object-invited_at)

invited\_at

integer

The Unix timestamp (in seconds) of when the invite was sent.

[](#invite/object-object)

object

string

The object type, which is always `organization.invite`

[](#invite/object-projects)

projects

array

The projects that were granted membership upon acceptance of the invite.

Show properties

[](#invite/object-role)

role

string

`owner` or `reader`

[](#invite/object-status)

status

string

`accepted`,`expired`, or `pending`

OBJECT The invite object
    {
      "object": "organization.invite",
      "id": "invite-abc",
      "email": "user@example.com",
      "role": "owner",
      "status": "accepted",
      "invited_at": 1711471533,
      "expires_at": 1711471533,
      "accepted_at": 1711471533,
      "projects": [
        {
          "id": "project-xyz",
          "role": "member"
        }
      ]
    }

Users


---------

Manage users and their role in an organization.

List users


--------------

getÂ https://api.openai.com/v1/organization/users

Lists all of the users in the organization.

#### Query parameters

[](#users-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#users-list-emails)

emails

array

Optional

Filter by the email address of users.

[](#users-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [User](/docs/api-reference/users/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "object": "organization.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
        ],
        "first_id": "user-abc",
        "last_id": "user-xyz",
        "has_more": false
    }

Modify user


---------------

postÂ https://api.openai.com/v1/organization/users/{user\_id}

Modifies a user's role in the organization.

#### Path parameters

[](#users-modify-user_id)

user\_id

string

Required

The ID of the user.

#### Request body

[](#users-modify-role)

role

string

Required

`owner` or `reader`

#### Returns

The updated [User](/docs/api-reference/users/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "role": "owner"
      }'

Response
    {
        "object": "organization.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Retrieve user


-----------------

getÂ https://api.openai.com/v1/organization/users/{user\_id}

Retrieves a user by their identifier.

#### Path parameters

[](#users-retrieve-user_id)

user\_id

string

Required

The ID of the user.

#### Returns

The [User](/docs/api-reference/users/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Delete user


---------------

deleteÂ https://api.openai.com/v1/organization/users/{user\_id}

Deletes a user from the organization.

#### Path parameters

[](#users-delete-user_id)

user\_id

string

Required

The ID of the user.

#### Returns

Confirmation of the deleted user

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.user.deleted",
        "id": "user_abc",
        "deleted": true
    }

The user object


-------------------

Represents an individual `user` within an organization.

[](#users/object-added_at)

added\_at

integer

The Unix timestamp (in seconds) of when the user was added.

[](#users/object-email)

email

string

The email address of the user

[](#users/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#users/object-name)

name

string

The name of the user

[](#users/object-object)

object

string

The object type, which is always `organization.user`

[](#users/object-role)

role

string

`owner` or `reader`

OBJECT The user object
    {
        "object": "organization.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Projects


------------

Manage the projects within an orgnanization includes creation, updating, and archiving or projects. The Default project cannot be archived.

List projects


-----------------

getÂ https://api.openai.com/v1/organization/projects

Returns a list of projects.

#### Query parameters

[](#projects-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#projects-list-include_archived)

include\_archived

boolean

Optional

Defaults to false

If `true` returns all projects including those that have been `archived`. Archived projects are not included by default.

[](#projects-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [Project](/docs/api-reference/projects/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "id": "proj_abc",
                "object": "organization.project",
                "name": "Project example",
                "created_at": 1711471533,
                "archived_at": null,
                "status": "active"
            }
        ],
        "first_id": "proj-abc",
        "last_id": "proj-xyz",
        "has_more": false
    }

Create project


------------------

postÂ https://api.openai.com/v1/organization/projects

Create a new project in the organization. Projects can be created and archived, but cannot be deleted.

#### Request body

[](#projects-create-name)

name

string

Required

The friendly name of the project, this name appears in reports.

#### Returns

The created [Project](/docs/api-reference/projects/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "name": "Project ABC"
      }'

Response
    {
        "id": "proj_abc",
        "object": "organization.project",
        "name": "Project ABC",
        "created_at": 1711471533,
        "archived_at": null,
        "status": "active"
    }

Retrieve project


--------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}

Retrieves a project.

#### Path parameters

[](#projects-retrieve-project_id)

project\_id

string

Required

The ID of the project.

#### Returns

The [Project](/docs/api-reference/projects/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "id": "proj_abc",
        "object": "organization.project",
        "name": "Project example",
        "created_at": 1711471533,
        "archived_at": null,
        "status": "active"
    }

Modify project


------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}

Modifies a project in the organization.

#### Path parameters

[](#projects-modify-project_id)

project\_id

string

Required

The ID of the project.

#### Request body

[](#projects-modify-name)

name

string

Required

The updated name of the project, this name appears in reports.

#### Returns

The updated [Project](/docs/api-reference/projects/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "name": "Project DEF"
      }'

Archive project


-------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/archive

Archives a project in the organization. Archived projects cannot be used or updated.

#### Path parameters

[](#projects-archive-project_id)

project\_id

string

Required

The ID of the project.

#### Returns

The archived [Project](/docs/api-reference/projects/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "id": "proj_abc",
        "object": "organization.project",
        "name": "Project DEF",
        "created_at": 1711471533,
        "archived_at": 1711471533,
        "status": "archived"
    }

The project object


----------------------

Represents an individual project.

[](#projects/object-archived_at)

archived\_at

integer or null

The Unix timestamp (in seconds) of when the project was archived or `null`.

[](#projects/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) of when the project was created.

[](#projects/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#projects/object-name)

name

string

The name of the project. This appears in reporting.

[](#projects/object-object)

object

string

The object type, which is always `organization.project`

[](#projects/object-status)

status

string

`active` or `archived`

OBJECT The project object
    {
        "id": "proj_abc",
        "object": "organization.project",
        "name": "Project example",
        "created_at": 1711471533,
        "archived_at": null,
        "status": "active"
    }

Project users


-----------------

Manage users within a project, including adding, updating roles, and removing users.

List project users


----------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/users

Returns a list of users in the project.

#### Path parameters

[](#project-users-list-project_id)

project\_id

string

Required

The ID of the project.

#### Query parameters

[](#project-users-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#project-users-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [ProjectUser](/docs/api-reference/project-users/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "object": "organization.project.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
        ],
        "first_id": "user-abc",
        "last_id": "user-xyz",
        "has_more": false
    }

Create project user


-----------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/users

Adds a user to the project. Users must already be members of the organization to be added to a project.

#### Path parameters

[](#project-users-creeate-project_id)

project\_id

string

Required

The ID of the project.

#### Request body

[](#project-users-creeate-role)

role

string

Required

`owner` or `member`

[](#project-users-creeate-user_id)

user\_id

string

Required

The ID of the user.

#### Returns

The created [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "user_id": "user_abc",
          "role": "member"
      }'

Response
    {
        "object": "organization.project.user",
        "id": "user_abc",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Retrieve project user


-------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Retrieves a user in the project.

#### Path parameters

[](#project-users-retrieve-project_id)

project\_id

string

Required

The ID of the project.

[](#project-users-retrieve-user_id)

user\_id

string

Required

The ID of the user.

#### Returns

The [ProjectUser](/docs/api-reference/project-users/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Modify project user


-----------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Modifies a user's role in the project.

#### Path parameters

[](#project-users-modify-project_id)

project\_id

string

Required

The ID of the project.

[](#project-users-modify-user_id)

user\_id

string

Required

The ID of the user.

#### Request body

[](#project-users-modify-role)

role

string

Required

`owner` or `member`

#### Returns

The updated [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "role": "owner"
      }'

Response
    {
        "object": "organization.project.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Delete project user


-----------------------

deleteÂ https://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Deletes a user from the project.

#### Path parameters

[](#project-users-delete-project_id)

project\_id

string

Required

The ID of the project.

[](#project-users-delete-user_id)

user\_id

string

Required

The ID of the user.

#### Returns

Confirmation that project has been deleted or an error in case of an archived project, which has no users

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.user.deleted",
        "id": "user_abc",
        "deleted": true
    }

The project user object


---------------------------

Represents an individual user in a project.

[](#project-users/object-added_at)

added\_at

integer

The Unix timestamp (in seconds) of when the project was added.

[](#project-users/object-email)

email

string

The email address of the user

[](#project-users/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#project-users/object-name)

name

string

The name of the user

[](#project-users/object-object)

object

string

The object type, which is always `organization.project.user`

[](#project-users/object-role)

role

string

`owner` or `member`

OBJECT The project user object
    {
        "object": "organization.project.user",
        "id": "user_abc",
        "name": "First Last",
        "email": "user@example.com",
        "role": "owner",
        "added_at": 1711471533
    }

Project service accounts


----------------------------

Manage service accounts within a project. A service account is a bot user that is not associated with a user. If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts do not have this limitation. However, service accounts can also be deleted from a project.

List project service accounts


---------------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Returns a list of service accounts in the project.

#### Path parameters

[](#project-service-accounts-list-project_id)

project\_id

string

Required

The ID of the project.

#### Query parameters

[](#project-service-accounts-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#project-service-accounts-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "object": "organization.project.service_account",
                "id": "svc_acct_abc",
                "name": "Service Account",
                "role": "owner",
                "created_at": 1711471533
            }
        ],
        "first_id": "svc_acct_abc",
        "last_id": "svc_acct_xyz",
        "has_more": false
    }

Create project service account


----------------------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Creates a new service account in the project. This also returns an unredacted API key for the service account.

#### Path parameters

[](#project-service-accounts-create-project_id)

project\_id

string

Required

The ID of the project.

#### Request body

[](#project-service-accounts-create-name)

name

string

Required

The name of the service account being created.

#### Returns

The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "name": "Production App"
      }'

Response
    {
        "object": "organization.project.service_account",
        "id": "svc_acct_abc",
        "name": "Production App",
        "role": "member",
        "created_at": 1711471533,
        "api_key": {
            "object": "organization.project.service_account.api_key",
            "value": "sk-abcdefghijklmnop123",
            "name": "Secret Key",
            "created_at": 1711471533,
            "id": "key_abc"
        }
    }

Retrieve project service account


------------------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Retrieves a service account in the project.

#### Path parameters

[](#project-service-accounts-retrieve-project_id)

project\_id

string

Required

The ID of the project.

[](#project-service-accounts-retrieve-service_account_id)

service\_account\_id

string

Required

The ID of the service account.

#### Returns

The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.service_account",
        "id": "svc_acct_abc",
        "name": "Service Account",
        "role": "owner",
        "created_at": 1711471533
    }

Delete project service account


----------------------------------

deleteÂ https://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Deletes a service account from the project.

#### Path parameters

[](#project-service-accounts-delete-project_id)

project\_id

string

Required

The ID of the project.

[](#project-service-accounts-delete-service_account_id)

service\_account\_id

string

Required

The ID of the service account.

#### Returns

Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.service_account.deleted",
        "id": "svc_acct_abc",
        "deleted": true
    }

The project service account object


--------------------------------------

Represents an individual service account in a project.

[](#project-service-accounts/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) of when the service account was created

[](#project-service-accounts/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#project-service-accounts/object-name)

name

string

The name of the service account

[](#project-service-accounts/object-object)

object

string

The object type, which is always `organization.project.service_account`

[](#project-service-accounts/object-role)

role

string

`owner` or `member`

OBJECT The project service account object
    {
        "object": "organization.project.service_account",
        "id": "svc_acct_abc",
        "name": "Service Account",
        "role": "owner",
        "created_at": 1711471533
    }

Project API keys


--------------------

Manage API keys for a given project. Supports listing and deleting keys for users. This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.

List project API keys


-------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/api\_keys

Returns a list of API keys in the project.

#### Path parameters

[](#project-api-keys-list-project_id)

project\_id

string

Required

The ID of the project.

#### Query parameters

[](#project-api-keys-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#project-api-keys-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

#### Returns

A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "object": "organization.project.api_key",
                "redacted_value": "sk-abc...def",
                "name": "My API Key",
                "created_at": 1711471533,
                "last_used_at": 1711471534,
                "id": "key_abc",
                "owner": {
                    "type": "user",
                    "user": {
                        "object": "organization.project.user",
                        "id": "user_abc",
                        "name": "First Last",
                        "email": "user@example.com",
                        "role": "owner",
                        "added_at": 1711471533
                    }
                }
            }
        ],
        "first_id": "key_abc",
        "last_id": "key_xyz",
        "has_more": false
    }

Retrieve project API key


----------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Retrieves an API key in the project.

#### Path parameters

[](#project-api-keys-retrieve-key_id)

key\_id

string

Required

The ID of the API key.

[](#project-api-keys-retrieve-project_id)

project\_id

string

Required

The ID of the project.

#### Returns

The [ProjectApiKey](/docs/api-reference/project-api-keys/object) object matching the specified ID.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.api_key",
        "redacted_value": "sk-abc...def",
        "name": "My API Key",
        "created_at": 1711471533,
        "last_used_at": 1711471534,
        "id": "key_abc",
        "owner": {
            "type": "user",
            "user": {
                "object": "organization.project.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "added_at": 1711471533
            }
        }
    }

Delete project API key


--------------------------

deleteÂ https://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Deletes an API key from the project.

#### Path parameters

[](#project-api-keys-delete-key_id)

key\_id

string

Required

The ID of the API key.

[](#project-api-keys-delete-project_id)

project\_id

string

Required

The ID of the project.

#### Returns

Confirmation of the key's deletion or an error if the key belonged to a service account

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "organization.project.api_key.deleted",
        "id": "key_abc",
        "deleted": true
    }

The project API key object


------------------------------

Represents an individual API key in a project.

[](#project-api-keys/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) of when the API key was created

[](#project-api-keys/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#project-api-keys/object-last_used_at)

last\_used\_at

integer

The Unix timestamp (in seconds) of when the API key was last used.

[](#project-api-keys/object-name)

name

string

The name of the API key

[](#project-api-keys/object-object)

object

string

The object type, which is always `organization.project.api_key`

[](#project-api-keys/object-owner)

owner

object

Show properties

[](#project-api-keys/object-redacted_value)

redacted\_value

string

The redacted value of the API key

OBJECT The project API key object
    {
        "object": "organization.project.api_key",
        "redacted_value": "sk-abc...def",
        "name": "My API Key",
        "created_at": 1711471533,
        "last_used_at": 1711471534,
        "id": "key_abc",
        "owner": {
            "type": "user",
            "user": {
                "object": "organization.project.user",
                "id": "user_abc",
                "name": "First Last",
                "email": "user@example.com",
                "role": "owner",
                "created_at": 1711471533
            }
        }
    }

Project rate limits


-----------------------

Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.

List project rate limits


----------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits

Returns the rate limits per model for a project.

#### Path parameters

[](#project-rate-limits-list-project_id)

project\_id

string

Required

The ID of the project.

#### Query parameters

[](#project-rate-limits-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#project-rate-limits-list-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#project-rate-limits-list-limit)

limit

integer

Optional

Defaults to 100

A limit on the number of objects to be returned. The default is 100.

#### Returns

A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
              "object": "project.rate_limit",
              "id": "rl-ada",
              "model": "ada",
              "max_requests_per_1_minute": 600,
              "max_tokens_per_1_minute": 150000,
              "max_images_per_1_minute": 10
            }
        ],
        "first_id": "rl-ada",
        "last_id": "rl-ada",
        "has_more": false
    }

Modify project rate limit


-----------------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits/{rate\_limit\_id}

Updates a project rate limit.

#### Path parameters

[](#project-rate-limits-update-project_id)

project\_id

string

Required

The ID of the project.

[](#project-rate-limits-update-rate_limit_id)

rate\_limit\_id

string

Required

The ID of the rate limit.

#### Request body

[](#project-rate-limits-update-batch_1_day_max_input_tokens)

batch\_1\_day\_max\_input\_tokens

integer

Optional

The maximum batch input tokens per day. Only relevant for certain models.

[](#project-rate-limits-update-max_audio_megabytes_per_1_minute)

max\_audio\_megabytes\_per\_1\_minute

integer

Optional

The maximum audio megabytes per minute. Only relevant for certain models.

[](#project-rate-limits-update-max_images_per_1_minute)

max\_images\_per\_1\_minute

integer

Optional

The maximum images per minute. Only relevant for certain models.

[](#project-rate-limits-update-max_requests_per_1_day)

max\_requests\_per\_1\_day

integer

Optional

The maximum requests per day. Only relevant for certain models.

[](#project-rate-limits-update-max_requests_per_1_minute)

max\_requests\_per\_1\_minute

integer

Optional

The maximum requests per minute.

[](#project-rate-limits-update-max_tokens_per_1_minute)

max\_tokens\_per\_1\_minute

integer

Optional

The maximum tokens per minute.

#### Returns

The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
      -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
      -H "Content-Type: application/json" \
      -d '{
          "max_requests_per_1_minute": 500
      }'

Response
    {
        "object": "project.rate_limit",
        "id": "rl-ada",
        "model": "ada",
        "max_requests_per_1_minute": 600,
        "max_tokens_per_1_minute": 150000,
        "max_images_per_1_minute": 10
      }

The project rate limit object


---------------------------------

Represents a project rate limit config.

[](#project-rate-limits/object-batch_1_day_max_input_tokens)

batch\_1\_day\_max\_input\_tokens

integer

The maximum batch input tokens per day. Only present for relevant models.

[](#project-rate-limits/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#project-rate-limits/object-max_audio_megabytes_per_1_minute)

max\_audio\_megabytes\_per\_1\_minute

integer

The maximum audio megabytes per minute. Only present for relevant models.

[](#project-rate-limits/object-max_images_per_1_minute)

max\_images\_per\_1\_minute

integer

The maximum images per minute. Only present for relevant models.

[](#project-rate-limits/object-max_requests_per_1_day)

max\_requests\_per\_1\_day

integer

The maximum requests per day. Only present for relevant models.

[](#project-rate-limits/object-max_requests_per_1_minute)

max\_requests\_per\_1\_minute

integer

The maximum requests per minute.

[](#project-rate-limits/object-max_tokens_per_1_minute)

max\_tokens\_per\_1\_minute

integer

The maximum tokens per minute.

[](#project-rate-limits/object-model)

model

string

The model this rate limit applies to.

[](#project-rate-limits/object-object)

object

string

The object type, which is always `project.rate_limit`

OBJECT The project rate limit object
    {
        "object": "project.rate_limit",
        "id": "rl_ada",
        "model": "ada",
        "max_requests_per_1_minute": 600,
        "max_tokens_per_1_minute": 150000,
        "max_images_per_1_minute": 10
    }

Audit logs


--------------

Logs of user actions and configuration changes within this organization. To log events, you must activate logging in the [Organization Settings](/settings/organization/general). Once activated, for security reasons, logging cannot be deactivated.

List audit logs


-------------------

getÂ https://api.openai.com/v1/organization/audit\_logs

List user actions and configuration changes within this organization.

#### Query parameters

[](#audit-logs-list-actor_emails)

actor\_emails\[\]

array

Optional

Return only events performed by users with these emails.

[](#audit-logs-list-actor_ids)

actor\_ids\[\]

array

Optional

Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.

[](#audit-logs-list-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#audit-logs-list-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

[](#audit-logs-list-effective_at)

effective\_at

object

Optional

Return only events whose `effective_at` (Unix seconds) is in this range.

Show properties

[](#audit-logs-list-event_types)

event\_types\[\]

array

Optional

Return only events with a `type` in one of these values. For example, `project.created`. For all options, see the documentation for the [audit log object](/docs/api-reference/audit-logs/object).

[](#audit-logs-list-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#audit-logs-list-project_ids)

project\_ids\[\]

array

Optional

Return only events for these projects.

[](#audit-logs-list-resource_ids)

resource\_ids\[\]

array

Optional

Return only events performed on these targets. For example, a project ID updated.

#### Returns

A list of paginated [Audit Log](/docs/api-reference/audit-logs/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/audit_logs \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "list",
        "data": [
            {
                "id": "audit_log-xxx_yyyymmdd",
                "type": "project.archived",
                "effective_at": 1722461446,
                "actor": {
                    "type": "api_key",
                    "api_key": {
                        "type": "user",
                        "user": {
                            "id": "user-xxx",
                            "email": "user@example.com"
                        }
                    }
                },
                "project.archived": {
                    "id": "proj_abc"
                },
            },
            {
                "id": "audit_log-yyy__20240101",
                "type": "api_key.updated",
                "effective_at": 1720804190,
                "actor": {
                    "type": "session",
                    "session": {
                        "user": {
                            "id": "user-xxx",
                            "email": "user@example.com"
                        },
                        "ip_address": "127.0.0.1",
                        "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                        "ja3": "a497151ce4338a12c4418c44d375173e",
                        "ja4": "q13d0313h3_55b375c5d22e_c7319ce65786",
                        "ip_address_details": {
                          "country": "US",
                          "city": "San Francisco",
                          "region": "California",
                          "region_code": "CA",
                          "asn": "1234",
                          "latitude": "37.77490",
                          "longitude": "-122.41940"
                        }
                    }
                },
                "api_key.updated": {
                    "id": "key_xxxx",
                    "data": {
                        "scopes": ["resource_2.operation_2"]
                    }
                },
            }
        ],
        "first_id": "audit_log-xxx__20240101",
        "last_id": "audit_log_yyy__20240101",
        "has_more": true
    }

The audit log object


------------------------

A log of a user action or configuration change within this organization.

[](#audit-logs/object-actor)

actor

object

The actor who performed the audit logged action.

Show properties

[](#audit-logs/object-api_key-created)

api\_key.created

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-api_key-deleted)

api\_key.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-api_key-updated)

api\_key.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-certificate-created)

certificate.created

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-certificate-deleted)

certificate.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-certificate-updated)

certificate.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-certificates-activated)

certificates.activated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-certificates-deactivated)

certificates.deactivated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-checkpoint_permission-created)

checkpoint\_permission.created

object

The project and fine-tuned model checkpoint that the checkpoint permission was created for.

Show properties

[](#audit-logs/object-checkpoint_permission-deleted)

checkpoint\_permission.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-effective_at)

effective\_at

integer

The Unix timestamp (in seconds) of the event.

[](#audit-logs/object-id)

id

string

The ID of this log.

[](#audit-logs/object-invite-accepted)

invite.accepted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-invite-deleted)

invite.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-invite-sent)

invite.sent

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-login-failed)

login.failed

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-logout-failed)

logout.failed

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-organization-updated)

organization.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-project)

project

object

The project that the action was scoped to. Absent for actions not scoped to projects.

Show properties

[](#audit-logs/object-project-archived)

project.archived

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-project-created)

project.created

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-project-updated)

project.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-rate_limit-deleted)

rate\_limit.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-rate_limit-updated)

rate\_limit.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-service_account-created)

service\_account.created

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-service_account-deleted)

service\_account.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-service_account-updated)

service\_account.updated

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-type)

type

string

The event type.

[](#audit-logs/object-user-added)

user.added

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-user-deleted)

user.deleted

object

The details for events with this `type`.

Show properties

[](#audit-logs/object-user-updated)

user.updated

object

The details for events with this `type`.

Show properties

OBJECT The audit log object
    {
        "id": "req_xxx_20240101",
        "type": "api_key.created",
        "effective_at": 1720804090,
        "actor": {
            "type": "session",
            "session": {
                "user": {
                    "id": "user-xxx",
                    "email": "user@example.com"
                },
                "ip_address": "127.0.0.1",
                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
        },
        "api_key.created": {
            "id": "key_xxxx",
            "data": {
                "scopes": ["resource.operation"]
            }
        }
    }

Usage


---------

The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.

Completions


---------------

getÂ https://api.openai.com/v1/organization/usage/completions

Get completions usage details for the organization.

#### Query parameters

[](#usage-completions-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-completions-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-completions-batch)

batch

boolean

Optional

If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.

[](#usage-completions-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-completions-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-completions-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any combination of them.

[](#usage-completions-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-completions-models)

models

array

Optional

Return only usage for these models.

[](#usage-completions-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-completions-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-completions-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.completions.result",
                        "input_tokens": 1000,
                        "output_tokens": 500,
                        "input_cached_tokens": 800,
                        "input_audio_tokens": 0,
                        "output_audio_tokens": 0,
                        "num_model_requests": 5,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null,
                        "batch": null
                    }
                ]
            }
        ],
        "has_more": true,
        "next_page": "page_AAAAAGdGxdEiJdKOAAAAAGcqsYA="
    }

Completions usage object


----------------------------

The aggregated completions usage details of the specific time bucket.

[](#usage/completions_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/completions_object-batch)

batch

boolean or null

When `group_by=batch`, this field tells whether the grouped usage result is batch or not.

[](#usage/completions_object-input_audio_tokens)

input\_audio\_tokens

integer

The aggregated number of audio input tokens used, including cached tokens.

[](#usage/completions_object-input_cached_tokens)

input\_cached\_tokens

integer

The aggregated number of text input tokens that has been cached from previous requests. For customers subscribe to scale tier, this includes scale tier tokens.

[](#usage/completions_object-input_tokens)

input\_tokens

integer

The aggregated number of text input tokens used, including cached tokens. For customers subscribe to scale tier, this includes scale tier tokens.

[](#usage/completions_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/completions_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/completions_object-object)

object

string

[](#usage/completions_object-output_audio_tokens)

output\_audio\_tokens

integer

The aggregated number of audio output tokens used.

[](#usage/completions_object-output_tokens)

output\_tokens

integer

The aggregated number of text output tokens used. For customers subscribe to scale tier, this includes scale tier tokens.

[](#usage/completions_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/completions_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Completions usage object
    {
        "object": "organization.usage.completions.result",
        "input_tokens": 5000,
        "output_tokens": 1000,
        "input_cached_tokens": 4000,
        "input_audio_tokens": 300,
        "output_audio_tokens": 200,
        "num_model_requests": 5,
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "gpt-4o-mini-2024-07-18",
        "batch": false
    }

Embeddings


--------------

getÂ https://api.openai.com/v1/organization/usage/embeddings

Get embeddings usage details for the organization.

#### Query parameters

[](#usage-embeddings-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-embeddings-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-embeddings-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-embeddings-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-embeddings-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

[](#usage-embeddings-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-embeddings-models)

models

array

Optional

Return only usage for these models.

[](#usage-embeddings-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-embeddings-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-embeddings-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.embeddings.result",
                        "input_tokens": 16,
                        "num_model_requests": 2,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Embeddings usage object


---------------------------

The aggregated embeddings usage details of the specific time bucket.

[](#usage/embeddings_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/embeddings_object-input_tokens)

input\_tokens

integer

The aggregated number of input tokens used.

[](#usage/embeddings_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/embeddings_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/embeddings_object-object)

object

string

[](#usage/embeddings_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/embeddings_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Embeddings usage object
    {
        "object": "organization.usage.embeddings.result",
        "input_tokens": 20,
        "num_model_requests": 2,
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "text-embedding-ada-002-v2"
    }

Moderations


---------------

getÂ https://api.openai.com/v1/organization/usage/moderations

Get moderations usage details for the organization.

#### Query parameters

[](#usage-moderations-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-moderations-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-moderations-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-moderations-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-moderations-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

[](#usage-moderations-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-moderations-models)

models

array

Optional

Return only usage for these models.

[](#usage-moderations-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-moderations-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-moderations-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.moderations.result",
                        "input_tokens": 16,
                        "num_model_requests": 2,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Moderations usage object


----------------------------

The aggregated moderations usage details of the specific time bucket.

[](#usage/moderations_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/moderations_object-input_tokens)

input\_tokens

integer

The aggregated number of input tokens used.

[](#usage/moderations_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/moderations_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/moderations_object-object)

object

string

[](#usage/moderations_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/moderations_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Moderations usage object
    {
        "object": "organization.usage.moderations.result",
        "input_tokens": 20,
        "num_model_requests": 2,
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "text-moderation"
    }

Images


----------

getÂ https://api.openai.com/v1/organization/usage/images

Get images usage details for the organization.

#### Query parameters

[](#usage-images-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-images-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-images-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-images-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-images-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source` or any combination of them.

[](#usage-images-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-images-models)

models

array

Optional

Return only usage for these models.

[](#usage-images-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-images-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-images-sizes)

sizes

array

Optional

Return only usages for these image sizes. Possible values are `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination of them.

[](#usage-images-sources)

sources

array

Optional

Return only usages for these sources. Possible values are `image.generation`, `image.edit`, `image.variation` or any combination of them.

[](#usage-images-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.images.result",
                        "images": 2,
                        "num_model_requests": 2,
                        "size": null,
                        "source": null,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Images usage object


-----------------------

The aggregated images usage details of the specific time bucket.

[](#usage/images_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/images_object-images)

images

integer

The number of images processed.

[](#usage/images_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/images_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/images_object-object)

object

string

[](#usage/images_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/images_object-size)

size

string or null

When `group_by=size`, this field provides the image size of the grouped usage result.

[](#usage/images_object-source)

source

string or null

When `group_by=source`, this field provides the source of the grouped usage result, possible values are `image.generation`, `image.edit`, `image.variation`.

[](#usage/images_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Images usage object
    {
        "object": "organization.usage.images.result",
        "images": 2,
        "num_model_requests": 2,
        "size": "1024x1024",
        "source": "image.generation",
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "dall-e-3"
    }

Audio speeches


------------------

getÂ https://api.openai.com/v1/organization/usage/audio\_speeches

Get audio speeches usage details for the organization.

#### Query parameters

[](#usage-audio_speeches-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-audio_speeches-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-audio_speeches-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-audio_speeches-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-audio_speeches-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

[](#usage-audio_speeches-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-audio_speeches-models)

models

array

Optional

Return only usage for these models.

[](#usage-audio_speeches-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-audio_speeches-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-audio_speeches-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.audio_speeches.result",
                        "characters": 45,
                        "num_model_requests": 1,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Audio speeches usage object


-------------------------------

The aggregated audio speeches usage details of the specific time bucket.

[](#usage/audio_speeches_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/audio_speeches_object-characters)

characters

integer

The number of characters processed.

[](#usage/audio_speeches_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/audio_speeches_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/audio_speeches_object-object)

object

string

[](#usage/audio_speeches_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/audio_speeches_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Audio speeches usage object
    {
        "object": "organization.usage.audio_speeches.result",
        "characters": 45,
        "num_model_requests": 1,
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "tts-1"
    }

Audio transcriptions


------------------------

getÂ https://api.openai.com/v1/organization/usage/audio\_transcriptions

Get audio transcriptions usage details for the organization.

#### Query parameters

[](#usage-audio_transcriptions-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-audio_transcriptions-api_key_ids)

api\_key\_ids

array

Optional

Return only usage for these API keys.

[](#usage-audio_transcriptions-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-audio_transcriptions-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-audio_transcriptions-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

[](#usage-audio_transcriptions-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-audio_transcriptions-models)

models

array

Optional

Return only usage for these models.

[](#usage-audio_transcriptions-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-audio_transcriptions-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

[](#usage-audio_transcriptions-user_ids)

user\_ids

array

Optional

Return only usage for these users.

#### Returns

A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.audio_transcriptions.result",
                        "seconds": 20,
                        "num_model_requests": 1,
                        "project_id": null,
                        "user_id": null,
                        "api_key_id": null,
                        "model": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Audio transcriptions usage object


-------------------------------------

The aggregated audio transcriptions usage details of the specific time bucket.

[](#usage/audio_transcriptions_object-api_key_id)

api\_key\_id

string or null

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

[](#usage/audio_transcriptions_object-model)

model

string or null

When `group_by=model`, this field provides the model name of the grouped usage result.

[](#usage/audio_transcriptions_object-num_model_requests)

num\_model\_requests

integer

The count of requests made to the model.

[](#usage/audio_transcriptions_object-object)

object

string

[](#usage/audio_transcriptions_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/audio_transcriptions_object-seconds)

seconds

integer

The number of seconds processed.

[](#usage/audio_transcriptions_object-user_id)

user\_id

string or null

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

OBJECT Audio transcriptions usage object
    {
        "object": "organization.usage.audio_transcriptions.result",
        "seconds": 10,
        "num_model_requests": 1,
        "project_id": "proj_abc",
        "user_id": "user-abc",
        "api_key_id": "key_abc",
        "model": "tts-1"
    }

Vector stores


-----------------

getÂ https://api.openai.com/v1/organization/usage/vector\_stores

Get vector stores usage details for the organization.

#### Query parameters

[](#usage-vector_stores-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-vector_stores-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-vector_stores-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-vector_stores-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

[](#usage-vector_stores-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-vector_stores-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-vector_stores-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

#### Returns

A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.vector_stores.result",
                        "usage_bytes": 1024,
                        "project_id": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Vector stores usage object


------------------------------

The aggregated vector stores usage details of the specific time bucket.

[](#usage/vector_stores_object-object)

object

string

[](#usage/vector_stores_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

[](#usage/vector_stores_object-usage_bytes)

usage\_bytes

integer

The vector stores usage in bytes.

OBJECT Vector stores usage object
    {
        "object": "organization.usage.vector_stores.result",
        "usage_bytes": 1024,
        "project_id": "proj_abc"
    }

Code interpreter sessions


-----------------------------

getÂ https://api.openai.com/v1/organization/usage/code\_interpreter\_sessions

Get code interpreter sessions usage details for the organization.

#### Query parameters

[](#usage-code_interpreter_sessions-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-code_interpreter_sessions-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

[](#usage-code_interpreter_sessions-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-code_interpreter_sessions-group_by)

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

[](#usage-code_interpreter_sessions-limit)

limit

integer

Optional

Specifies the number of buckets to return.

*   `bucket_width=1d`: default: 7, max: 31
*   `bucket_width=1h`: default: 24, max: 168
*   `bucket_width=1m`: default: 60, max: 1440

[](#usage-code_interpreter_sessions-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-code_interpreter_sessions-project_ids)

project\_ids

array

Optional

Return only usage for these projects.

#### Returns

A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.usage.code_interpreter_sessions.result",
                        "num_sessions": 1,
                        "project_id": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Code interpreter sessions usage object


------------------------------------------

The aggregated code interpreter sessions usage details of the specific time bucket.

[](#usage/code_interpreter_sessions_object-num_sessions)

num\_sessions

integer

The number of code interpreter sessions.

[](#usage/code_interpreter_sessions_object-object)

object

string

[](#usage/code_interpreter_sessions_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Code interpreter sessions usage object
    {
        "object": "organization.usage.code_interpreter_sessions.result",
        "num_sessions": 1,
        "project_id": "proj_abc"
    }

Costs


---------

getÂ https://api.openai.com/v1/organization/costs

Get costs details for the organization.

#### Query parameters

[](#usage-costs-start_time)

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

[](#usage-costs-bucket_width)

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently only `1d` is supported, default to `1d`.

[](#usage-costs-end_time)

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

[](#usage-costs-group_by)

group\_by

array

Optional

Group the costs by the specified fields. Support fields include `project_id`, `line_item` and any combination of them.

[](#usage-costs-limit)

limit

integer

Optional

Defaults to 7

A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.

[](#usage-costs-page)

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

[](#usage-costs-project_ids)

project\_ids

array

Optional

Return only costs for these projects.

#### Returns

A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object) objects.

Example request

curl
    curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json"

Response
    {
        "object": "page",
        "data": [
            {
                "object": "bucket",
                "start_time": 1730419200,
                "end_time": 1730505600,
                "results": [
                    {
                        "object": "organization.costs.result",
                        "amount": {
                            "value": 0.06,
                            "currency": "usd"
                        },
                        "line_item": null,
                        "project_id": null
                    }
                ]
            }
        ],
        "has_more": false,
        "next_page": null
    }

Costs object


----------------

The aggregated costs details of the specific time bucket.

[](#usage/costs_object-amount)

amount

object

The monetary value in its associated currency.

Show properties

[](#usage/costs_object-line_item)

line\_item

string or null

When `group_by=line_item`, this field provides the line item of the grouped costs result.

[](#usage/costs_object-object)

object

string

[](#usage/costs_object-project_id)

project\_id

string or null

When `group_by=project_id`, this field provides the project ID of the grouped costs result.

OBJECT Costs object
    {
        "object": "organization.costs.result",
        "amount": {
          "value": 0.06,
          "currency": "usd"
        },
        "line_item": "Image models",
        "project_id": "proj_abc"
    }

Certificates

Beta


----------------------

Manage Mutual TLS certificates across your organization and projects.

[Learn more about Mutual TLS.](https://help.openai.com/en/articles/10876024-openai-mutual-tls-beta-program)

Upload certificate


----------------------

postÂ https://api.openai.com/v1/organization/certificates

Upload a certificate to the organization. This does **not** automatically activate the certificate.

Organizations can upload up to 50 certificates.

#### Request body

[](#certificates-uploadcertificate-content)

content

string

Required

The certificate content in PEM format

[](#certificates-uploadcertificate-name)

name

string

Optional

An optional name for the certificate

#### Returns

A single [Certificate](/docs/api-reference/certificates/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/certificates \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "name": "My Example Certificate",
      "certificate": "-----BEGIN CERTIFICATE-----\\nMIIDeT...\\n-----END CERTIFICATE-----"
    }'

Response
    {
      "object": "certificate",
      "id": "cert_abc",
      "name": "My Example Certificate",
      "created_at": 1234567,
      "certificate_details": {
        "valid_at": 12345667,
        "expires_at": 12345678
      }
    }

Get certificate


-------------------

getÂ https://api.openai.com/v1/organization/certificates/{certificate\_id}

Get a certificate that has been uploaded to the organization.

You can get a certificate regardless of whether it is active or not.

#### Path parameters

[](#certificates-getcertificate-cert_id)

cert\_id

string

Required

Unique ID of the certificate to retrieve.

#### Query parameters

[](#certificates-getcertificate-include)

include

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `content` to fetch the PEM content of the certificate.

#### Returns

A single [Certificate](/docs/api-reference/certificates/object) object.

Example request

curl
    curl "https://api.openai.com/v1/organization/certificates/cert_abc?include[]=content" \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY"

Response
    {
      "object": "certificate",
      "id": "cert_abc",
      "name": "My Example Certificate",
      "created_at": 1234567,
      "certificate_details": {
        "valid_at": 1234567,
        "expires_at": 12345678,
        "content": "-----BEGIN CERTIFICATE-----MIIDeT...-----END CERTIFICATE-----"
      }
    }

Modify certificate


----------------------

postÂ https://api.openai.com/v1/organization/certificates/{certificate\_id}

Modify a certificate. Note that only the name can be modified.

#### Request body

[](#certificates-modifycertificate-name)

name

string

Required

The updated name for the certificate

#### Returns

The updated [Certificate](/docs/api-reference/certificates/object) object.

Example request

curl
    curl -X POST https://api.openai.com/v1/organization/certificates/cert_abc \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "name": "Renamed Certificate"
    }'

Response
    {
      "object": "certificate",
      "id": "cert_abc",
      "name": "Renamed Certificate",
      "created_at": 1234567,
      "certificate_details": {
        "valid_at": 12345667,
        "expires_at": 12345678
      }
    }

Delete certificate


----------------------

deleteÂ https://api.openai.com/v1/organization/certificates/{certificate\_id}

Delete a certificate from the organization.

The certificate must be inactive for the organization and all projects.

#### Returns

A confirmation object indicating the certificate was deleted.

Example request

curl
    curl -X DELETE https://api.openai.com/v1/organization/certificates/cert_abc \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY"

Response
    {
      "object": "certificate.deleted",
      "id": "cert_abc"
    }

List organization certificates


----------------------------------

getÂ https://api.openai.com/v1/organization/certificates

List uploaded certificates for this organization.

#### Query parameters

[](#certificates-listorganizationcertificates-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#certificates-listorganizationcertificates-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#certificates-listorganizationcertificates-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/certificates \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "organization.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
      "first_id": "cert_abc",
      "last_id": "cert_abc",
      "has_more": false
    }

List project certificates


-----------------------------

getÂ https://api.openai.com/v1/organization/projects/{project\_id}/certificates

List certificates for this project.

#### Query parameters

[](#certificates-listprojectcertificates-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

[](#certificates-listprojectcertificates-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#certificates-listprojectcertificates-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/certificates \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY"

Response
    {
      "object": "list",
      "data": [
        {
          "object": "organization.project.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
      "first_id": "cert_abc",
      "last_id": "cert_abc",
      "has_more": false
    }

Activate certificates for organization


------------------------------------------

postÂ https://api.openai.com/v1/organization/certificates/activate

Activate certificates at the organization level.

You can atomically and idempotently activate up to 10 certificates at a time.

#### Request body

[](#certificates-activateorganizationcertificates-certificate_ids)

certificate\_ids

array

Required

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects that were activated.

Example request

curl
    curl https://api.openai.com/v1/organization/certificates/activate \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "data": ["cert_abc", "cert_def"]
    }'

Response
    {
      "object": "organization.certificate.activation",
      "data": [
        {
          "object": "organization.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
        {
          "object": "organization.certificate",
          "id": "cert_def",
          "name": "My Example Certificate 2",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
    }

Deactivate certificates for organization


--------------------------------------------

postÂ https://api.openai.com/v1/organization/certificates/deactivate

Deactivate certificates at the organization level.

You can atomically and idempotently deactivate up to 10 certificates at a time.

#### Request body

[](#certificates-deactivateorganizationcertificates-certificate_ids)

certificate\_ids

array

Required

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects that were deactivated.

Example request

curl
    curl https://api.openai.com/v1/organization/certificates/deactivate \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "data": ["cert_abc", "cert_def"]
    }'

Response
    {
      "object": "organization.certificate.deactivation",
      "data": [
        {
          "object": "organization.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": false,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
        {
          "object": "organization.certificate",
          "id": "cert_def",
          "name": "My Example Certificate 2",
          "active": false,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
    }

Activate certificates for project


-------------------------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/certificates/activate

Activate certificates at the project level.

You can atomically and idempotently activate up to 10 certificates at a time.

#### Request body

[](#certificates-activateprojectcertificates-certificate_ids)

certificate\_ids

array

Required

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects that were activated.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/certificates/activate \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "data": ["cert_abc", "cert_def"]
    }'

Response
    {
      "object": "organization.project.certificate.activation",
      "data": [
        {
          "object": "organization.project.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
        {
          "object": "organization.project.certificate",
          "id": "cert_def",
          "name": "My Example Certificate 2",
          "active": true,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
    }

Deactivate certificates for project


---------------------------------------

postÂ https://api.openai.com/v1/organization/projects/{project\_id}/certificates/deactivate

Deactivate certificates at the project level.

You can atomically and idempotently deactivate up to 10 certificates at a time.

#### Request body

[](#certificates-deactivateprojectcertificates-certificate_ids)

certificate\_ids

array

Required

#### Returns

A list of [Certificate](/docs/api-reference/certificates/object) objects that were deactivated.

Example request

curl
    curl https://api.openai.com/v1/organization/projects/proj_abc/certificates/deactivate \
    -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "data": ["cert_abc", "cert_def"]
    }'

Response
    {
      "object": "organization.project.certificate.deactivation",
      "data": [
        {
          "object": "organization.project.certificate",
          "id": "cert_abc",
          "name": "My Example Certificate",
          "active": false,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
        {
          "object": "organization.project.certificate",
          "id": "cert_def",
          "name": "My Example Certificate 2",
          "active": false,
          "created_at": 1234567,
          "certificate_details": {
            "valid_at": 12345667,
            "expires_at": 12345678
          }
        },
      ],
    }

The certificate object


--------------------------

Represents an individual `certificate` uploaded to the organization.

[](#certificates/object-active)

active

boolean

Whether the certificate is currently active at the specified scope. Not returned when getting details for a specific certificate.

[](#certificates/object-certificate_details)

certificate\_details

object

Show properties

[](#certificates/object-created_at)

created\_at

integer

The Unix timestamp (in seconds) of when the certificate was uploaded.

[](#certificates/object-id)

id

string

The identifier, which can be referenced in API endpoints

[](#certificates/object-name)

name

string

The name of the certificate.

[](#certificates/object-object)

object

string

The object type.

*   If creating, updating, or getting a specific certificate, the object type is `certificate`.
*   If listing, activating, or deactivating certificates for the organization, the object type is `organization.certificate`.
*   If listing, activating, or deactivating certificates for a project, the object type is `organization.project.certificate`.

OBJECT The certificate object
    {
      "object": "certificate",
      "id": "cert_abc",
      "name": "My Certificate",
      "created_at": 1234567,
      "certificate_details": {
        "valid_at": 1234567,
        "expires_at": 12345678,
        "content": "-----BEGIN CERTIFICATE----- MIIGAjCCA...6znFlOW+ -----END CERTIFICATE-----"
      }
    }

Completions

Legacy


-----------------------

Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.

Create completion

Legacy


-----------------------------

postÂ https://api.openai.com/v1/completions

Creates a completion for the provided prompt and parameters.

#### Request body

[](#completions-create-model)

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

[](#completions-create-prompt)

prompt

string or array

Required

The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.

[](#completions-create-best_of)

best\_of

integer or null

Optional

Defaults to 1

Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return â `best_of` must be greater than `n`.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

[](#completions-create-echo)

echo

boolean or null

Optional

Defaults to false

Echo back the prompt in addition to the completion

[](#completions-create-frequency_penalty)

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

[](#completions-create-logit_bias)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.

[](#completions-create-logprobs)

logprobs

integer or null

Optional

Defaults to null

Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

The maximum value for `logprobs` is 5.

[](#completions-create-max_tokens)

max\_tokens

integer or null

Optional

Defaults to 16

The maximum number of [tokens](/tokenizer) that can be generated in the completion.

The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

[](#completions-create-n)

n

integer or null

Optional

Defaults to 1

How many completions to generate for each prompt.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

[](#completions-create-presence_penalty)

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

[](#completions-create-seed)

seed

integer or null

Optional

If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

[](#completions-create-stop)

stop

string / array / null

Optional

Defaults to null

Not supported with latest reasoning models `o3` and `o4-mini`.

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

[](#completions-create-stream)

stream

boolean or null

Optional

Defaults to false

Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

[](#completions-create-stream_options)

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

[](#completions-create-suffix)

suffix

string or null

Optional

Defaults to null

The suffix that comes after a completion of inserted text.

This parameter is only supported for `gpt-3.5-turbo-instruct`.

[](#completions-create-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

[](#completions-create-top_p)

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

[](#completions-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

#### Returns

Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.

No streamingNo streamingStreamingStreaming

Example request

gpt-3.5-turbo-instruct

node.js
    curl https://api.openai.com/v1/completions \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "model": "gpt-3.5-turbo-instruct",
        "prompt": "Say this is a test",
        "max_tokens": 7,
        "temperature": 0
      }'
    from openai import OpenAI
    client = OpenAI()
    
    client.completions.create(
      model="gpt-3.5-turbo-instruct",
      prompt="Say this is a test",
      max_tokens=7,
      temperature=0
    )
    import OpenAI from "openai";
    
    const openai = new OpenAI();
    
    async function main() {
      const completion = await openai.completions.create({
        model: "gpt-3.5-turbo-instruct",
        prompt: "Say this is a test.",
        max_tokens: 7,
        temperature: 0,
      });
    
      console.log(completion);
    }
    main();

Response
    {
      "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
      "object": "text_completion",
      "created": 1589478378,
      "model": "gpt-3.5-turbo-instruct",
      "system_fingerprint": "fp_44709d6fcb",
      "choices": [
        {
          "text": "\n\nThis is indeed a test",
          "index": 0,
          "logprobs": null,
          "finish_reason": "length"
        }
      ],
      "usage": {
        "prompt_tokens": 5,
        "completion_tokens": 7,
        "total_tokens": 12
      }
    }

The completion object

Legacy


---------------------------------

Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).

[](#completions/object-choices)

choices

array

The list of completion choices the model generated for the input prompt.

Show properties

[](#completions/object-created)

created

integer

The Unix timestamp (in seconds) of when the completion was created.

[](#completions/object-id)

id

string

A unique identifier for the completion.

[](#completions/object-model)

model

string

The model used for completion.

[](#completions/object-object)

object

string

The object type, which is always "text\_completion"

[](#completions/object-system_fingerprint)

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

[](#completions/object-usage)

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The completion object

    {
      "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
      "object": "text_completion",
      "created": 1589478378,
      "model": "gpt-4-turbo",
      "choices": [
        {
          "text": "\n\nThis is indeed a test",
          "index": 0,
          "logprobs": null,
          "finish_reason": "length"
        }
      ],
      "usage": {
        "prompt_tokens": 5,
        "completion_tokens": 7,
        "total_tokens": 12
      }
    }